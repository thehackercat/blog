<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Kubernetes - Tag - LexusLee&#39;s blog</title>
        <link>https://example.com/tags/kubernetes/</link>
        <description>Kubernetes - Tag - LexusLee&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>lexuscyborg103@gmail.com (LexusLee)</managingEditor>
            <webMaster>lexuscyborg103@gmail.com (LexusLee)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 09 Oct 2021 09:57:53 &#43;0800</lastBuildDate><atom:link href="https://example.com/tags/kubernetes/" rel="self" type="application/rss+xml" /><item>
    <title>Kube-scheduler 调度模型与美团本地化改造</title>
    <link>https://example.com/kubernetes-scheduler-modified-in-meituan/</link>
    <pubDate>Sat, 09 Oct 2021 09:57:53 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://example.com/kubernetes-scheduler-modified-in-meituan/</guid>
    <description><![CDATA[背景 今天主要分享下我在美团 Hulk 团队调度系统组期间学习到的 k8s scheduler 调度模型及美团对于调度器相关改造
Hulk 团队介绍 Hulk 是美团负责容器云平台的团队, 我所在的组是调度系统组下面的 k8s 小组. 主要负责所有 k8s 相关组件开发维护.
Kube-scheduler 调度模型介绍 (本次介绍基于 k8s 1.16 版本)
pod 是 k8s 工作负载的最小实体，也是 scheduler 调度的主要对象。
k8s 调度器所做的工作，即将 pod 绑定到指定节点上，为 pod 选择合适的节点。
Scheduler 会先 watch apiserver 获取其中待调度的 pod, 即 pod.spec.nodeName 字段为空的 pod 对象, 通过调用 pod informer 的 handler 并将该 pod 加入调度队列中。
默认情况下, k8s 调度队列是一个 PriorityQueue, 并且当某些集群信息发生改变时, 调度器会对调度队列的内容进行一些特殊操作. 在这儿不论述.
一次调度过程在判断一个 Node是否可作为目标机器时，主要分为三个阶段：
 Predicates 预选阶段：硬性条件，过滤掉不满足条件的节点，这个过程称为 Predicates。这是固定先后顺序的一系列过滤条件，任何一个 Predicate 不符合则放弃该 Node。 Prioritites 优选阶段：软性条件，对通过的节点按照优先级排序，称之为 Priorities。每一个 Priority 都是一个影响因素，都有一定的权重。 Select 选定阶段：从优选列表中选择优先级最高的节点，称为 Select。选择的 Node 即为最终部署 Pod 的机器。  预选阶段 Scheduler 起 n 个 goroutine 并发对整个集群的所有 nodes 进行 predicates 串行运算过滤规则，直到最终过滤出符合条件的 nodes 列表]]></description>
</item><item>
    <title>云原生下发布平台建设思考</title>
    <link>https://example.com/talk-about-cloud-based-release-platform/</link>
    <pubDate>Sat, 02 Oct 2021 11:04:16 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://example.com/talk-about-cloud-based-release-platform/</guid>
    <description><![CDATA[<div style="text-align: right;">Lexus Lee</div>
<h2 id="背景">背景</h2>
<p>从过去几个月, 我的工作精力主要集中在企业级发布平台的建设上. 同时也聚焦在容器云 <strong>PaaS</strong> 层建设。</p>
<p>在当下云原生时代, 发布平台通常起到一个联结 PaaS 和 IaaS 的作用. 通过在 <strong>PaaS</strong> 层抽象，将 IaaS 层基建细节屏蔽，同时通过 api 和各个服务平台(CI/CD 服务, 监控告警服务, 网关服务, 工单系统, 服务治理系统等) 交互, 在云平台提供了一个统一的快捷入口，从逻辑上进行汇聚，便于开发者进行<strong>一站式</strong>应用发布、服务生命周期管理、服务治理、服务运维等操作.</p>]]></description>
</item><item>
    <title>基于服务画像的垂直伸缩系统建设思考</title>
    <link>https://example.com/service-portrait-vpa-design/</link>
    <pubDate>Tue, 28 Sep 2021 19:51:32 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://example.com/service-portrait-vpa-design/</guid>
    <description><![CDATA[<div style="text-align: right;">Lexus Lee</div>
<h2 id="背景">背景</h2>
<p>近期公司开始做成本治理, 降本增效. 通过观察以往各业务线的资源规格配置, 不难发现存在大量服务资源超配情况. 即服务实际资源开销远小于其声明的资源开销. 而这部分的资源超配直接导致了集群的资源使用率较低. 通常形如下图</p>]]></description>
</item><item>
    <title>Talk about Containerd</title>
    <link>https://example.com/talk-about-containerd/</link>
    <pubDate>Sat, 10 Apr 2021 15:04:09 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://example.com/talk-about-containerd/</guid>
    <description><![CDATA[背景 最近看一些社区 issue 中正好接触到 containerd 源码, 早年大家基本都使用 docker/podman 这类容器上层包装, 包括我也是, 故对真正容器运行时的结构部分了解得不够深入, 最近 k8s 社区在 1.21 规划上计划从 kubelet 中移除 docker-shim 交互的逻辑, 大势上组件走上 containerd-shim, 故需要着手对容器运行时更深入了解.
带着问题作为引入,
容器底层还是对 Linux LXC 的交互, 那究竟 docker daemon 中是哪个组件来完成这一步的呢？
1、背景知识 首先我们需要了解 Docker Daemon 生产出容器的过程.
当前整个 Docker 调用链架构可以用下图来简单概括
从 Docker 1.11 之后，Docker Daemon 被分成了多个模块以适应 OCI 标准。拆分之后，结构分成了以下几个部分：
16年12月 Docker公司宣布将 containerd 从Docker Engine中分离，并捐赠到开源社区独立发展和运营。
一个工业标准的容器运行时，注重简单、 健壮性、可移植性
Docker本身其实已经被剥离干净了，只剩下 Docker 自身作为 cli 的一些特色功能了，真正容器的管控都在 containerd 里实现。
在 17 年 docker重命名为moby, 从命名上逐渐脱离和 container 的关系, 而 Moby 更像是一个“乐高积木”，它包含了容器化的组件库 底层的构建、日志处理、卷管理、网络、镜像管理、containerd、SwarmKit等模块, 是个大杂烩.]]></description>
</item><item>
    <title>译《Autopilot: workload autoscaling at Google》</title>
    <link>https://example.com/google-autopilot-scaling/</link>
    <pubDate>Sun, 10 Jan 2021 13:10:46 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/google-autopilot-scaling/</guid>
    <description><![CDATA[摘要 原文链接：https://dl.acm.org/doi/pdf/10.1145/3342195.3387524
在许多公共和私有云系统中，用户需要指定资源量（CPU内核和RAM）的限制以为其工作负荷提供资源。 超出其限制的作业可能会受到限制或终止，从而导致最终用户请求的延迟或丢弃，因此人工操作人员针对这种问题出于谨慎考虑，会申请高于任务自身需要的配置。 从规模上讲，这将导致大量的资源浪费。
为了解决这个问题，Google使用Autopilot自动配置资源，同时调整作业中的并发任务数（水平缩放）和单个任务的CPU /内存限制（垂直缩放）。 Autopilot与人工操作员遵循相同的原则：Autopilot的主要目标是减少松弛（slack）（申请资源和实际资源使用之间的差异），同时最大程度地降低因内存不足（OOM）错误或 由于CPU节流，其性能下降。 Autopilot将机器学习算法应用到有关作业先前执行情况的历史数据上，再加上一组经过微调的启发式方法来实现这一目标。 在实践中，Autopilot工作只有23％的松弛（slack），而手动管理工作只有46％的松弛（slack）。 此外，Autopilot将受OOM严重影响的工作数量减少了10倍。
尽管有其优点，要确保Autopilot被广泛采用仍需付出巨大的努力，包括使尚未加入的客户容易看到潜在的建议，自动迁移某些类别的任务以及增加对自定义推荐器的支持。 在撰写本文时，Autopilot任务占Google资源使用的48％以上。
ACM参考格式：
Krzysztof Rzadca，Pawel Findeisen，Jacek Swiderski，Przemyslaw Zych，Przemyslaw Broniek，Jarek Kusmierek，Pawel Nowak，Beata Strack，Piotr Witusowski，Steven Hand和John Wilkes。 2020年。
Autopilot：Google的工作负载自动缩放。 在第十五欧洲2020年4月27日至30日，计算机系统会议（EuroSys'20），希腊伊拉克利翁。 ACM，美国纽约，纽约，共16页。 https://doi. org/10.1145/3342195.3387524
1 介绍 许多类型的公共云和私有云系统要求其用户声明在执行期间其工作负载将需要多少个实例以及每个实例所需的资源：在公共云平台中，用户需要选择他们需要租用虚拟机（VM）的类型和数量； 在Kubernetes集群中，用户可以设置Pod副本的数量和单个Pod的资源限制; 在Google中，我们要求用户指定所需的容器数量以及每个容器的资源限制。 这些限制使云基础架构能够提供足够的性能隔离，从而使云计算成为可能。
但是限制（主要是）对用户造成了麻烦。 很难估计一个作业需要多少资源才能最佳运行：CPU功率，内存和同时运行的副本数的正确组合。 负载测试可以帮助找到初始估计值，但是随着资源需求随时间变化，这些建议将过时，因为许多最终用户服务工作具有每日或每周的负载模式，并且随着服务变得越来越流行，流量在更长的时间内发生变化 。 最后，处理给定负载所需的资源会随着基础软件或硬件堆栈的新功能，优化和更新而变化。如果CPU容量不足，超出请求的资源可能会导致性能下降，或者导致任务被杀死 内存不足（OOM）。 都不是好事。
从调研结果看，理性的用户将故意高估其工作所需的资源，从而导致对物理资源的不良利用。 一项分析[26]对在一个Google集群[27]上执行的为期一个月的作业跟踪显示，平均内存利用率为50％； 对阿里巴巴YARN集群的另一项分析[23]显示任务的峰值内存利用率从未超过80％。
针对配置资源的困难，一种常见的模式是采用水平自动缩放器，该缩放器通过监控终端用户流量或平均CPU利用率的变化添加或删除副本来缩放任务。 所有主要的云提供商（AWS，Azure和GCP）都提供水平自动扩展功能； 它在某些云中间件（如Kubernetes）中也可用。 较不常见的模式是使用垂直自动缩放来调整每个副本可用的资源量。 两种技术也可以组合。
Autopilot是Google在其内部云上使用的主要自动缩放器。 它提供水平和垂直自动缩放。 本文重点介绍Autopilot的内存垂直扩展，因为这种情况鲜为人知。 论文：
  描述下Autopilot，以及它用于垂直自动缩放的两个主要算法：第一个算法依赖于历史用量的指数平滑滑动窗口； 另一个是基于从强化学习中借用的思想的元学习，该算法运行滑动窗口算法的许多变体，并为每个任务选择历史数据表现最佳的算法。（译注：强化学习：依赖海量的训练，并且需要精准的奖励。成本较高且比较复杂。元学习：具备自学能力，能够充分利用过去的经验来指导未来的任务。被认为是实现通用人工智能的关键。）
  通过Google的工作负载采样评估Autopilot算法的有效性；
  讨论为使我们的集群广泛采用Autopilot而采取的步骤。
  2 通过Borg管理云资源 Autopilot的目标和制约因素来自Google的Borg基础架构，并且针对Google的工作负载进行了调整。 我们在此处提供了两者的简要概述：有关Borg的更多详细信息，请参见[34]，有关工作负载的更多详细信息，请参见[26、27、31、35]。]]></description>
</item><item>
    <title>升级 k8s 集群 docker</title>
    <link>https://example.com/upgrade-dockerd-in-k8s/</link>
    <pubDate>Fri, 10 Jul 2020 19:10:46 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/upgrade-dockerd-in-k8s/</guid>
    <description><![CDATA[背景 最近需要给 k8s 集群升级 docker, 预期升到 19.03.x.
遇到一些问题, 记录下
调试期间遇到的问题: 集群中的 ingress 是以 daemonsets 方式部署, 通过 node-selector 选择节点定死.
而 kubectl drain node 并不 evict daemonset pods. 故在升级/重启 dockerd 期间会造成 ingress 短暂不可用. 而现有的 lb 的 health check 不能 cover 这一点, 仍会有流量打入.会导致升级期间 ingress 流量黑洞问题.
并且 dockerd 拉起来后, 有些 daemonsets 由于 ingress 自身 livenessProbe 等原因在 dockerd 升级期间持续 crashLoopbackoff 了, 一个原因是仍然 mount 一份旧的 docker overlay. 在 delete pod 重启后恢复. 故需要一个手段在升级后重启 ingress pods.
Ref https://github.com/kubernetes/kubernetes/issues/75482#issuecomment-511476698]]></description>
</item><item>
    <title>Talk about Kubernetes cronJob controller</title>
    <link>https://example.com/talk-about-k8s-cronjob/</link>
    <pubDate>Sat, 14 Dec 2019 13:57:32 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/talk-about-k8s-cronjob/</guid>
    <description><![CDATA[背景 之前一段时间正好接触到 kubernetes cronjob, 在接入时遇上了在一定量级下 cronjob schedule delay 的问题, 故开始读了下代码, 发现了一些问题并试着调优了下
存在的问题 按生产环境实际测试来看约 250-375 个 */1 * * * * 每分钟 interval 的 cronjob 就会产生 delay, cronjob 和 controller manager 没有异常 event 但新产生的 job 出现了延迟, 由于我们设置了 startingDeadlineSeconds 故累加起来的 delay 最终导致了 cron 任务严重滞后
代码解读 出于分析上述问题的目的, 读了下 cronjob controller 的代码, 代码量不多, 可能由于没上 GA 的原因, 整个 controllor 代码的设计也比较过程式, 不会像其他组件用到一些比如 Informer, refractor之类的组件读起来相对晦涩
下面开始解读下 release1.17 分支的 k8s cronjob controller 代码
 Controller struct  1 2 3 4 5 6 7  type Controller struct { kubeClient clientset.]]></description>
</item><item>
    <title>记一次升级 kube-proxy ipvs 引发的线上故障</title>
    <link>https://example.com/kubeproxy-ipvs-accident/</link>
    <pubDate>Mon, 29 Apr 2019 19:10:46 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/kubeproxy-ipvs-accident/</guid>
    <description><![CDATA[背景 最近在升级集群的 kube-prxoy 并开启 ipvs mode, 引发了一些线上故障
替换原因 由于豆瓣的集群使用 calico + kube-proxy iptables mode + puppet iptable 脚本管理
三个组件共同操作同一份 iptables, 容易出现 race condition 问题, 并且还会互相抢占 iptables 锁, 是个 Mutex unsafe 的操作, 不易于维护.
故打算尽量减少操作 iptables 的部分, 替换成 ipvs
事故回溯 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  @400000005cbea9a81eaf9164 W0423 13:58:54.514773 14016 server.go:195] WARNING: all flags other than --config, --write-config-to, and --cleanup are deprecated.]]></description>
</item><item>
    <title>浅谈 k8s service&amp;kube-proxy</title>
    <link>https://example.com/k8s-service-endpoints/</link>
    <pubDate>Fri, 14 Sep 2018 19:10:46 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/k8s-service-endpoints/</guid>
    <description><![CDATA[<div style="text-align: right;">Lexus Lee</div>
<h3 id="背景">背景</h3>
<p>最开始听到同事 k8s 分享时比较困惑我的一个问题是 k8s 怎么实现一个私有 ip(虚拟 ip，以下简称 vip)到另一个私有ip收发包的。</p>
<p>不过其实我想知道的应该是 k8s 通信机制，它是怎么实现服务发现的，新建的 pod 是怎么感知到的，万一有些 pod 节点变更 vip 变了 k8s 是如何感知的。</p>
<p>基于这个问题，做一下关于 k8s service&amp;kube-proxy 的分享。</p>]]></description>
</item></channel>
</rss>
