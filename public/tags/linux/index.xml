<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Linux - Tag - LexusLee&#39;s blog</title>
        <link>https://example.com/tags/linux/</link>
        <description>Linux - Tag - LexusLee&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>lexuscyborg103@gmail.com (LexusLee)</managingEditor>
            <webMaster>lexuscyborg103@gmail.com (LexusLee)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Sat, 09 Oct 2021 09:57:53 &#43;0800</lastBuildDate><atom:link href="https://example.com/tags/linux/" rel="self" type="application/rss+xml" /><item>
    <title>Kube-scheduler 调度模型与美团本地化改造</title>
    <link>https://example.com/kubernetes-scheduler-modified-in-meituan/</link>
    <pubDate>Sat, 09 Oct 2021 09:57:53 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://example.com/kubernetes-scheduler-modified-in-meituan/</guid>
    <description><![CDATA[背景 今天主要分享下我在美团 Hulk 团队调度系统组期间学习到的 k8s scheduler 调度模型及美团对于调度器相关改造
Hulk 团队介绍 Hulk 是美团负责容器云平台的团队, 我所在的组是调度系统组下面的 k8s 小组. 主要负责所有 k8s 相关组件开发维护.
Kube-scheduler 调度模型介绍 (本次介绍基于 k8s 1.16 版本)
pod 是 k8s 工作负载的最小实体，也是 scheduler 调度的主要对象。
k8s 调度器所做的工作，即将 pod 绑定到指定节点上，为 pod 选择合适的节点。
Scheduler 会先 watch apiserver 获取其中待调度的 pod, 即 pod.spec.nodeName 字段为空的 pod 对象, 通过调用 pod informer 的 handler 并将该 pod 加入调度队列中。
默认情况下, k8s 调度队列是一个 PriorityQueue, 并且当某些集群信息发生改变时, 调度器会对调度队列的内容进行一些特殊操作. 在这儿不论述.
一次调度过程在判断一个 Node是否可作为目标机器时，主要分为三个阶段：
 Predicates 预选阶段：硬性条件，过滤掉不满足条件的节点，这个过程称为 Predicates。这是固定先后顺序的一系列过滤条件，任何一个 Predicate 不符合则放弃该 Node。 Prioritites 优选阶段：软性条件，对通过的节点按照优先级排序，称之为 Priorities。每一个 Priority 都是一个影响因素，都有一定的权重。 Select 选定阶段：从优选列表中选择优先级最高的节点，称为 Select。选择的 Node 即为最终部署 Pod 的机器。  预选阶段 Scheduler 起 n 个 goroutine 并发对整个集群的所有 nodes 进行 predicates 串行运算过滤规则，直到最终过滤出符合条件的 nodes 列表]]></description>
</item><item>
    <title>基于服务画像的垂直伸缩系统建设思考</title>
    <link>https://example.com/service-portrait-vpa-design/</link>
    <pubDate>Tue, 28 Sep 2021 19:51:32 &#43;0800</pubDate>
    <author>Author</author>
    <guid>https://example.com/service-portrait-vpa-design/</guid>
    <description><![CDATA[<div style="text-align: right;">Lexus Lee</div>
<h2 id="背景">背景</h2>
<p>近期公司开始做成本治理, 降本增效. 通过观察以往各业务线的资源规格配置, 不难发现存在大量服务资源超配情况. 即服务实际资源开销远小于其声明的资源开销. 而这部分的资源超配直接导致了集群的资源使用率较低. 通常形如下图</p>]]></description>
</item><item>
    <title>eBPF learning 01</title>
    <link>https://example.com/ebpf-leanring1/</link>
    <pubDate>Mon, 13 Jan 2020 18:26:09 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/ebpf-leanring1/</guid>
    <description><![CDATA[(译) eBPF Tracing 简明教程与示例 背景    原文链接 http://www.brendangregg.com/blog/2019-01-01/learn-ebpf-tracing.html     原文作者 Brendan Gregg   出版时间 01 Jan 2019   翻译时间 11 Jan 2020    之前开 2019 ShangHai KubeConf 听了几场 eBPF 的分享, 最近才开始深入研究, 故打算把研究 Linux performance 的大佬 Brendan Gregg 的文章《Learn eBPF Tracing: Tutorial and Examples》 作为 eBPF 入门翻译一遍, 希望对其他非英语母语的开发者有帮助。
译文 在 2019 年的 Linux Plumber&rsquo;s 大会上至少有 24 场关于 eBPF 的讲座, eBPF 迅速地成为了炙手可热的技术。所以也许你也计划在新的一年里开始学习 eBPF!]]></description>
</item><item>
    <title>Talk about Kubernetes cronJob controller</title>
    <link>https://example.com/talk-about-k8s-cronjob/</link>
    <pubDate>Sat, 14 Dec 2019 13:57:32 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/talk-about-k8s-cronjob/</guid>
    <description><![CDATA[背景 之前一段时间正好接触到 kubernetes cronjob, 在接入时遇上了在一定量级下 cronjob schedule delay 的问题, 故开始读了下代码, 发现了一些问题并试着调优了下
存在的问题 按生产环境实际测试来看约 250-375 个 */1 * * * * 每分钟 interval 的 cronjob 就会产生 delay, cronjob 和 controller manager 没有异常 event 但新产生的 job 出现了延迟, 由于我们设置了 startingDeadlineSeconds 故累加起来的 delay 最终导致了 cron 任务严重滞后
代码解读 出于分析上述问题的目的, 读了下 cronjob controller 的代码, 代码量不多, 可能由于没上 GA 的原因, 整个 controllor 代码的设计也比较过程式, 不会像其他组件用到一些比如 Informer, refractor之类的组件读起来相对晦涩
下面开始解读下 release1.17 分支的 k8s cronjob controller 代码
 Controller struct  1 2 3 4 5 6 7  type Controller struct { kubeClient clientset.]]></description>
</item><item>
    <title>记一次升级 kube-proxy ipvs 引发的线上故障</title>
    <link>https://example.com/kubeproxy-ipvs-accident/</link>
    <pubDate>Mon, 29 Apr 2019 19:10:46 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/kubeproxy-ipvs-accident/</guid>
    <description><![CDATA[背景 最近在升级集群的 kube-prxoy 并开启 ipvs mode, 引发了一些线上故障
替换原因 由于豆瓣的集群使用 calico + kube-proxy iptables mode + puppet iptable 脚本管理
三个组件共同操作同一份 iptables, 容易出现 race condition 问题, 并且还会互相抢占 iptables 锁, 是个 Mutex unsafe 的操作, 不易于维护.
故打算尽量减少操作 iptables 的部分, 替换成 ipvs
事故回溯 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  @400000005cbea9a81eaf9164 W0423 13:58:54.514773 14016 server.go:195] WARNING: all flags other than --config, --write-config-to, and --cleanup are deprecated.]]></description>
</item><item>
    <title>浅谈 k8s service&amp;kube-proxy</title>
    <link>https://example.com/k8s-service-endpoints/</link>
    <pubDate>Fri, 14 Sep 2018 19:10:46 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/k8s-service-endpoints/</guid>
    <description><![CDATA[<div style="text-align: right;">Lexus Lee</div>
<h3 id="背景">背景</h3>
<p>最开始听到同事 k8s 分享时比较困惑我的一个问题是 k8s 怎么实现一个私有 ip(虚拟 ip，以下简称 vip)到另一个私有ip收发包的。</p>
<p>不过其实我想知道的应该是 k8s 通信机制，它是怎么实现服务发现的，新建的 pod 是怎么感知到的，万一有些 pod 节点变更 vip 变了 k8s 是如何感知的。</p>
<p>基于这个问题，做一下关于 k8s service&amp;kube-proxy 的分享。</p>]]></description>
</item><item>
    <title>记一次 postgresql 斯嘉丽约翰逊攻击的排查</title>
    <link>https://example.com/scarllet-sql-attack/</link>
    <pubDate>Sat, 11 Aug 2018 22:49:52 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/scarllet-sql-attack/</guid>
    <description><![CDATA[<h3 id="背景">背景</h3>
<p>今天下午连续收到了腾讯云 CPU overload 报警</p>
<p></p>
<p>登服务器一看, 有个 postgres 账户跑的进程把 CPU 占满了，进程名特别奇怪。</p>
<p></p>]]></description>
</item><item>
    <title>坦率地讲 服务熔断 &amp; 服务降级</title>
    <link>https://example.com/service-fallback/</link>
    <pubDate>Thu, 01 Feb 2018 19:03:25 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/service-fallback/</guid>
    <description><![CDATA[<h2 id="坦率地讲-服务熔断--服务降级">坦率地讲 服务熔断 &amp; 服务降级</h2>
<h3 id="背景">背景</h3>
<p>之前遇到个问题，发现一个系统如果拆分了太多业务类服务，或者依赖于大量的第三方服务，就很容易因为某个服务的故障导致整个系统不可用，比如</p>
<ul>
<li>模块中使用了 Elastic Search 进行监控，但是 ES 突然挂了，相关的 api 的调用报错导致级联的服务全部阻塞，那么应该要有规避由 ES 调用 raise 出的异常或者调用超时而导致整个模块或整个系统崩溃的保护措施。</li>
<li>使用 AWS 或 阿里云 的 ECS 服务来作为 micro-service 的载体，但是 ECS 服务故障或者过载了导致整个业务链无法正常进行，那么应有对应的降级或者限制调用频度的方案来进行保护。</li>
</ul>]]></description>
</item><item>
    <title>关于关闭 Socket 的一些坑</title>
    <link>https://example.com/tcp-close-socket/</link>
    <pubDate>Wed, 06 Sep 2017 20:36:51 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/tcp-close-socket/</guid>
    <description><![CDATA[<h2 id="关于关闭-socket-的一些坑">关于关闭 Socket 的一些坑</h2>
<div style="text-align: right">LexusLee</div>
<h3 id="背景">背景</h3>
<p>最近踩到一个 &ldquo;Socket 连接持续处于 Fin_Wait2 和 Close_Wait 状态无法关闭&rdquo; 的坑中。起因是在维护大量连接时调用 <code>socket.close()</code> 时，看到部分连接并没有正常关闭，而是从 <code>ESTABLISHED</code> 的状态变成 <code>FIN_WAIT2</code> 并且连接状态没有后续迁移，而对端的连接状态则是从 <code>ESTABLISHED</code> 变成了 <code>CLOSE_WAIT</code> 。</p>]]></description>
</item><item>
    <title>终端配置总结</title>
    <link>https://example.com/terminal-config/</link>
    <pubDate>Thu, 30 Mar 2017 15:29:19 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/terminal-config/</guid>
    <description><![CDATA[<h2 id="终端配置总结">终端配置总结</h2>
<h3 id="背景">背景</h3>
<p>最近公司新购置了好几台 Linux 服务器然后配置一些服务的时候很不习惯，估计是我平时自己的 zsh + oh-my-zsh 用多了，故想整理下 .bash_rc 和 .zshrc 我个人的一些配置，这些配置包含了一些 alias 快捷命令和命令行系统配置，可以让终端变得快捷易用，今晚再写个 shell 脚本实现快速修改 .bash_rc 的配置。</p>]]></description>
</item></channel>
</rss>
