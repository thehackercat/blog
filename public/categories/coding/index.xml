<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Coding - Category - LexusLee&#39;s blog</title>
        <link>https://example.com/categories/coding/</link>
        <description>Coding - Category - LexusLee&#39;s blog</description>
        <generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>lexuscyborg103@gmail.com (LexusLee)</managingEditor>
            <webMaster>lexuscyborg103@gmail.com (LexusLee)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Fri, 10 Jul 2020 19:10:46 &#43;0000</lastBuildDate><atom:link href="https://example.com/categories/coding/" rel="self" type="application/rss+xml" /><item>
    <title>升级 k8s 集群 docker</title>
    <link>https://example.com/upgrade-dockerd-in-k8s/</link>
    <pubDate>Fri, 10 Jul 2020 19:10:46 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/upgrade-dockerd-in-k8s/</guid>
    <description><![CDATA[背景 最近需要给 k8s 集群升级 docker, 预期升到 19.03.x.
遇到一些问题, 记录下
调试期间遇到的问题: 集群中的 ingress 是以 daemonsets 方式部署, 通过 node-selector 选择节点定死.
而 kubectl drain node 并不 evict daemonset pods. 故在升级/重启 dockerd 期间会造成 ingress 短暂不可用. 而现有的 lb 的 health check 不能 cover 这一点, 仍会有流量打入.会导致升级期间 ingress 流量黑洞问题.
并且 dockerd 拉起来后, 有些 daemonsets 由于 ingress 自身 livenessProbe 等原因在 dockerd 升级期间持续 crashLoopbackoff 了, 一个原因是仍然 mount 一份旧的 docker overlay. 在 delete pod 重启后恢复. 故需要一个手段在升级后重启 ingress pods.
Ref https://github.com/kubernetes/kubernetes/issues/75482#issuecomment-511476698]]></description>
</item><item>
    <title>告警收敛设计</title>
    <link>https://example.com/alert-convergence/</link>
    <pubDate>Tue, 07 Jul 2020 22:30:07 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/alert-convergence/</guid>
    <description><![CDATA[背景 最近在豆瓣做面向开发者的 op 报警系统, 最头疼的是下列几种情况
 脉冲型报警 单个原因引起的报警发散 多个报警为同个诱因  由于目前现有的一些告警系统都强依赖后面的监控 agent/cmdb , 比如 open-falcon/prometheus 虽然都支持了告警收敛这一套, 但要从豆瓣的 statsd+icinga 迁移到 alertManager 需要折腾一阵。而我实际只想要一个中间轻量的 alert exporter 去做告警聚合/收敛.
所以我期望实现下列 feature:
 对于告警可配置梯度, 比如 apperr &gt; 50, 则立马报警不做 retry, 并且 notify_interval 为 1 分钟; 对于 50 &gt; apperr &gt; 20 则有3次 retry, retry 周期为 1 分钟, 报警周期为2分钟. 对于 apperr &lt; 1 则 retry 5 次, retry 周期 3 分钟, 报警周期 5 分钟. 告警配置中可用 与|或|非 的方式进行组合告警,告警收敛. 如  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  [rules] apperr - script: xxx - label: http, service, statsd, codeerr - warning_threshold: 0.]]></description>
</item><item>
    <title>eBPF learning 01</title>
    <link>https://example.com/ebpf-leanring1/</link>
    <pubDate>Mon, 13 Jan 2020 18:26:09 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/ebpf-leanring1/</guid>
    <description><![CDATA[(译) eBPF Tracing 简明教程与示例 背景    原文链接 http://www.brendangregg.com/blog/2019-01-01/learn-ebpf-tracing.html     原文作者 Brendan Gregg   出版时间 01 Jan 2019   翻译时间 11 Jan 2020    之前开 2019 ShangHai KubeConf 听了几场 eBPF 的分享, 最近才开始深入研究, 故打算把研究 Linux performance 的大佬 Brendan Gregg 的文章《Learn eBPF Tracing: Tutorial and Examples》 作为 eBPF 入门翻译一遍, 希望对其他非英语母语的开发者有帮助。
译文 在 2019 年的 Linux Plumber&rsquo;s 大会上至少有 24 场关于 eBPF 的讲座, eBPF 迅速地成为了炙手可热的技术。所以也许你也计划在新的一年里开始学习 eBPF!]]></description>
</item><item>
    <title>Talk about Kubernetes cronJob controller</title>
    <link>https://example.com/talk-about-k8s-cronjob/</link>
    <pubDate>Sat, 14 Dec 2019 13:57:32 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/talk-about-k8s-cronjob/</guid>
    <description><![CDATA[背景 之前一段时间正好接触到 kubernetes cronjob, 在接入时遇上了在一定量级下 cronjob schedule delay 的问题, 故开始读了下代码, 发现了一些问题并试着调优了下
存在的问题 按生产环境实际测试来看约 250-375 个 */1 * * * * 每分钟 interval 的 cronjob 就会产生 delay, cronjob 和 controller manager 没有异常 event 但新产生的 job 出现了延迟, 由于我们设置了 startingDeadlineSeconds 故累加起来的 delay 最终导致了 cron 任务严重滞后
代码解读 出于分析上述问题的目的, 读了下 cronjob controller 的代码, 代码量不多, 可能由于没上 GA 的原因, 整个 controllor 代码的设计也比较过程式, 不会像其他组件用到一些比如 Informer, refractor之类的组件读起来相对晦涩
下面开始解读下 release1.17 分支的 k8s cronjob controller 代码
 Controller struct  1 2 3 4 5 6 7  type Controller struct { kubeClient clientset.]]></description>
</item><item>
    <title>记一次升级 kube-proxy ipvs 引发的线上故障</title>
    <link>https://example.com/kubeproxy-ipvs-accident/</link>
    <pubDate>Mon, 29 Apr 2019 19:10:46 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/kubeproxy-ipvs-accident/</guid>
    <description><![CDATA[背景 最近在升级集群的 kube-prxoy 并开启 ipvs mode, 引发了一些线上故障
替换原因 由于豆瓣的集群使用 calico + kube-proxy iptables mode + puppet iptable 脚本管理
三个组件共同操作同一份 iptables, 容易出现 race condition 问题, 并且还会互相抢占 iptables 锁, 是个 Mutex unsafe 的操作, 不易于维护.
故打算尽量减少操作 iptables 的部分, 替换成 ipvs
事故回溯 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  @400000005cbea9a81eaf9164 W0423 13:58:54.514773 14016 server.go:195] WARNING: all flags other than --config, --write-config-to, and --cleanup are deprecated.]]></description>
</item><item>
    <title>浅谈 k8s service&amp;kube-proxy</title>
    <link>https://example.com/k8s-service-endpoints/</link>
    <pubDate>Fri, 14 Sep 2018 19:10:46 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/k8s-service-endpoints/</guid>
    <description><![CDATA[<div style="text-align: right;">Lexus Lee</div>
<h3 id="背景">背景</h3>
<p>最开始听到同事 k8s 分享时比较困惑我的一个问题是 k8s 怎么实现一个私有 ip(虚拟 ip，以下简称 vip)到另一个私有ip收发包的。</p>
<p>不过其实我想知道的应该是 k8s 通信机制，它是怎么实现服务发现的，新建的 pod 是怎么感知到的，万一有些 pod 节点变更 vip 变了 k8s 是如何感知的。</p>
<p>基于这个问题，做一下关于 k8s service&amp;kube-proxy 的分享。</p>]]></description>
</item><item>
    <title>记一次 postgresql 斯嘉丽约翰逊攻击的排查</title>
    <link>https://example.com/scarllet-sql-attack/</link>
    <pubDate>Sat, 11 Aug 2018 22:49:52 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/scarllet-sql-attack/</guid>
    <description><![CDATA[<h3 id="背景">背景</h3>
<p>今天下午连续收到了腾讯云 CPU overload 报警</p>
<p></p>
<p>登服务器一看, 有个 postgres 账户跑的进程把 CPU 占满了，进程名特别奇怪。</p>
<p></p>]]></description>
</item><item>
    <title>坦率地讲 服务熔断 &amp; 服务降级</title>
    <link>https://example.com/service-fallback/</link>
    <pubDate>Thu, 01 Feb 2018 19:03:25 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/service-fallback/</guid>
    <description><![CDATA[<h2 id="坦率地讲-服务熔断--服务降级">坦率地讲 服务熔断 &amp; 服务降级</h2>
<h3 id="背景">背景</h3>
<p>之前遇到个问题，发现一个系统如果拆分了太多业务类服务，或者依赖于大量的第三方服务，就很容易因为某个服务的故障导致整个系统不可用，比如</p>
<ul>
<li>模块中使用了 Elastic Search 进行监控，但是 ES 突然挂了，相关的 api 的调用报错导致级联的服务全部阻塞，那么应该要有规避由 ES 调用 raise 出的异常或者调用超时而导致整个模块或整个系统崩溃的保护措施。</li>
<li>使用 AWS 或 阿里云 的 ECS 服务来作为 micro-service 的载体，但是 ECS 服务故障或者过载了导致整个业务链无法正常进行，那么应有对应的降级或者限制调用频度的方案来进行保护。</li>
</ul>]]></description>
</item><item>
    <title>浅谈 Workflow 设计</title>
    <link>https://example.com/workflow-design/</link>
    <pubDate>Sun, 03 Dec 2017 22:30:07 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/workflow-design/</guid>
    <description><![CDATA[浅谈 Workflow 设计 LexusLee 背景 最近刚接触到 workflow 相关的东西，之前都没有造过这方面的轮子，所以看了一些框架总结了一下我认为的好的 Workflow 的设计应该是怎样的。
什么是 Workflow ? Workflow 是一些可重复执行的事件按特定的顺序&amp;路径组合成的事件流，这个组成的事件流通常是为了满足某一个流程较长的任务。
这些事件通常是不可再被细分，是具有原子性的。每个原子事件可能包含执行任务、文档或数据。这些事件按照提前声明好的规则组合起来就成了一个 Workflow .
e.g. 如上图所示，Workflow 类似软件工程中的流程图，指定了每个节点可能出现的路径分支，节点执行的事情以及节点的终结状态。
如何设计 Workflow ? 比较经典的 Workflow design pattern 应该满足以下几个元素：
 路径覆盖 事件原子性 有效的状态迁移  路径覆盖 路径覆盖是和节点状态相关的，通常的节点状态有如下几种：
 Start —— 开始 jobs ，标明 workflow 起点 Maybe —— 表示这个任务可能会执行，但不一定会执行，它的执行依赖于一定条件，比如上层节点的输出 Likely —— 和 Maybe 节点类似，但是比它的优先级更高，是作为与 Maybe 节点共享父节点的默认路径节点 Future —— 表示 workflow 执行体认为该路径一定会到达的节点，Future 节点的任务在不被 cancel 的情况下一定会执行 Waiting —— 表示当前任务是个阻塞任务，还在执行中，需要等待执行完毕才能进入下个路径 Ready —— 表示 Waiting 节点的任务已执行完，作为 Waiting 节点的 handler Complete —— 表示整个 workflow 的 Jobs 已经全部执行完毕，为终结节点 Cancel —— 表示任务被明确终止了，在状态迁移过程中不作为最终状态  事件原子性 pass]]></description>
</item><item>
    <title>关于关闭 Socket 的一些坑</title>
    <link>https://example.com/tcp-close-socket/</link>
    <pubDate>Wed, 06 Sep 2017 20:36:51 &#43;0000</pubDate>
    <author>Author</author>
    <guid>https://example.com/tcp-close-socket/</guid>
    <description><![CDATA[<h2 id="关于关闭-socket-的一些坑">关于关闭 Socket 的一些坑</h2>
<div style="text-align: right">LexusLee</div>
<h3 id="背景">背景</h3>
<p>最近踩到一个 &ldquo;Socket 连接持续处于 Fin_Wait2 和 Close_Wait 状态无法关闭&rdquo; 的坑中。起因是在维护大量连接时调用 <code>socket.close()</code> 时，看到部分连接并没有正常关闭，而是从 <code>ESTABLISHED</code> 的状态变成 <code>FIN_WAIT2</code> 并且连接状态没有后续迁移，而对端的连接状态则是从 <code>ESTABLISHED</code> 变成了 <code>CLOSE_WAIT</code> 。</p>]]></description>
</item></channel>
</rss>
